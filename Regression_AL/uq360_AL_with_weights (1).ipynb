{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq360 version 0.2 needs to be installed\n",
    "!pip install uq360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6743d0ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the libraries are found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from uq360.metrics import picp, mpiw, compute_regression_metrics\n",
    "    from uq360.metrics import UncertaintyCharacteristicsCurve as ucc\n",
    "\n",
    "    from uq360.algorithms import * \n",
    "    from uq360.algorithms.actively_learned_model import ActivelyLearnedModel\n",
    "    from uq360.algorithms.ensemble_heteroscedastic_regression import EnsembleHeteroscedasticRegression\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print('All the libraries are found')\n",
    "    \n",
    "except:\n",
    "    print(\"One or more libraries need to be installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed02bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name,sheet_name):\n",
    "    \n",
    "    xls_new = pd.ExcelFile(file_name)\n",
    "    df=pd.read_excel(xls_new,sheet_name,header=1).dropna(how='all', axis=1)\n",
    "    df.drop('#',axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = read_data(r'/data/MGP/TestPoints_100k_NEW.xlsx','ResFeasible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368e72b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liquid density [kg/m3]</th>\n",
       "      <th>Liquid \\nviscosity\\n [Pa.s]</th>\n",
       "      <th>Gas molar mass \\n[g/mol]</th>\n",
       "      <th>Gas inlet compressibility\\n</th>\n",
       "      <th>Hub radius [m]</th>\n",
       "      <th>Tip radius [m]</th>\n",
       "      <th>Stage 1 [y=1/n=0]</th>\n",
       "      <th>Tin [K]</th>\n",
       "      <th>Pin [kPa]</th>\n",
       "      <th>GVFin</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "      <th>Unnamed: 56</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>Unnamed: 58</th>\n",
       "      <th>Unnamed: 59</th>\n",
       "      <th>Unnamed: 60</th>\n",
       "      <th>Unnamed: 61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>989.321765</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>322.017877</td>\n",
       "      <td>1867.320507</td>\n",
       "      <td>45.802559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511641</td>\n",
       "      <td>0.481170</td>\n",
       "      <td>0.282785</td>\n",
       "      <td>44.199004</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>1.534924</td>\n",
       "      <td>38.493574</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>-82.805027</td>\n",
       "      <td>-82.510976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997.303292</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.996045</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>300.789449</td>\n",
       "      <td>2261.871734</td>\n",
       "      <td>23.139203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101193</td>\n",
       "      <td>0.215564</td>\n",
       "      <td>0.072913</td>\n",
       "      <td>18.578440</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>0.303578</td>\n",
       "      <td>17.245107</td>\n",
       "      <td>0.053124</td>\n",
       "      <td>-95.641822</td>\n",
       "      <td>-94.785923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>992.909998</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>28.013</td>\n",
       "      <td>1.001839</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>316.852547</td>\n",
       "      <td>5056.459294</td>\n",
       "      <td>46.289280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160709</td>\n",
       "      <td>0.536857</td>\n",
       "      <td>0.188671</td>\n",
       "      <td>44.027960</td>\n",
       "      <td>0.075112</td>\n",
       "      <td>0.482127</td>\n",
       "      <td>42.948563</td>\n",
       "      <td>0.073961</td>\n",
       "      <td>-91.866904</td>\n",
       "      <td>-91.822715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>979.249421</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>28.013</td>\n",
       "      <td>1.006971</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>344.056608</td>\n",
       "      <td>4641.124807</td>\n",
       "      <td>50.149929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116026</td>\n",
       "      <td>0.621454</td>\n",
       "      <td>0.492915</td>\n",
       "      <td>50.014722</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>0.348078</td>\n",
       "      <td>49.716317</td>\n",
       "      <td>0.128725</td>\n",
       "      <td>-81.856351</td>\n",
       "      <td>-81.617170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>991.458984</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>318.474477</td>\n",
       "      <td>3259.999596</td>\n",
       "      <td>40.705742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512668</td>\n",
       "      <td>0.456966</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>41.638716</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>1.538003</td>\n",
       "      <td>36.557283</td>\n",
       "      <td>0.087832</td>\n",
       "      <td>-83.343677</td>\n",
       "      <td>-83.547905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61220</th>\n",
       "      <td>993.307603</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>312.675702</td>\n",
       "      <td>2168.269984</td>\n",
       "      <td>73.980593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580630</td>\n",
       "      <td>0.877313</td>\n",
       "      <td>0.422514</td>\n",
       "      <td>73.258925</td>\n",
       "      <td>0.128289</td>\n",
       "      <td>1.741889</td>\n",
       "      <td>70.185019</td>\n",
       "      <td>0.116052</td>\n",
       "      <td>-75.168011</td>\n",
       "      <td>-74.742154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61221</th>\n",
       "      <td>979.013643</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>28.013</td>\n",
       "      <td>1.003220</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>343.324449</td>\n",
       "      <td>3142.194751</td>\n",
       "      <td>23.701937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483268</td>\n",
       "      <td>0.243125</td>\n",
       "      <td>0.281590</td>\n",
       "      <td>23.139584</td>\n",
       "      <td>0.095482</td>\n",
       "      <td>1.449804</td>\n",
       "      <td>19.450000</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>-84.072124</td>\n",
       "      <td>-83.439957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61222</th>\n",
       "      <td>976.836571</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>28.013</td>\n",
       "      <td>1.005500</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>347.624602</td>\n",
       "      <td>3880.621826</td>\n",
       "      <td>28.295631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>0.320294</td>\n",
       "      <td>0.134274</td>\n",
       "      <td>27.408280</td>\n",
       "      <td>0.065917</td>\n",
       "      <td>0.642008</td>\n",
       "      <td>25.623543</td>\n",
       "      <td>0.064169</td>\n",
       "      <td>-92.708562</td>\n",
       "      <td>-92.300374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61223</th>\n",
       "      <td>988.950121</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.999209</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>322.756787</td>\n",
       "      <td>1772.036814</td>\n",
       "      <td>55.869969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173825</td>\n",
       "      <td>0.676903</td>\n",
       "      <td>0.460372</td>\n",
       "      <td>56.380953</td>\n",
       "      <td>0.128793</td>\n",
       "      <td>0.521475</td>\n",
       "      <td>54.152261</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>-81.158805</td>\n",
       "      <td>-81.033007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61224</th>\n",
       "      <td>997.309404</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>28.013</td>\n",
       "      <td>0.996580</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>303.471654</td>\n",
       "      <td>4065.991613</td>\n",
       "      <td>43.921494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190651</td>\n",
       "      <td>0.514834</td>\n",
       "      <td>0.512962</td>\n",
       "      <td>42.965882</td>\n",
       "      <td>0.136706</td>\n",
       "      <td>0.571952</td>\n",
       "      <td>41.186750</td>\n",
       "      <td>0.132333</td>\n",
       "      <td>-78.753806</td>\n",
       "      <td>-78.657528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61225 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Liquid density [kg/m3]  Liquid \\nviscosity\\n [Pa.s]  \\\n",
       "0                  989.321765                     0.000558   \n",
       "1                  997.303292                     0.000839   \n",
       "2                  992.909998                     0.000611   \n",
       "3                  979.249421                     0.000400   \n",
       "4                  991.458984                     0.000593   \n",
       "...                       ...                          ...   \n",
       "61220              993.307603                     0.000659   \n",
       "61221              979.013643                     0.000404   \n",
       "61222              976.836571                     0.000381   \n",
       "61223              988.950121                     0.000551   \n",
       "61224              997.309404                     0.000792   \n",
       "\n",
       "       Gas molar mass \\n[g/mol]  Gas inlet compressibility\\n  Hub radius [m]  \\\n",
       "0                        28.013                     0.999146            0.14   \n",
       "1                        28.013                     0.996045            0.14   \n",
       "2                        28.013                     1.001839            0.14   \n",
       "3                        28.013                     1.006971            0.14   \n",
       "4                        28.013                     0.999425            0.14   \n",
       "...                         ...                          ...             ...   \n",
       "61220                    28.013                     0.997979            0.14   \n",
       "61221                    28.013                     1.003220            0.14   \n",
       "61222                    28.013                     1.005500            0.14   \n",
       "61223                    28.013                     0.999209            0.14   \n",
       "61224                    28.013                     0.996580            0.14   \n",
       "\n",
       "       Tip radius [m]  Stage 1 [y=1/n=0]     Tin [K]    Pin [kPa]      GVFin  \\\n",
       "0                0.16                  1  322.017877  1867.320507  45.802559   \n",
       "1                0.16                  1  300.789449  2261.871734  23.139203   \n",
       "2                0.16                  1  316.852547  5056.459294  46.289280   \n",
       "3                0.16                  1  344.056608  4641.124807  50.149929   \n",
       "4                0.16                  1  318.474477  3259.999596  40.705742   \n",
       "...               ...                ...         ...          ...        ...   \n",
       "61220            0.16                  1  312.675702  2168.269984  73.980593   \n",
       "61221            0.16                  1  343.324449  3142.194751  23.701937   \n",
       "61222            0.16                  1  347.624602  3880.621826  28.295631   \n",
       "61223            0.16                  1  322.756787  1772.036814  55.869969   \n",
       "61224            0.16                  1  303.471654  4065.991613  43.921494   \n",
       "\n",
       "       ...  Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  Unnamed: 56  \\\n",
       "0      ...     0.511641     0.481170     0.282785    44.199004     0.100509   \n",
       "1      ...     0.101193     0.215564     0.072913    18.578440     0.054718   \n",
       "2      ...     0.160709     0.536857     0.188671    44.027960     0.075112   \n",
       "3      ...     0.116026     0.621454     0.492915    50.014722     0.130476   \n",
       "4      ...     0.512668     0.456966     0.265734    41.638716     0.095642   \n",
       "...    ...          ...          ...          ...          ...          ...   \n",
       "61220  ...     0.580630     0.877313     0.422514    73.258925     0.128289   \n",
       "61221  ...     0.483268     0.243125     0.281590    23.139584     0.095482   \n",
       "61222  ...     0.214003     0.320294     0.134274    27.408280     0.065917   \n",
       "61223  ...     0.173825     0.676903     0.460372    56.380953     0.128793   \n",
       "61224  ...     0.190651     0.514834     0.512962    42.965882     0.136706   \n",
       "\n",
       "       Unnamed: 57  Unnamed: 58  Unnamed: 59  Unnamed: 60  Unnamed: 61  \n",
       "0         1.534924    38.493574     0.090901   -82.805027   -82.510976  \n",
       "1         0.303578    17.245107     0.053124   -95.641822   -94.785923  \n",
       "2         0.482127    42.948563     0.073961   -91.866904   -91.822715  \n",
       "3         0.348078    49.716317     0.128725   -81.856351   -81.617170  \n",
       "4         1.538003    36.557283     0.087832   -83.343677   -83.547905  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "61220     1.741889    70.185019     0.116052   -75.168011   -74.742154  \n",
       "61221     1.449804    19.450000     0.090686   -84.072124   -83.439957  \n",
       "61222     0.642008    25.623543     0.064169   -92.708562   -92.300374  \n",
       "61223     0.521475    54.152261     0.122867   -81.158805   -81.033007  \n",
       "61224     0.571952    41.186750     0.132333   -78.753806   -78.657528  \n",
       "\n",
       "[61225 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kanika\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77daec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df,columns,input_columns,output_columns):\n",
    "    \n",
    "    df = df[columns]\n",
    "    df['Diff_Pressure'] = df['Pout [kPA]'] - df['Pin [kPa]']\n",
    "    df = pd.concat([df[input_columns],df[output_columns]],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b455886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47956/4194695666.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Diff_Pressure'] = df['Pout [kPA]'] - df['Pin [kPa]']\n"
     ]
    }
   ],
   "source": [
    "columns = ['Tin [K]','Pin [kPa]','N [rpm]','Total Consumed power','Pout [kPA]','GVFin','Qin [m3/s]']\n",
    "INPUT_C = ['Tin [K]','Pin [kPa]','N [rpm]','Total Consumed power','Pout [kPA]']\n",
    "OUTPUT_C =['Qin [m3/s]']\n",
    "data_1 = select_columns(data,columns,INPUT_C,OUTPUT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069d67b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61225, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need -of this cell, I am checking for the correct shape\n",
    "data_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427853c0",
   "metadata": {},
   "source": [
    "## Part 1- Implementing Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data and select the number of samples to be considered\n",
    "def scale_data(df,samples):\n",
    "    df_1 = df[0:samples]\n",
    "    df_x = df_1.iloc[:, :-1].values\n",
    "    y_labels = np.squeeze(df_1.iloc[:, -1:].values, axis=1)\n",
    "    y_labels = y_labels.reshape((-1,1))\n",
    "\n",
    "    # scale the values\n",
    "    scaler = StandardScaler()\n",
    "    scaling = scaler.fit(df_x)\n",
    "    x_data = scaling.transform(df_x)\n",
    "    \n",
    "    \n",
    "    return df, y_labels, x_data\n",
    "\n",
    "data,y_labels,x_data = scale_data(data_1,30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e41d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Offline sample and query, two mandatory arguments (and the data):\n",
    "    - Position where to start sampling\n",
    "    - Number of points to sample\n",
    "'''\n",
    "def sample_(start_index, n_points, X_data=x_data):\n",
    "    return x_data[start_index:start_index+n_points,:]\n",
    "\n",
    "def querry_(start_index, n_points, y_labels=y_labels):\n",
    "    return y_labels[start_index:start_index+n_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed8f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configuration for both models, regression baseline and regression with Active Learning\n",
    "def config_():\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # define config for Heteroscedastic regression\n",
    "    config_HR = {\"num_features\": 5, \"num_hidden\": 32, \"num_outputs\": 1, \"batch_size\": 16, \"num_epochs\": 10,\n",
    "                      \"lr\": 0.001}\n",
    "    HR_kwargs = {\"model_type\":'mlp',\n",
    "                   \"config\": config_HR,\n",
    "                   \"device\": device}\n",
    "    # define config for ensemble\n",
    "    config_ensemble = {\"num_models\": 1, \n",
    "              \"batch_size\": 16,\n",
    "              \"model_kwargs\":HR_kwargs, }\n",
    "\n",
    "    ninit = 128\n",
    "    T = 4 # do not change this, since the model is CPU based  T 25 gives error need atleast one array\n",
    "    # define config for active learning object\n",
    "    # T = # no of iterations\n",
    "    # K = # no of uncertain points\n",
    "    config_AL = {\"num_init\": 512, \n",
    "     \"T\": 4, \n",
    "     \"K\": 64, \n",
    "     \"M\": 4, \n",
    "     \"sampling_function\": sample_, \n",
    "     \"querry_function\" : querry_,\n",
    "     \"model_function\": EnsembleHeteroscedasticRegression,\n",
    "     \"model_kwargs\": {\"model_type\":'ensembleheteroscedasticregression', \n",
    "                                                 \"config\":config_ensemble, \n",
    "                                                 \"device\":device}, }\n",
    "    \n",
    "    return config_HR,HR_kwargs,config_AL\n",
    "config_HR,HR_kwargs,config_AL = config_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e82f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the data set has the good dimension\n",
    "def verify_dimension(data_x,config_AL,config_HR):\n",
    "    \n",
    "    assert(data_x.shape[0] >= config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"])\n",
    "    assert(data_x.shape[1] == config_HR[\"num_features\"])\n",
    "    \n",
    "    return True\n",
    "\n",
    "verify_dimension(x_data,config_AL,config_HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f16289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(config_AL):\n",
    "    # Baseline without AL\n",
    "    K_train_list = [16, 32, 64, 128, 256, 512]\n",
    "    frac_err_baseline = []\n",
    "    ninit=128\n",
    "    N_test = 512\n",
    "    device = torch.device(\"cpu\")\n",
    "    T=4\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary to have no active learning and the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit + K_train_list[i] * T\n",
    "        print(config_AL[\"num_init\"])\n",
    "        config_AL[\"T\"] = 0  # no AL here\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit() # until here it is working # model loss -training\n",
    "\n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "        print(X_test.shape,y_test.shape)\n",
    "\n",
    "        res = uq_model.predict(X_test) \n",
    "        print(X_test.shape)\n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_baseline.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        print('iteration---------',i)\n",
    "        \n",
    "    return  frac_err_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8623052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.6799914290507635\n",
      "Epoch: 1, loss = 0.5952014277378719\n",
      "Epoch: 2, loss = 0.5211907799045246\n",
      "Epoch: 3, loss = 0.44937964280446363\n",
      "Epoch: 4, loss = 0.37528171390295034\n",
      "Epoch: 5, loss = 0.2961791219810645\n",
      "Epoch: 6, loss = 0.20944171771407127\n",
      "Epoch: 7, loss = 0.11386424489319326\n",
      "Epoch: 8, loss = 0.008518327027559279\n",
      "Epoch: 9, loss = -0.10694995646675426\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7059683998425801\n",
      "Epoch: 1, loss = 0.6409183293581008\n",
      "Epoch: 2, loss = 0.577372873822848\n",
      "Epoch: 3, loss = 0.5116916944583257\n",
      "Epoch: 4, loss = 0.44103494534889864\n",
      "Epoch: 5, loss = 0.36316909144322074\n",
      "Epoch: 6, loss = 0.27646369362870854\n",
      "Epoch: 7, loss = 0.17947303193310896\n",
      "Epoch: 8, loss = 0.07077185173208515\n",
      "Epoch: 9, loss = -0.05080209206789732\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7265736311674118\n",
      "Epoch: 1, loss = 0.6318246573209763\n",
      "Epoch: 2, loss = 0.554073433081309\n",
      "Epoch: 3, loss = 0.48047244797150296\n",
      "Epoch: 4, loss = 0.40385369956493383\n",
      "Epoch: 5, loss = 0.3228006685773531\n",
      "Epoch: 6, loss = 0.23541353767116863\n",
      "Epoch: 7, loss = 0.14037333180507022\n",
      "Epoch: 8, loss = 0.036723991002266594\n",
      "Epoch: 9, loss = -0.07652875036001205\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7260268529256184\n",
      "Epoch: 1, loss = 0.6696614821751913\n",
      "Epoch: 2, loss = 0.6156399647394816\n",
      "Epoch: 3, loss = 0.5612968603769938\n",
      "Epoch: 4, loss = 0.5036568666497866\n",
      "Epoch: 5, loss = 0.4403249944249789\n",
      "Epoch: 6, loss = 0.3694441094994544\n",
      "Epoch: 7, loss = 0.2895621806383133\n",
      "Epoch: 8, loss = 0.19934455615778765\n",
      "Epoch: 9, loss = 0.09718721235791843\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7691815247138342\n",
      "Epoch: 1, loss = 0.7006016472975413\n",
      "Epoch: 2, loss = 0.6389732559521994\n",
      "Epoch: 3, loss = 0.5776892453432083\n",
      "Epoch: 4, loss = 0.5136118506391842\n",
      "Epoch: 5, loss = 0.44462044040362037\n",
      "Epoch: 6, loss = 0.3690859029690425\n",
      "Epoch: 7, loss = 0.28568469732999807\n",
      "Epoch: 8, loss = 0.19304817852874595\n",
      "Epoch: 9, loss = 0.08987864696731172\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 0\n",
      "256\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8145766742527485\n",
      "Epoch: 1, loss = 0.7460774071514606\n",
      "Epoch: 2, loss = 0.6781131029129028\n",
      "Epoch: 3, loss = 0.6037821471691132\n",
      "Epoch: 4, loss = 0.517919996753335\n",
      "Epoch: 5, loss = 0.41692945174872875\n",
      "Epoch: 6, loss = 0.29749458748847246\n",
      "Epoch: 7, loss = 0.15655030915513635\n",
      "Epoch: 8, loss = -0.007322266232222319\n",
      "Epoch: 9, loss = -0.18918655021116138\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7465799860656261\n",
      "Epoch: 1, loss = 0.6432211361825466\n",
      "Epoch: 2, loss = 0.546527486294508\n",
      "Epoch: 3, loss = 0.4429725110530853\n",
      "Epoch: 4, loss = 0.32907310128211975\n",
      "Epoch: 5, loss = 0.20077806059271097\n",
      "Epoch: 6, loss = 0.054930432699620724\n",
      "Epoch: 7, loss = -0.11086297337897122\n",
      "Epoch: 8, loss = -0.29838688811287284\n",
      "Epoch: 9, loss = -0.5070473160594702\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7935410812497139\n",
      "Epoch: 1, loss = 0.7293562777340412\n",
      "Epoch: 2, loss = 0.6606642603874207\n",
      "Epoch: 3, loss = 0.5830996744334698\n",
      "Epoch: 4, loss = 0.4927919786423445\n",
      "Epoch: 5, loss = 0.38579394668340683\n",
      "Epoch: 6, loss = 0.25881976913660765\n",
      "Epoch: 7, loss = 0.10960150498431176\n",
      "Epoch: 8, loss = -0.06285406881943345\n",
      "Epoch: 9, loss = -0.25756731862202287\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7105448581278324\n",
      "Epoch: 1, loss = 0.6249919421970844\n",
      "Epoch: 2, loss = 0.5398553758859634\n",
      "Epoch: 3, loss = 0.4483235329389572\n",
      "Epoch: 4, loss = 0.3460059240460396\n",
      "Epoch: 5, loss = 0.2290948824957013\n",
      "Epoch: 6, loss = 0.09498840890591964\n",
      "Epoch: 7, loss = -0.05666468420531601\n",
      "Epoch: 8, loss = -0.22314034774899483\n",
      "Epoch: 9, loss = -0.39746377151459455\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7110912427306175\n",
      "Epoch: 1, loss = 0.641936469823122\n",
      "Epoch: 2, loss = 0.5697941072285175\n",
      "Epoch: 3, loss = 0.4916172791272402\n",
      "Epoch: 4, loss = 0.404673982411623\n",
      "Epoch: 5, loss = 0.3065778547897935\n",
      "Epoch: 6, loss = 0.19496101839467883\n",
      "Epoch: 7, loss = 0.06744752236409113\n",
      "Epoch: 8, loss = -0.07778505340684205\n",
      "Epoch: 9, loss = -0.2418437241576612\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 1\n",
      "384\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8010758633414904\n",
      "Epoch: 1, loss = 0.7026630391677221\n",
      "Epoch: 2, loss = 0.5950037067135174\n",
      "Epoch: 3, loss = 0.461686418702205\n",
      "Epoch: 4, loss = 0.2906010032941898\n",
      "Epoch: 5, loss = 0.0719859119465885\n",
      "Epoch: 6, loss = -0.19510096420223513\n",
      "Epoch: 7, loss = -0.4869635061671337\n",
      "Epoch: 8, loss = -0.7670724168419839\n",
      "Epoch: 9, loss = -0.9826119740804036\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7196651821335157\n",
      "Epoch: 1, loss = 0.5736000401278336\n",
      "Epoch: 2, loss = 0.4212707194189231\n",
      "Epoch: 3, loss = 0.24383539116630953\n",
      "Epoch: 4, loss = 0.03004340928358336\n",
      "Epoch: 5, loss = -0.22849916123474634\n",
      "Epoch: 6, loss = -0.5341626480221748\n",
      "Epoch: 7, loss = -0.8697334577639896\n",
      "Epoch: 8, loss = -1.1833667755126953\n",
      "Epoch: 9, loss = -1.3741058955589929\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7785226851701738\n",
      "Epoch: 1, loss = 0.6827064529061317\n",
      "Epoch: 2, loss = 0.571122729529937\n",
      "Epoch: 3, loss = 0.43107381338874495\n",
      "Epoch: 4, loss = 0.25120489578694105\n",
      "Epoch: 5, loss = 0.023651054749886193\n",
      "Epoch: 6, loss = -0.2534555004288753\n",
      "Epoch: 7, loss = -0.5667316714922588\n",
      "Epoch: 8, loss = -0.8411403422554335\n",
      "Epoch: 9, loss = -0.9826127116878829\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.6910463546713194\n",
      "Epoch: 1, loss = 0.5660490207374095\n",
      "Epoch: 2, loss = 0.43198638657728833\n",
      "Epoch: 3, loss = 0.27342308467874926\n",
      "Epoch: 4, loss = 0.07896123143533867\n",
      "Epoch: 5, loss = -0.15221243848403293\n",
      "Epoch: 6, loss = -0.3943412924806277\n",
      "Epoch: 7, loss = -0.6240791392823061\n",
      "Epoch: 8, loss = -0.8214540208379428\n",
      "Epoch: 9, loss = -0.8876318236192068\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.6962688590089481\n",
      "Epoch: 1, loss = 0.5938048958778381\n",
      "Epoch: 2, loss = 0.4804437222580115\n",
      "Epoch: 3, loss = 0.34740911548336356\n",
      "Epoch: 4, loss = 0.18672767219444117\n",
      "Epoch: 5, loss = -0.008797140287545817\n",
      "Epoch: 6, loss = -0.24420056336869794\n",
      "Epoch: 7, loss = -0.518046257396539\n",
      "Epoch: 8, loss = -0.8165905301769575\n",
      "Epoch: 9, loss = -1.1104008778929708\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 2\n",
      "640\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7593924045562744\n",
      "Epoch: 1, loss = 0.5784210778772833\n",
      "Epoch: 2, loss = 0.3254525812342763\n",
      "Epoch: 3, loss = -0.030990516289602962\n",
      "Epoch: 4, loss = -0.3587925750762225\n",
      "Epoch: 5, loss = -0.6069479137659073\n",
      "Epoch: 6, loss = -0.8884535498917104\n",
      "Epoch: 7, loss = -1.1252166900783778\n",
      "Epoch: 8, loss = -1.334181770682335\n",
      "Epoch: 9, loss = -1.5891729861497874\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.6749812349677086\n",
      "Epoch: 1, loss = 0.4284253597259521\n",
      "Epoch: 2, loss = 0.12091022887034338\n",
      "Epoch: 3, loss = -0.2948069941718131\n",
      "Epoch: 4, loss = -0.802132462710142\n",
      "Epoch: 5, loss = -1.2733093172311782\n",
      "Epoch: 6, loss = -1.5766602635383609\n",
      "Epoch: 7, loss = -1.6954806387424466\n",
      "Epoch: 8, loss = -1.6081460326910018\n",
      "Epoch: 9, loss = -1.731531327962875\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.750040636956692\n",
      "Epoch: 1, loss = 0.5682098284363747\n",
      "Epoch: 2, loss = 0.30700582452118397\n",
      "Epoch: 3, loss = -0.07226748503744602\n",
      "Epoch: 4, loss = -0.5215829446911812\n",
      "Epoch: 5, loss = -0.901646425575018\n",
      "Epoch: 6, loss = -1.1701479896903038\n",
      "Epoch: 7, loss = -1.3859877586364748\n",
      "Epoch: 8, loss = -1.51789533495903\n",
      "Epoch: 9, loss = -1.6504095226526256\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.6521941840648652\n",
      "Epoch: 1, loss = 0.4325434036552906\n",
      "Epoch: 2, loss = 0.15007704193703827\n",
      "Epoch: 3, loss = -0.21722996453754606\n",
      "Epoch: 4, loss = -0.5926949348300696\n",
      "Epoch: 5, loss = -0.9129357308149337\n",
      "Epoch: 6, loss = -1.1032740309834481\n",
      "Epoch: 7, loss = -1.4030849039554596\n",
      "Epoch: 8, loss = -1.388310931622982\n",
      "Epoch: 9, loss = -1.4940362922847268\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.6636801660060883\n",
      "Epoch: 1, loss = 0.4833988964557647\n",
      "Epoch: 2, loss = 0.25095456652343273\n",
      "Epoch: 3, loss = -0.06739246859215199\n",
      "Epoch: 4, loss = -0.490202060341835\n",
      "Epoch: 5, loss = -0.9693631291389466\n",
      "Epoch: 6, loss = -1.304395970702171\n",
      "Epoch: 7, loss = -1.5562148243188858\n",
      "Epoch: 8, loss = -1.694405055046081\n",
      "Epoch: 9, loss = -1.759764587879181\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 3\n",
      "1152\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.6849311466018361\n",
      "Epoch: 1, loss = 0.24712109468722093\n",
      "Epoch: 2, loss = -0.3262180362362414\n",
      "Epoch: 3, loss = -0.6635024866296184\n",
      "Epoch: 4, loss = -1.0913216099143028\n",
      "Epoch: 5, loss = -1.4001774237387707\n",
      "Epoch: 6, loss = -1.682035719354948\n",
      "Epoch: 7, loss = -1.7994732277260892\n",
      "Epoch: 8, loss = -1.8796082288026807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss = -1.9439502341879742\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.5815198603603575\n",
      "Epoch: 1, loss = 0.049515883140783326\n",
      "Epoch: 2, loss = -0.7829138504134285\n",
      "Epoch: 3, loss = -1.3678697993357976\n",
      "Epoch: 4, loss = -1.5978513575262496\n",
      "Epoch: 5, loss = -1.71097288115157\n",
      "Epoch: 6, loss = -1.8361309832996786\n",
      "Epoch: 7, loss = -1.8812179780668676\n",
      "Epoch: 8, loss = -1.966198159588708\n",
      "Epoch: 9, loss = -2.0056112358967466\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.6776625319487519\n",
      "Epoch: 1, loss = 0.22468310585504184\n",
      "Epoch: 2, loss = -0.5152211630096036\n",
      "Epoch: 3, loss = -1.0137931431333222\n",
      "Epoch: 4, loss = -1.4121904282106292\n",
      "Epoch: 5, loss = -1.5244201281004484\n",
      "Epoch: 6, loss = -1.712517289651764\n",
      "Epoch: 7, loss = -1.7191638648509977\n",
      "Epoch: 8, loss = -1.877744265728527\n",
      "Epoch: 9, loss = -1.924430607093705\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.5690964398284755\n",
      "Epoch: 1, loss = 0.08228557062749232\n",
      "Epoch: 2, loss = -0.47031731779376656\n",
      "Epoch: 3, loss = -1.01199938936366\n",
      "Epoch: 4, loss = -1.3502518849240408\n",
      "Epoch: 5, loss = -1.629308854540189\n",
      "Epoch: 6, loss = -1.7011593133211138\n",
      "Epoch: 7, loss = -1.8493743952777661\n",
      "Epoch: 8, loss = -1.846625830564234\n",
      "Epoch: 9, loss = -1.9433111697435381\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.5900196503433919\n",
      "Epoch: 1, loss = 0.18833426099606873\n",
      "Epoch: 2, loss = -0.4840763121222456\n",
      "Epoch: 3, loss = -1.2030397206544876\n",
      "Epoch: 4, loss = -1.412202268838883\n",
      "Epoch: 5, loss = -1.733322423365381\n",
      "Epoch: 6, loss = -1.845119906796349\n",
      "Epoch: 7, loss = -1.8967844926648674\n",
      "Epoch: 8, loss = -2.023340619272655\n",
      "Epoch: 9, loss = -1.9368383085562122\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 4\n",
      "2176\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4943468576324556\n",
      "Epoch: 1, loss = -0.44883634673212397\n",
      "Epoch: 2, loss = -1.0911108830067162\n",
      "Epoch: 3, loss = -1.645652740865069\n",
      "Epoch: 4, loss = -1.867723145905663\n",
      "Epoch: 5, loss = -1.968758501550731\n",
      "Epoch: 6, loss = -2.0394770971992435\n",
      "Epoch: 7, loss = -2.1014498726410027\n",
      "Epoch: 8, loss = -2.154590028173782\n",
      "Epoch: 9, loss = -2.2024341392166478\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.34687688508454484\n",
      "Epoch: 1, loss = -1.0252888590535691\n",
      "Epoch: 2, loss = -1.6316911532160119\n",
      "Epoch: 3, loss = -1.8743424700463516\n",
      "Epoch: 4, loss = -1.9355592377045583\n",
      "Epoch: 5, loss = -2.0626915539888766\n",
      "Epoch: 6, loss = -2.0976456574657387\n",
      "Epoch: 7, loss = -2.175938808742692\n",
      "Epoch: 8, loss = -2.2342216013108986\n",
      "Epoch: 9, loss = -2.2528289477614796\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48333225106163064\n",
      "Epoch: 1, loss = -0.6232163309092247\n",
      "Epoch: 2, loss = -1.3711904949125127\n",
      "Epoch: 3, loss = -1.679932563620455\n",
      "Epoch: 4, loss = -1.8207507858819818\n",
      "Epoch: 5, loss = -1.9289304377401575\n",
      "Epoch: 6, loss = -1.9954983462743905\n",
      "Epoch: 7, loss = -2.0732070803642273\n",
      "Epoch: 8, loss = -2.1297027293373563\n",
      "Epoch: 9, loss = -2.1912559452740585\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.34779508305056134\n",
      "Epoch: 1, loss = -0.7631643113187131\n",
      "Epoch: 2, loss = -1.1265398105058602\n",
      "Epoch: 3, loss = -1.7345362108419926\n",
      "Epoch: 4, loss = -1.8552314433104853\n",
      "Epoch: 5, loss = -1.9410195488701858\n",
      "Epoch: 6, loss = -2.0182428732514386\n",
      "Epoch: 7, loss = -2.0883579219088837\n",
      "Epoch: 8, loss = -2.1547570842153894\n",
      "Epoch: 9, loss = -2.2124933328698666\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.4204489782808679\n",
      "Epoch: 1, loss = -0.7389286982087309\n",
      "Epoch: 2, loss = -1.572017511024195\n",
      "Epoch: 3, loss = -1.8543494326226857\n",
      "Epoch: 4, loss = -1.9734660492223859\n",
      "Epoch: 5, loss = -2.0701386753250572\n",
      "Epoch: 6, loss = -2.152668184217285\n",
      "Epoch: 7, loss = -2.2200702709310187\n",
      "Epoch: 8, loss = -2.2783235162496567\n",
      "Epoch: 9, loss = -2.32904571031823\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 5\n"
     ]
    }
   ],
   "source": [
    "errors_baseline=baseline(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70b36fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_al(config_AL):\n",
    "    # AL, ensemble of 5 NNs\n",
    "    frac_err_AL_ens = []\n",
    "    device = torch.device(\"cpu\")\n",
    "    K_train_list = [16, 32, 64, 128, 256, 512] # make it as a global variable\n",
    "    N_test = 512\n",
    "    ninit=128\n",
    "    T=4\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary for the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit\n",
    "        config_AL[\"K\"] = K_train_list[i]\n",
    "        config_AL[\"M\"] = 4\n",
    "        config_AL[\"T\"] = T\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit()\n",
    "\n",
    "        \n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "\n",
    "        res = uq_model.predict(X_test)\n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_AL_ens.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        \n",
    "    return frac_err_AL_ens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e285fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4635593063301511\n",
      "Epoch: 1, loss = 0.41496842768457204\n",
      "Epoch: 2, loss = 0.3640258378452724\n",
      "Epoch: 3, loss = 0.30970504383246106\n",
      "Epoch: 4, loss = 0.251527313556936\n",
      "Epoch: 5, loss = 0.18896440789103508\n",
      "Epoch: 6, loss = 0.12166911198033226\n",
      "Epoch: 7, loss = 0.04938091782646047\n",
      "Epoch: 8, loss = -0.02821777471237713\n",
      "Epoch: 9, loss = -0.11088917031884193\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2399344013796912\n",
      "Epoch: 1, loss = 0.17415515250629848\n",
      "Epoch: 2, loss = 0.10545694972905847\n",
      "Epoch: 3, loss = 0.033193146602975\n",
      "Epoch: 4, loss = -0.043537216261029237\n",
      "Epoch: 5, loss = -0.12473154792355166\n",
      "Epoch: 6, loss = -0.21116480314069325\n",
      "Epoch: 7, loss = -0.3026941153738234\n",
      "Epoch: 8, loss = -0.39950910872883266\n",
      "Epoch: 9, loss = -0.5016251371966468\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.43416361014048255\n",
      "Epoch: 1, loss = 0.38395483626259697\n",
      "Epoch: 2, loss = 0.3315184977319506\n",
      "Epoch: 3, loss = 0.27589492499828344\n",
      "Epoch: 4, loss = 0.21673651039600372\n",
      "Epoch: 5, loss = 0.15353365035520655\n",
      "Epoch: 6, loss = 0.0860797990527418\n",
      "Epoch: 7, loss = 0.01397553469157881\n",
      "Epoch: 8, loss = -0.06309952338536579\n",
      "Epoch: 9, loss = -0.14518752445777255\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.27208062012990314\n",
      "Epoch: 1, loss = 0.21425792409314048\n",
      "Epoch: 2, loss = 0.15490200701687074\n",
      "Epoch: 3, loss = 0.09154873734547034\n",
      "Epoch: 4, loss = 0.02466463545958201\n",
      "Epoch: 5, loss = -0.04676134139299393\n",
      "Epoch: 6, loss = -0.12252073176205157\n",
      "Epoch: 7, loss = -0.20266267905632657\n",
      "Epoch: 8, loss = -0.28704261945353615\n",
      "Epoch: 9, loss = -0.3758997139003542\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3486979537540012\n",
      "Epoch: 1, loss = 0.30070258842574227\n",
      "Epoch: 2, loss = 0.2511765940321816\n",
      "Epoch: 3, loss = 0.19922107954819995\n",
      "Epoch: 4, loss = 0.14433149703674844\n",
      "Epoch: 5, loss = 0.08593457668191858\n",
      "Epoch: 6, loss = 0.023604570577541985\n",
      "Epoch: 7, loss = -0.043133086110982634\n",
      "Epoch: 8, loss = -0.11459688883688714\n",
      "Epoch: 9, loss = -0.19118318582574526\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.16871007345616817\n",
      "Epoch: 1, loss = -0.24966636300086975\n",
      "Epoch: 2, loss = -0.33082264587283133\n",
      "Epoch: 3, loss = -0.4188434101641178\n",
      "Epoch: 4, loss = -0.5030308872461319\n",
      "Epoch: 5, loss = -0.5794428437948227\n",
      "Epoch: 6, loss = -0.6670791983604432\n",
      "Epoch: 7, loss = -0.7606742948293685\n",
      "Epoch: 8, loss = -0.8377457588911055\n",
      "Epoch: 9, loss = -0.8857958674430848\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.5668035089969635\n",
      "Epoch: 1, loss = -0.6672838747501373\n",
      "Epoch: 2, loss = -0.7676237344741821\n",
      "Epoch: 3, loss = -0.8710167646408081\n",
      "Epoch: 4, loss = -0.9763156235218047\n",
      "Epoch: 5, loss = -1.0815558075904845\n",
      "Epoch: 6, loss = -1.1882278144359588\n",
      "Epoch: 7, loss = -1.2948479890823363\n",
      "Epoch: 8, loss = -1.3971078813076017\n",
      "Epoch: 9, loss = -1.4914939641952514\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.19792136624455453\n",
      "Epoch: 1, loss = -0.2800671968609094\n",
      "Epoch: 2, loss = -0.36571337059140213\n",
      "Epoch: 3, loss = -0.45353507995605463\n",
      "Epoch: 4, loss = -0.5444744765758515\n",
      "Epoch: 5, loss = -0.6384782910346986\n",
      "Epoch: 6, loss = -0.7337072610855102\n",
      "Epoch: 7, loss = -0.8277075409889221\n",
      "Epoch: 8, loss = -0.9158306896686554\n",
      "Epoch: 9, loss = -0.994474071264267\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.42708277702331543\n",
      "Epoch: 1, loss = -0.5138442099094391\n",
      "Epoch: 2, loss = -0.6074847966432572\n",
      "Epoch: 3, loss = -0.6948028624057769\n",
      "Epoch: 4, loss = -0.7699132680892944\n",
      "Epoch: 5, loss = -0.8710964143276215\n",
      "Epoch: 6, loss = -0.967941665649414\n",
      "Epoch: 7, loss = -1.0558598160743713\n",
      "Epoch: 8, loss = -1.0888164997100829\n",
      "Epoch: 9, loss = -0.7381678193807603\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.24110266510397196\n",
      "Epoch: 1, loss = -0.31773920506238934\n",
      "Epoch: 2, loss = -0.39922129213809965\n",
      "Epoch: 3, loss = -0.4829373598098755\n",
      "Epoch: 4, loss = -0.5712851107120513\n",
      "Epoch: 5, loss = -0.664307874441147\n",
      "Epoch: 6, loss = -0.7599267333745957\n",
      "Epoch: 7, loss = -0.8569386541843415\n",
      "Epoch: 8, loss = -0.9565378189086914\n",
      "Epoch: 9, loss = -1.0563571155071259\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.9207964051853526\n",
      "Epoch: 1, loss = -0.9729787707328797\n",
      "Epoch: 2, loss = -1.004054383798079\n",
      "Epoch: 3, loss = -1.1095001697540283\n",
      "Epoch: 4, loss = -1.1405068039894104\n",
      "Epoch: 5, loss = -1.2366575869646939\n",
      "Epoch: 6, loss = -1.3041689233346418\n",
      "Epoch: 7, loss = -1.3208531087095088\n",
      "Epoch: 8, loss = -1.2284149256619539\n",
      "Epoch: 9, loss = -1.3863400708545337\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.4992320104078813\n",
      "Epoch: 1, loss = -1.5848991220647637\n",
      "Epoch: 2, loss = -1.6571738611568103\n",
      "Epoch: 3, loss = -1.724781946702437\n",
      "Epoch: 4, loss = -1.7032720392400569\n",
      "Epoch: 5, loss = -1.5214537165381694\n",
      "Epoch: 6, loss = -1.7839559208263052\n",
      "Epoch: 7, loss = -1.7263357422568582\n",
      "Epoch: 8, loss = -1.9003835699775002\n",
      "Epoch: 9, loss = -1.8833609169179744\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.017719729380174\n",
      "Epoch: 1, loss = -1.0936091921546243\n",
      "Epoch: 2, loss = -1.1996327476067976\n",
      "Epoch: 3, loss = -1.282901558009061\n",
      "Epoch: 4, loss = -1.330936312675476\n",
      "Epoch: 5, loss = -1.2783047394319014\n",
      "Epoch: 6, loss = -1.451420074159449\n",
      "Epoch: 7, loss = -1.5195374543016607\n",
      "Epoch: 8, loss = -1.584772678938779\n",
      "Epoch: 9, loss = -1.5534423806450584\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.1575197848406704\n",
      "Epoch: 1, loss = -1.2421616749329998\n",
      "Epoch: 2, loss = -1.22117587111213\n",
      "Epoch: 3, loss = -1.2122136787934739\n",
      "Epoch: 4, loss = -1.175808397206393\n",
      "Epoch: 5, loss = -1.3001880103891545\n",
      "Epoch: 6, loss = -1.4454681981693616\n",
      "Epoch: 7, loss = -1.487798636609858\n",
      "Epoch: 8, loss = -1.461877302689986\n",
      "Epoch: 9, loss = -1.5982901291413742\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.0967332504012366\n",
      "Epoch: 1, loss = -1.193007761781866\n",
      "Epoch: 2, loss = -1.2817932692441072\n",
      "Epoch: 3, loss = -1.3493843891403892\n",
      "Epoch: 4, loss = -1.4217576980590818\n",
      "Epoch: 5, loss = -1.4969872344623913\n",
      "Epoch: 6, loss = -1.5562160394408486\n",
      "Epoch: 7, loss = -1.5871902379122649\n",
      "Epoch: 8, loss = -1.6484553272073916\n",
      "Epoch: 9, loss = -1.7530664964155716\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.367286498347918\n",
      "Epoch: 1, loss = -1.439305916428566\n",
      "Epoch: 2, loss = -1.4363181591033936\n",
      "Epoch: 3, loss = -1.488239695628484\n",
      "Epoch: 4, loss = -1.4415686031182606\n",
      "Epoch: 5, loss = -1.4791465898354845\n",
      "Epoch: 6, loss = -1.386013587315877\n",
      "Epoch: 7, loss = -1.391787980993589\n",
      "Epoch: 8, loss = -1.172506369650364\n",
      "Epoch: 9, loss = -0.8962338541944821\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.8511219720045724\n",
      "Epoch: 1, loss = -1.9167125324408212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss = -1.9850128094355262\n",
      "Epoch: 3, loss = -1.873079111178716\n",
      "Epoch: 4, loss = -1.7555571496486662\n",
      "Epoch: 5, loss = -1.8931968907515209\n",
      "Epoch: 6, loss = -1.7636443972587585\n",
      "Epoch: 7, loss = -1.9556300938129425\n",
      "Epoch: 8, loss = -2.0335583190123243\n",
      "Epoch: 9, loss = -2.0741897920767465\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5284046580394108\n",
      "Epoch: 1, loss = -1.5735684235890708\n",
      "Epoch: 2, loss = -1.6747030913829803\n",
      "Epoch: 3, loss = -1.7406587203343706\n",
      "Epoch: 4, loss = -1.7622078160444894\n",
      "Epoch: 5, loss = -1.6771304706732433\n",
      "Epoch: 6, loss = -1.442042628924052\n",
      "Epoch: 7, loss = -1.658596048752467\n",
      "Epoch: 8, loss = -1.492231920361519\n",
      "Epoch: 9, loss = -1.5455191632111869\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.4070620338122048\n",
      "Epoch: 1, loss = -1.430319428443909\n",
      "Epoch: 2, loss = -1.1363088823854923\n",
      "Epoch: 3, loss = -1.2790035754442215\n",
      "Epoch: 4, loss = -1.2426727364460628\n",
      "Epoch: 5, loss = -1.291507214307785\n",
      "Epoch: 6, loss = -1.3437020778656004\n",
      "Epoch: 7, loss = -1.4412337442239125\n",
      "Epoch: 8, loss = -1.5379763940970104\n",
      "Epoch: 9, loss = -1.5942226747671762\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.7317940096060436\n",
      "Epoch: 1, loss = -1.781889299551646\n",
      "Epoch: 2, loss = -1.642958124478658\n",
      "Epoch: 3, loss = -1.7291936675707498\n",
      "Epoch: 4, loss = -1.7087308565775552\n",
      "Epoch: 5, loss = -1.8470199704170225\n",
      "Epoch: 6, loss = -1.8328049778938291\n",
      "Epoch: 7, loss = -1.9330613911151888\n",
      "Epoch: 8, loss = -1.9552310307820637\n",
      "Epoch: 9, loss = -1.9577795167764027\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.46944885551929477\n",
      "Epoch: 1, loss = 0.4166005909442902\n",
      "Epoch: 2, loss = 0.36092160642147064\n",
      "Epoch: 3, loss = 0.30098188966512684\n",
      "Epoch: 4, loss = 0.23622570037841795\n",
      "Epoch: 5, loss = 0.16595304552465678\n",
      "Epoch: 6, loss = 0.0897199222818017\n",
      "Epoch: 7, loss = 0.007366427406668662\n",
      "Epoch: 8, loss = -0.0808842558413744\n",
      "Epoch: 9, loss = -0.17394597232341769\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.25197884440422064\n",
      "Epoch: 1, loss = 0.18132519200444222\n",
      "Epoch: 2, loss = 0.10682590678334236\n",
      "Epoch: 3, loss = 0.028307480737566944\n",
      "Epoch: 4, loss = -0.05615288922563194\n",
      "Epoch: 5, loss = -0.14580133203417062\n",
      "Epoch: 6, loss = -0.24206947013735772\n",
      "Epoch: 7, loss = -0.34465941190719607\n",
      "Epoch: 8, loss = -0.45358557701110835\n",
      "Epoch: 9, loss = -0.5684835523366929\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.44364193379879\n",
      "Epoch: 1, loss = 0.38949733674526216\n",
      "Epoch: 2, loss = 0.33270853161811825\n",
      "Epoch: 3, loss = 0.27197993993759156\n",
      "Epoch: 4, loss = 0.20689539089798928\n",
      "Epoch: 5, loss = 0.13680021651089191\n",
      "Epoch: 6, loss = 0.0614071924239397\n",
      "Epoch: 7, loss = -0.01975009944289923\n",
      "Epoch: 8, loss = -0.10683313393965364\n",
      "Epoch: 9, loss = -0.19986510053277018\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.285348504781723\n",
      "Epoch: 1, loss = 0.2230245016515255\n",
      "Epoch: 2, loss = 0.15834813453257085\n",
      "Epoch: 3, loss = 0.08917784253135325\n",
      "Epoch: 4, loss = 0.015446992218494415\n",
      "Epoch: 5, loss = -0.06370250321924688\n",
      "Epoch: 6, loss = -0.14772527161985635\n",
      "Epoch: 7, loss = -0.23693660721182822\n",
      "Epoch: 8, loss = -0.33086037188768386\n",
      "Epoch: 9, loss = -0.42873149514198305\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3587699413299561\n",
      "Epoch: 1, loss = 0.307647106051445\n",
      "Epoch: 2, loss = 0.25469764322042465\n",
      "Epoch: 3, loss = 0.19876541569828987\n",
      "Epoch: 4, loss = 0.13913446366786958\n",
      "Epoch: 5, loss = 0.07513327607885004\n",
      "Epoch: 6, loss = 0.006136860419064761\n",
      "Epoch: 7, loss = -0.06828517280519009\n",
      "Epoch: 8, loss = -0.1486571379005909\n",
      "Epoch: 9, loss = -0.23535498753190037\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.20618672835795832\n",
      "Epoch: 1, loss = -0.29543630980576085\n",
      "Epoch: 2, loss = -0.3945447923615575\n",
      "Epoch: 3, loss = -0.4910324815039833\n",
      "Epoch: 4, loss = -0.5823747677107652\n",
      "Epoch: 5, loss = -0.6410903843740624\n",
      "Epoch: 6, loss = -0.7519435534874599\n",
      "Epoch: 7, loss = -0.8394573827584584\n",
      "Epoch: 8, loss = -0.9304534569382668\n",
      "Epoch: 9, loss = -0.897529348731041\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.6246272126833597\n",
      "Epoch: 1, loss = -0.7401998912294706\n",
      "Epoch: 2, loss = -0.8576196829477944\n",
      "Epoch: 3, loss = -0.9699272364377975\n",
      "Epoch: 4, loss = -1.0759417911370595\n",
      "Epoch: 5, loss = -1.1848339587450027\n",
      "Epoch: 6, loss = -1.2997265358765921\n",
      "Epoch: 7, loss = -1.3803357879320781\n",
      "Epoch: 8, loss = -1.3267002205053966\n",
      "Epoch: 9, loss = -0.9997604042291642\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.22573013479510937\n",
      "Epoch: 1, loss = -0.32036725788687676\n",
      "Epoch: 2, loss = -0.41907567065209156\n",
      "Epoch: 3, loss = -0.520043163560331\n",
      "Epoch: 4, loss = -0.6221227024992309\n",
      "Epoch: 5, loss = -0.7212093981603782\n",
      "Epoch: 6, loss = -0.8172558732330799\n",
      "Epoch: 7, loss = -0.9139044955372809\n",
      "Epoch: 8, loss = -1.0074717551469803\n",
      "Epoch: 9, loss = -1.0865944996476173\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.4681528784955541\n",
      "Epoch: 1, loss = -0.5686746276915073\n",
      "Epoch: 2, loss = -0.6789642535150051\n",
      "Epoch: 3, loss = -0.7775781080126761\n",
      "Epoch: 4, loss = -0.83048311372598\n",
      "Epoch: 5, loss = -0.8506364002823831\n",
      "Epoch: 6, loss = -0.9450289482871692\n",
      "Epoch: 7, loss = -1.0435493687788646\n",
      "Epoch: 8, loss = -1.0139109492301943\n",
      "Epoch: 9, loss = -1.1921487053235371\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.27608654477323097\n",
      "Epoch: 1, loss = -0.36470468590656924\n",
      "Epoch: 2, loss = -0.46169066180785495\n",
      "Epoch: 3, loss = -0.5614762815336386\n",
      "Epoch: 4, loss = -0.6625549892584484\n",
      "Epoch: 5, loss = -0.7701963757475218\n",
      "Epoch: 6, loss = -0.8824840237696966\n",
      "Epoch: 7, loss = -0.9844312022129694\n",
      "Epoch: 8, loss = -1.0642887552579245\n",
      "Epoch: 9, loss = -1.1658405760924022\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.0077658295631409\n",
      "Epoch: 1, loss = -0.8797513246536255\n",
      "Epoch: 2, loss = -1.0650738094534193\n",
      "Epoch: 3, loss = -1.1786462324006217\n",
      "Epoch: 4, loss = -1.2209556187902177\n",
      "Epoch: 5, loss = -1.3250579365662163\n",
      "Epoch: 6, loss = -1.3605693450995857\n",
      "Epoch: 7, loss = -1.3671903865677968\n",
      "Epoch: 8, loss = -1.3174619185073035\n",
      "Epoch: 9, loss = -1.456071104322161\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.1825482760156902\n",
      "Epoch: 1, loss = -0.7952091172337532\n",
      "Epoch: 2, loss = -0.6834154725074768\n",
      "Epoch: 3, loss = -0.9415298040424075\n",
      "Epoch: 4, loss = -1.256478181907109\n",
      "Epoch: 5, loss = -1.4121105032307761\n",
      "Epoch: 6, loss = -1.4842524954250882\n",
      "Epoch: 7, loss = -1.5426025220326016\n",
      "Epoch: 8, loss = -1.6018624901771545\n",
      "Epoch: 9, loss = -1.6604059849466597\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.098791697195598\n",
      "Epoch: 1, loss = -1.1735331756728036\n",
      "Epoch: 2, loss = -1.2841788062027526\n",
      "Epoch: 3, loss = -1.3578308778149741\n",
      "Epoch: 4, loss = -1.4446121624537875\n",
      "Epoch: 5, loss = -1.3589578781809124\n",
      "Epoch: 6, loss = -1.0810894497803278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss = -1.4184070101806094\n",
      "Epoch: 8, loss = -1.5552849641868047\n",
      "Epoch: 9, loss = -1.6096841182027544\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.162535126720156\n",
      "Epoch: 1, loss = -1.1831775094781602\n",
      "Epoch: 2, loss = -0.9968368953892164\n",
      "Epoch: 3, loss = -1.1602550787585122\n",
      "Epoch: 4, loss = -1.1248057442052024\n",
      "Epoch: 5, loss = -1.0868415385484695\n",
      "Epoch: 6, loss = -0.9664363318255971\n",
      "Epoch: 7, loss = -0.884533915668726\n",
      "Epoch: 8, loss = -0.9769095416579928\n",
      "Epoch: 9, loss = -1.187931788819177\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.2292569449969701\n",
      "Epoch: 1, loss = -1.286460480519703\n",
      "Epoch: 2, loss = -1.3959426539284843\n",
      "Epoch: 3, loss = -1.4135487845965793\n",
      "Epoch: 4, loss = -1.4676006393773215\n",
      "Epoch: 5, loss = -1.598349119935717\n",
      "Epoch: 6, loss = -1.6422760997499737\n",
      "Epoch: 7, loss = -1.4183746576309204\n",
      "Epoch: 8, loss = -1.4525883623531888\n",
      "Epoch: 9, loss = -1.5399196233068195\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.4447544813156128\n",
      "Epoch: 1, loss = -1.2561657801270485\n",
      "Epoch: 2, loss = -1.1310215182602406\n",
      "Epoch: 3, loss = -0.4077064674347639\n",
      "Epoch: 4, loss = -0.0427078939974308\n",
      "Epoch: 5, loss = -0.6327339746057987\n",
      "Epoch: 6, loss = -1.2408601678907871\n",
      "Epoch: 7, loss = -1.4656595848500729\n",
      "Epoch: 8, loss = -1.5028541833162308\n",
      "Epoch: 9, loss = -1.5353226214647293\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.6548573449254036\n",
      "Epoch: 1, loss = -1.6594569832086563\n",
      "Epoch: 2, loss = -1.6631819233298302\n",
      "Epoch: 3, loss = -1.223668433725834\n",
      "Epoch: 4, loss = -1.4253258295357227\n",
      "Epoch: 5, loss = -0.9024201147258282\n",
      "Epoch: 6, loss = 0.44110067933797836\n",
      "Epoch: 7, loss = -0.007297759875655174\n",
      "Epoch: 8, loss = -1.5024986565113068\n",
      "Epoch: 9, loss = -1.5102016776800156\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5209986343979836\n",
      "Epoch: 1, loss = -1.4636782482266426\n",
      "Epoch: 2, loss = -1.3126757685095072\n",
      "Epoch: 3, loss = -1.3191573098301888\n",
      "Epoch: 4, loss = -1.2140150014311075\n",
      "Epoch: 5, loss = -1.3651639074087143\n",
      "Epoch: 6, loss = -1.47231974452734\n",
      "Epoch: 7, loss = -1.5678389221429825\n",
      "Epoch: 8, loss = -1.566203162074089\n",
      "Epoch: 9, loss = -1.6365644708275795\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.3566317781805992\n",
      "Epoch: 1, loss = -1.4357575923204422\n",
      "Epoch: 2, loss = -1.4669832587242126\n",
      "Epoch: 3, loss = -1.300162436440587\n",
      "Epoch: 4, loss = -1.442536510527134\n",
      "Epoch: 5, loss = -1.1173889338970184\n",
      "Epoch: 6, loss = -0.9172187941148877\n",
      "Epoch: 7, loss = -0.9463475979864597\n",
      "Epoch: 8, loss = -1.2492971122264862\n",
      "Epoch: 9, loss = -1.4695990942418575\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.6514528766274452\n",
      "Epoch: 1, loss = -1.726644642651081\n",
      "Epoch: 2, loss = -1.6151898577809334\n",
      "Epoch: 3, loss = -1.7566904053092003\n",
      "Epoch: 4, loss = -1.612594274803996\n",
      "Epoch: 5, loss = -1.6289393156766891\n",
      "Epoch: 6, loss = -1.862123154103756\n",
      "Epoch: 7, loss = -1.8638950437307358\n",
      "Epoch: 8, loss = -1.8697412610054016\n",
      "Epoch: 9, loss = -1.7896406799554825\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4904185806711515\n",
      "Epoch: 1, loss = 0.43172332396109897\n",
      "Epoch: 2, loss = 0.3693026229739189\n",
      "Epoch: 3, loss = 0.3010291637231906\n",
      "Epoch: 4, loss = 0.22603602210680646\n",
      "Epoch: 5, loss = 0.14359105098992586\n",
      "Epoch: 6, loss = 0.05304261700560649\n",
      "Epoch: 7, loss = -0.045648439476887376\n",
      "Epoch: 8, loss = -0.15065387512246767\n",
      "Epoch: 9, loss = -0.25534302182495594\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2646451021234194\n",
      "Epoch: 1, loss = 0.18403911031782627\n",
      "Epoch: 2, loss = 0.09718382343028982\n",
      "Epoch: 3, loss = 0.005363224656321108\n",
      "Epoch: 4, loss = -0.09569807754208645\n",
      "Epoch: 5, loss = -0.20428281292940179\n",
      "Epoch: 6, loss = -0.32138070153693366\n",
      "Epoch: 7, loss = -0.4469455803434054\n",
      "Epoch: 8, loss = -0.5798526282111803\n",
      "Epoch: 9, loss = -0.717141220966975\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.465469424923261\n",
      "Epoch: 1, loss = 0.406162199874719\n",
      "Epoch: 2, loss = 0.343579555551211\n",
      "Epoch: 3, loss = 0.27582471755643684\n",
      "Epoch: 4, loss = 0.20201577812743682\n",
      "Epoch: 5, loss = 0.12155990737179914\n",
      "Epoch: 6, loss = 0.03371256977940599\n",
      "Epoch: 7, loss = -0.06190962468584378\n",
      "Epoch: 8, loss = -0.1654526752924236\n",
      "Epoch: 9, loss = -0.2762841532627741\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.299437219897906\n",
      "Epoch: 1, loss = 0.2274156678467989\n",
      "Epoch: 2, loss = 0.15182700380682945\n",
      "Epoch: 3, loss = 0.06986413135503729\n",
      "Epoch: 4, loss = -0.018911366661389664\n",
      "Epoch: 5, loss = -0.11500410673518975\n",
      "Epoch: 6, loss = -0.2182859992608428\n",
      "Epoch: 7, loss = -0.32784634952743846\n",
      "Epoch: 8, loss = -0.442084170334662\n",
      "Epoch: 9, loss = -0.5559122400979202\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3746489112575849\n",
      "Epoch: 1, loss = 0.3169469609856605\n",
      "Epoch: 2, loss = 0.2566949625809987\n",
      "Epoch: 3, loss = 0.19208080259462199\n",
      "Epoch: 4, loss = 0.12185365823097527\n",
      "Epoch: 5, loss = 0.04509622960661848\n",
      "Epoch: 6, loss = -0.03889603012551864\n",
      "Epoch: 7, loss = -0.13085687408844632\n",
      "Epoch: 8, loss = -0.23120010131970045\n",
      "Epoch: 9, loss = -0.33987266228844726\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.3058756235986948\n",
      "Epoch: 1, loss = -0.41927047190256417\n",
      "Epoch: 2, loss = -0.5430944571271539\n",
      "Epoch: 3, loss = -0.6531895063817501\n",
      "Epoch: 4, loss = -0.740464149042964\n",
      "Epoch: 5, loss = -0.7385640535503626\n",
      "Epoch: 6, loss = -0.7827182598412037\n",
      "Epoch: 7, loss = -0.8730237185955048\n",
      "Epoch: 8, loss = -0.8555501252412796\n",
      "Epoch: 9, loss = -0.9373042918741703\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.7721632905304432\n",
      "Epoch: 1, loss = -0.8809287957847118\n",
      "Epoch: 2, loss = -1.0184754766523838\n",
      "Epoch: 3, loss = -1.1029966175556183\n",
      "Epoch: 4, loss = -1.1240664385259151\n",
      "Epoch: 5, loss = -1.169747058302164\n",
      "Epoch: 6, loss = -1.1735357716679573\n",
      "Epoch: 7, loss = -0.9612351562827826\n",
      "Epoch: 8, loss = -0.7223183363676071\n",
      "Epoch: 9, loss = -0.38307603634893894\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.31647252081893384\n",
      "Epoch: 1, loss = -0.43655259592924267\n",
      "Epoch: 2, loss = -0.5663136905059218\n",
      "Epoch: 3, loss = -0.6920655127614737\n",
      "Epoch: 4, loss = -0.797476053237915\n",
      "Epoch: 5, loss = -0.8867185413837433\n",
      "Epoch: 6, loss = -1.0495170764625072\n",
      "Epoch: 7, loss = -1.1594678275287151\n",
      "Epoch: 8, loss = -1.2047758102416992\n",
      "Epoch: 9, loss = -1.0030045099556446\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.5957353254780173\n",
      "Epoch: 1, loss = -0.7309909090399742\n",
      "Epoch: 2, loss = -0.8558006025850773\n",
      "Epoch: 3, loss = -0.8674454465508461\n",
      "Epoch: 4, loss = -0.9307308588176966\n",
      "Epoch: 5, loss = -0.6417821161448956\n",
      "Epoch: 6, loss = -0.9420245178043842\n",
      "Epoch: 7, loss = -1.0470571294426918\n",
      "Epoch: 8, loss = -1.0950533859431744\n",
      "Epoch: 9, loss = -1.1390798911452293\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.40293278079479933\n",
      "Epoch: 1, loss = -0.5066622802987695\n",
      "Epoch: 2, loss = -0.6429853569716215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss = -0.771494809538126\n",
      "Epoch: 4, loss = -0.8714142180979252\n",
      "Epoch: 5, loss = -1.0107361860573292\n",
      "Epoch: 6, loss = -1.132780596613884\n",
      "Epoch: 7, loss = -1.1797550208866596\n",
      "Epoch: 8, loss = -1.1114021483808756\n",
      "Epoch: 9, loss = -1.3178188726305962\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.9305411338806154\n",
      "Epoch: 1, loss = -1.0731848239898683\n",
      "Epoch: 2, loss = -1.030782473087311\n",
      "Epoch: 3, loss = -0.8925433039665222\n",
      "Epoch: 4, loss = -0.6699833586812018\n",
      "Epoch: 5, loss = -0.8653724387288092\n",
      "Epoch: 6, loss = -1.1498486965894699\n",
      "Epoch: 7, loss = -1.3047108709812165\n",
      "Epoch: 8, loss = -1.4053036779165269\n",
      "Epoch: 9, loss = -1.4525061130523682\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.0129454553127288\n",
      "Epoch: 1, loss = -1.0368398606777192\n",
      "Epoch: 2, loss = -0.9686664156615733\n",
      "Epoch: 3, loss = -0.881257450580597\n",
      "Epoch: 4, loss = -1.085236692428589\n",
      "Epoch: 5, loss = -1.2992586731910707\n",
      "Epoch: 6, loss = -1.4568484544754028\n",
      "Epoch: 7, loss = -1.4872993767261506\n",
      "Epoch: 8, loss = -1.5199692964553835\n",
      "Epoch: 9, loss = -1.136223077774048\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.2635592758655552\n",
      "Epoch: 1, loss = -1.3999408006668088\n",
      "Epoch: 2, loss = -1.4887347012758259\n",
      "Epoch: 3, loss = -1.5210910171270369\n",
      "Epoch: 4, loss = -1.405549630522728\n",
      "Epoch: 5, loss = -1.2765290766954422\n",
      "Epoch: 6, loss = -1.3633862018585203\n",
      "Epoch: 7, loss = -1.202697305381298\n",
      "Epoch: 8, loss = -1.1241629391908647\n",
      "Epoch: 9, loss = -1.0844300188124179\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.1125028401613235\n",
      "Epoch: 1, loss = -0.7384978085756302\n",
      "Epoch: 2, loss = -0.39914775639772415\n",
      "Epoch: 3, loss = -0.541563056409359\n",
      "Epoch: 4, loss = -0.8920747801661489\n",
      "Epoch: 5, loss = -1.1119128555059432\n",
      "Epoch: 6, loss = -1.2316437602043153\n",
      "Epoch: 7, loss = -1.2860402315855026\n",
      "Epoch: 8, loss = -1.3529564380645756\n",
      "Epoch: 9, loss = -1.392950144410133\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.2526834130287168\n",
      "Epoch: 1, loss = -1.3408980071544647\n",
      "Epoch: 2, loss = -1.2939464047551155\n",
      "Epoch: 3, loss = -1.2694949805736542\n",
      "Epoch: 4, loss = -1.1639717251062391\n",
      "Epoch: 5, loss = -0.9752790600061416\n",
      "Epoch: 6, loss = -0.7831725060939787\n",
      "Epoch: 7, loss = -0.9470196269452572\n",
      "Epoch: 8, loss = -1.2698948651552202\n",
      "Epoch: 9, loss = -1.4406970411539077\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.472419341405233\n",
      "Epoch: 1, loss = -1.4731066450476646\n",
      "Epoch: 2, loss = -1.4166837160785992\n",
      "Epoch: 3, loss = -1.0833134117225807\n",
      "Epoch: 4, loss = -1.0020120237022636\n",
      "Epoch: 5, loss = -0.9600500663121541\n",
      "Epoch: 6, loss = -1.2713783929745357\n",
      "Epoch: 7, loss = -1.4569689681132634\n",
      "Epoch: 8, loss = -1.5504749814669294\n",
      "Epoch: 9, loss = -1.5859146863222124\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.3829108625650406\n",
      "Epoch: 1, loss = -1.4653286437193556\n",
      "Epoch: 2, loss = -1.2674384266138077\n",
      "Epoch: 3, loss = -0.9395861619462571\n",
      "Epoch: 4, loss = -0.6615040665492415\n",
      "Epoch: 5, loss = -1.0041770425935583\n",
      "Epoch: 6, loss = -1.3678353528181713\n",
      "Epoch: 7, loss = -1.4957029670476913\n",
      "Epoch: 8, loss = -1.5768616646528244\n",
      "Epoch: 9, loss = -1.6853763560454051\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.4701369553804395\n",
      "Epoch: 1, loss = -1.5356888075669606\n",
      "Epoch: 2, loss = -1.6163124839464824\n",
      "Epoch: 3, loss = -1.3430694018801053\n",
      "Epoch: 4, loss = -1.3524952431519826\n",
      "Epoch: 5, loss = -1.4200488527615869\n",
      "Epoch: 6, loss = -1.434511472781499\n",
      "Epoch: 7, loss = -1.2763173381487525\n",
      "Epoch: 8, loss = -0.9033373333513736\n",
      "Epoch: 9, loss = -0.47966462684174377\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.3818113182981813\n",
      "Epoch: 1, loss = -1.5069351991017659\n",
      "Epoch: 2, loss = -1.5522656391064327\n",
      "Epoch: 3, loss = -1.325472317636013\n",
      "Epoch: 4, loss = -1.1041079709927242\n",
      "Epoch: 5, loss = -1.384201819698016\n",
      "Epoch: 6, loss = -1.4446789051095643\n",
      "Epoch: 7, loss = -1.5591011047363283\n",
      "Epoch: 8, loss = -1.3689085592826207\n",
      "Epoch: 9, loss = -1.4595970660448074\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.4920490433772404\n",
      "Epoch: 1, loss = -1.6009589930375416\n",
      "Epoch: 2, loss = -1.5350846971074736\n",
      "Epoch: 3, loss = -1.3405144140124319\n",
      "Epoch: 4, loss = -1.6050565540790558\n",
      "Epoch: 5, loss = -1.7143539836009345\n",
      "Epoch: 6, loss = -1.7883912622928615\n",
      "Epoch: 7, loss = -1.7982787539561584\n",
      "Epoch: 8, loss = -1.785800541440646\n",
      "Epoch: 9, loss = -1.6227644483248391\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5106778796762228\n",
      "Epoch: 1, loss = 0.4375646747648716\n",
      "Epoch: 2, loss = 0.3566667325794697\n",
      "Epoch: 3, loss = 0.2649948389735073\n",
      "Epoch: 4, loss = 0.16024895594455302\n",
      "Epoch: 5, loss = 0.040734096663072705\n",
      "Epoch: 6, loss = -0.09446791047230363\n",
      "Epoch: 7, loss = -0.2458417343441397\n",
      "Epoch: 8, loss = -0.40767998760566115\n",
      "Epoch: 9, loss = -0.582311425358057\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.27310554310679436\n",
      "Epoch: 1, loss = 0.17014633282087743\n",
      "Epoch: 2, loss = 0.05387030472047627\n",
      "Epoch: 3, loss = -0.07307526550721377\n",
      "Epoch: 4, loss = -0.2146713025867939\n",
      "Epoch: 5, loss = -0.37033981271088123\n",
      "Epoch: 6, loss = -0.5364410001784563\n",
      "Epoch: 7, loss = -0.7065077237784863\n",
      "Epoch: 8, loss = -0.8727704659104347\n",
      "Epoch: 9, loss = -1.0131463557481766\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48376308009028435\n",
      "Epoch: 1, loss = 0.4117095023393631\n",
      "Epoch: 2, loss = 0.33246288541704416\n",
      "Epoch: 3, loss = 0.24469602829776704\n",
      "Epoch: 4, loss = 0.14492193760816008\n",
      "Epoch: 5, loss = 0.033035984029993415\n",
      "Epoch: 6, loss = -0.09264225279912353\n",
      "Epoch: 7, loss = -0.23151016037445515\n",
      "Epoch: 8, loss = -0.37844235775992274\n",
      "Epoch: 9, loss = -0.525763375684619\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.31051775999367237\n",
      "Epoch: 1, loss = 0.2180161706637591\n",
      "Epoch: 2, loss = 0.11520745197776705\n",
      "Epoch: 3, loss = 0.001962686248589307\n",
      "Epoch: 4, loss = -0.12470523384399712\n",
      "Epoch: 5, loss = -0.26437474085832946\n",
      "Epoch: 6, loss = -0.4180417996831238\n",
      "Epoch: 7, loss = -0.5612113177776337\n",
      "Epoch: 8, loss = -0.6452443934977055\n",
      "Epoch: 9, loss = -0.7069121170789003\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3892520908266306\n",
      "Epoch: 1, loss = 0.31689022947102785\n",
      "Epoch: 2, loss = 0.2389727532863617\n",
      "Epoch: 3, loss = 0.15190467447973788\n",
      "Epoch: 4, loss = 0.053501585382036865\n",
      "Epoch: 5, loss = -0.05757359531708062\n",
      "Epoch: 6, loss = -0.1823149443953298\n",
      "Epoch: 7, loss = -0.3207064541056752\n",
      "Epoch: 8, loss = -0.46864498499780893\n",
      "Epoch: 9, loss = -0.6169440113008022\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.6601554354031882\n",
      "Epoch: 1, loss = -0.8055587100485959\n",
      "Epoch: 2, loss = -0.9301336531837779\n",
      "Epoch: 3, loss = -0.9270127018292745\n",
      "Epoch: 4, loss = -0.8004218979428213\n",
      "Epoch: 5, loss = -0.6970900607605776\n",
      "Epoch: 6, loss = -0.9464396393547455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss = -0.8963977533082167\n",
      "Epoch: 8, loss = -0.9668750700851281\n",
      "Epoch: 9, loss = -0.9999107358356318\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.0028755764166513\n",
      "Epoch: 1, loss = -0.6183266515533129\n",
      "Epoch: 2, loss = -0.10219528774420401\n",
      "Epoch: 3, loss = 0.1695281453430653\n",
      "Epoch: 4, loss = -0.7605884581183395\n",
      "Epoch: 5, loss = -0.9378410850962005\n",
      "Epoch: 6, loss = -1.0636304020881655\n",
      "Epoch: 7, loss = -1.102520008881887\n",
      "Epoch: 8, loss = -1.2082450116674104\n",
      "Epoch: 9, loss = -1.214136891067028\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.6179264516880113\n",
      "Epoch: 1, loss = -0.7918772250413894\n",
      "Epoch: 2, loss = -0.9858254318435989\n",
      "Epoch: 3, loss = -1.0753041754166286\n",
      "Epoch: 4, loss = -1.1338684161504111\n",
      "Epoch: 5, loss = -1.2445627823472023\n",
      "Epoch: 6, loss = -1.3743029509981475\n",
      "Epoch: 7, loss = -1.3504465545217195\n",
      "Epoch: 8, loss = -1.2722436611851053\n",
      "Epoch: 9, loss = -0.9412421273688475\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.5660104677081107\n",
      "Epoch: 1, loss = -0.7271570855130753\n",
      "Epoch: 2, loss = -0.754784777139624\n",
      "Epoch: 3, loss = -0.7162589542567731\n",
      "Epoch: 4, loss = -0.5882694280395904\n",
      "Epoch: 5, loss = -0.4547119121998548\n",
      "Epoch: 6, loss = -0.49291182123124605\n",
      "Epoch: 7, loss = -0.7330666743218899\n",
      "Epoch: 8, loss = -0.9140304774045944\n",
      "Epoch: 9, loss = -1.0243135119477909\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.6875843976934751\n",
      "Epoch: 1, loss = -0.8390641423563162\n",
      "Epoch: 2, loss = -1.037383352716764\n",
      "Epoch: 3, loss = -1.178812774519126\n",
      "Epoch: 4, loss = -1.1426403373479845\n",
      "Epoch: 5, loss = -0.8747185269991556\n",
      "Epoch: 6, loss = -1.1778881922364233\n",
      "Epoch: 7, loss = -1.187547860046228\n",
      "Epoch: 8, loss = -1.0628194113572438\n",
      "Epoch: 9, loss = -0.8550931836167971\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.377731455489993\n",
      "Epoch: 1, loss = -1.5332148801535368\n",
      "Epoch: 2, loss = -1.4237556857988238\n",
      "Epoch: 3, loss = -1.196869257837534\n",
      "Epoch: 4, loss = -1.1719132289290428\n",
      "Epoch: 5, loss = -1.475639559328556\n",
      "Epoch: 6, loss = -1.5658266954123974\n",
      "Epoch: 7, loss = -1.677832044661045\n",
      "Epoch: 8, loss = -1.6008788011968136\n",
      "Epoch: 9, loss = -1.640097200870514\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.3417635522782803\n",
      "Epoch: 1, loss = -1.5665701776742935\n",
      "Epoch: 2, loss = -1.6193489618599415\n",
      "Epoch: 3, loss = -1.5130623821169138\n",
      "Epoch: 4, loss = -1.3808990977704525\n",
      "Epoch: 5, loss = -0.5888834530487657\n",
      "Epoch: 6, loss = -0.5676168035715818\n",
      "Epoch: 7, loss = -0.48500256706029177\n",
      "Epoch: 8, loss = -1.2777391336858273\n",
      "Epoch: 9, loss = -1.5341448858380318\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.1385512659326196\n",
      "Epoch: 1, loss = -1.2867038659751415\n",
      "Epoch: 2, loss = -1.324873408768326\n",
      "Epoch: 3, loss = -1.295830081216991\n",
      "Epoch: 4, loss = -1.2448535226285458\n",
      "Epoch: 5, loss = -1.1639549806714058\n",
      "Epoch: 6, loss = -1.1074611935764551\n",
      "Epoch: 7, loss = -1.1296802563592792\n",
      "Epoch: 8, loss = -1.3326636590063572\n",
      "Epoch: 9, loss = -1.4252558322623372\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.122202942147851\n",
      "Epoch: 1, loss = -1.3195285703986883\n",
      "Epoch: 2, loss = -1.3821353639941663\n",
      "Epoch: 3, loss = -1.3235343070700765\n",
      "Epoch: 4, loss = -1.1060710828751326\n",
      "Epoch: 5, loss = -1.1050290763378143\n",
      "Epoch: 6, loss = -1.308058924973011\n",
      "Epoch: 7, loss = -1.3072447404265404\n",
      "Epoch: 8, loss = -1.31142901442945\n",
      "Epoch: 9, loss = -1.313608887605369\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.8969588242471218\n",
      "Epoch: 1, loss = -1.005863418802619\n",
      "Epoch: 2, loss = -1.1772440765053034\n",
      "Epoch: 3, loss = -1.181600980926305\n",
      "Epoch: 4, loss = -1.3301354330033064\n",
      "Epoch: 5, loss = -1.246619409415871\n",
      "Epoch: 6, loss = -1.3202029396779835\n",
      "Epoch: 7, loss = -1.343534167855978\n",
      "Epoch: 8, loss = -1.4762640632689\n",
      "Epoch: 9, loss = -1.4317313078790903\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.628463798761368\n",
      "Epoch: 1, loss = -1.6794892236590386\n",
      "Epoch: 2, loss = -1.3142122134566305\n",
      "Epoch: 3, loss = -1.681390225887299\n",
      "Epoch: 4, loss = -1.8228020191192629\n",
      "Epoch: 5, loss = -1.8833558320999144\n",
      "Epoch: 6, loss = -1.8640174090862276\n",
      "Epoch: 7, loss = -1.898578459024429\n",
      "Epoch: 8, loss = -1.9015302211046219\n",
      "Epoch: 9, loss = -1.928806284070015\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.6730491548776625\n",
      "Epoch: 1, loss = -1.7813423871994014\n",
      "Epoch: 2, loss = -1.828053167462349\n",
      "Epoch: 3, loss = -1.5385972134768964\n",
      "Epoch: 4, loss = -1.6525946825742726\n",
      "Epoch: 5, loss = -1.69598530754447\n",
      "Epoch: 6, loss = -1.8863171190023427\n",
      "Epoch: 7, loss = -1.9972323596477508\n",
      "Epoch: 8, loss = -2.0880385100841523\n",
      "Epoch: 9, loss = -2.142878568172455\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5011793464422225\n",
      "Epoch: 1, loss = -1.6790975689888\n",
      "Epoch: 2, loss = -1.586666175723076\n",
      "Epoch: 3, loss = -1.5552694767713546\n",
      "Epoch: 4, loss = -1.5737029165029526\n",
      "Epoch: 5, loss = -1.6615564659237865\n",
      "Epoch: 6, loss = -1.8575854152441025\n",
      "Epoch: 7, loss = -1.882245042920113\n",
      "Epoch: 8, loss = -1.791454353928566\n",
      "Epoch: 9, loss = -1.750387173891067\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.5058983683586118\n",
      "Epoch: 1, loss = -1.5253027006983757\n",
      "Epoch: 2, loss = -1.6634543895721436\n",
      "Epoch: 3, loss = -1.4714292109012606\n",
      "Epoch: 4, loss = -1.6426795497536661\n",
      "Epoch: 5, loss = -1.8611462265253067\n",
      "Epoch: 6, loss = -1.8946735918521878\n",
      "Epoch: 7, loss = -1.7744191884994502\n",
      "Epoch: 8, loss = -1.6713482595980163\n",
      "Epoch: 9, loss = -1.5470413237810137\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.5811309754848482\n",
      "Epoch: 1, loss = -1.786104616522789\n",
      "Epoch: 2, loss = -1.8883228987455367\n",
      "Epoch: 3, loss = -1.7933830708265306\n",
      "Epoch: 4, loss = -1.3103793531656265\n",
      "Epoch: 5, loss = -1.3646943584084512\n",
      "Epoch: 6, loss = -1.7957762956619265\n",
      "Epoch: 7, loss = -1.9538829743862147\n",
      "Epoch: 8, loss = -2.00707435309887\n",
      "Epoch: 9, loss = -2.048999750614166\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5279096526404223\n",
      "Epoch: 1, loss = 0.424944581463933\n",
      "Epoch: 2, loss = 0.30084352226306993\n",
      "Epoch: 3, loss = 0.14812675351276994\n",
      "Epoch: 4, loss = -0.03998850472271444\n",
      "Epoch: 5, loss = -0.26840095687657595\n",
      "Epoch: 6, loss = -0.5247837553421656\n",
      "Epoch: 7, loss = -0.754830287148555\n",
      "Epoch: 8, loss = -0.8702047417561213\n",
      "Epoch: 9, loss = -1.2134191592534382\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2714847729851802\n",
      "Epoch: 1, loss = 0.11644310294650494\n",
      "Epoch: 2, loss = -0.06655673197625828\n",
      "Epoch: 3, loss = -0.2825286354248722\n",
      "Epoch: 4, loss = -0.5301409301658472\n",
      "Epoch: 5, loss = -0.7826452863713107\n",
      "Epoch: 6, loss = -1.029792532324791\n",
      "Epoch: 7, loss = -1.2391794696450236\n",
      "Epoch: 8, loss = -1.0444774900873501\n",
      "Epoch: 9, loss = -0.8283834531903267\n",
      "\n",
      "Training model 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = 0.49649380395809817\n",
      "Epoch: 1, loss = 0.39944239954153693\n",
      "Epoch: 2, loss = 0.2793438217292229\n",
      "Epoch: 3, loss = 0.1386466009231905\n",
      "Epoch: 4, loss = -0.03352497869248811\n",
      "Epoch: 5, loss = -0.24055820377543566\n",
      "Epoch: 6, loss = -0.4797610351815819\n",
      "Epoch: 7, loss = -0.7487969311575092\n",
      "Epoch: 8, loss = -0.9961859633525213\n",
      "Epoch: 9, loss = -0.9508015116055806\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.32371673732995987\n",
      "Epoch: 1, loss = 0.1998005538868407\n",
      "Epoch: 2, loss = 0.036350065415414676\n",
      "Epoch: 3, loss = -0.1421635818357269\n",
      "Epoch: 4, loss = -0.33868118096143\n",
      "Epoch: 5, loss = -0.5480796371897061\n",
      "Epoch: 6, loss = -0.7058981694281101\n",
      "Epoch: 7, loss = -0.8557038530707359\n",
      "Epoch: 8, loss = -0.9230166375637054\n",
      "Epoch: 9, loss = -1.0303444787859917\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.392896756529808\n",
      "Epoch: 1, loss = 0.28905452353258926\n",
      "Epoch: 2, loss = 0.16791216070608547\n",
      "Epoch: 3, loss = 0.021945316810160872\n",
      "Epoch: 4, loss = -0.1527775649835045\n",
      "Epoch: 5, loss = -0.35282933091123897\n",
      "Epoch: 6, loss = -0.5583271210392318\n",
      "Epoch: 7, loss = -0.7237035483121871\n",
      "Epoch: 8, loss = -0.8151203918581207\n",
      "Epoch: 9, loss = -0.9501126085718474\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.2308589935302738\n",
      "Epoch: 1, loss = -1.4051823303103446\n",
      "Epoch: 2, loss = -1.5566791653633116\n",
      "Epoch: 3, loss = -1.5287231646478174\n",
      "Epoch: 4, loss = -1.560230292379856\n",
      "Epoch: 5, loss = -1.3487040698528285\n",
      "Epoch: 6, loss = -1.2631035787984732\n",
      "Epoch: 7, loss = -1.0870528753846884\n",
      "Epoch: 8, loss = -1.4997849464416506\n",
      "Epoch: 9, loss = -1.644699442386627\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.7861777547746897\n",
      "Epoch: 1, loss = -0.7313758015632629\n",
      "Epoch: 2, loss = -0.3355761498212814\n",
      "Epoch: 3, loss = -0.27911458611488354\n",
      "Epoch: 4, loss = -0.8729014940559863\n",
      "Epoch: 5, loss = -1.2859276443719865\n",
      "Epoch: 6, loss = -1.3312227860093118\n",
      "Epoch: 7, loss = -1.3931209474802015\n",
      "Epoch: 8, loss = -1.4178089767694473\n",
      "Epoch: 9, loss = -1.5857077419757846\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.0419208064675332\n",
      "Epoch: 1, loss = -1.1869385823607446\n",
      "Epoch: 2, loss = -1.2161321122199296\n",
      "Epoch: 3, loss = -1.2182270973920823\n",
      "Epoch: 4, loss = -1.2301574200391772\n",
      "Epoch: 5, loss = -1.207684470713139\n",
      "Epoch: 6, loss = -1.3032134272158147\n",
      "Epoch: 7, loss = -1.244644762575626\n",
      "Epoch: 8, loss = -1.4179838031530374\n",
      "Epoch: 9, loss = -1.411278323829174\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.0962336450815198\n",
      "Epoch: 1, loss = -0.8876369394361974\n",
      "Epoch: 2, loss = -0.6187513388693334\n",
      "Epoch: 3, loss = -0.8649277895689009\n",
      "Epoch: 4, loss = -0.6804045461118219\n",
      "Epoch: 5, loss = -1.0183419153094293\n",
      "Epoch: 6, loss = -1.1387088321149352\n",
      "Epoch: 7, loss = -1.258287236094475\n",
      "Epoch: 8, loss = -1.375565345585346\n",
      "Epoch: 9, loss = -1.4238196894526478\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.1026953101158141\n",
      "Epoch: 1, loss = -1.035526539385319\n",
      "Epoch: 2, loss = -1.3552165403962138\n",
      "Epoch: 3, loss = -1.4803475141525269\n",
      "Epoch: 4, loss = -1.4123461693525314\n",
      "Epoch: 5, loss = -1.5415764071047302\n",
      "Epoch: 6, loss = -1.4543639335781335\n",
      "Epoch: 7, loss = -1.6846896469593047\n",
      "Epoch: 8, loss = -1.6809263676404949\n",
      "Epoch: 9, loss = -1.7667302936315539\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.6085475449051176\n",
      "Epoch: 1, loss = -1.7495147096259258\n",
      "Epoch: 2, loss = -1.853169615779604\n",
      "Epoch: 3, loss = -1.8245482891798015\n",
      "Epoch: 4, loss = -1.8668630591460638\n",
      "Epoch: 5, loss = -1.906660611076014\n",
      "Epoch: 6, loss = -1.9579953742878775\n",
      "Epoch: 7, loss = -1.9869010778410092\n",
      "Epoch: 8, loss = -1.967356466821261\n",
      "Epoch: 9, loss = -1.9835390661443981\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.710401571222714\n",
      "Epoch: 1, loss = -1.7640903195632356\n",
      "Epoch: 2, loss = -1.6393804539527208\n",
      "Epoch: 3, loss = -1.842400589159557\n",
      "Epoch: 4, loss = -1.7981290564473185\n",
      "Epoch: 5, loss = -1.9658288976975846\n",
      "Epoch: 6, loss = -1.7356532234698536\n",
      "Epoch: 7, loss = -1.9968079839433948\n",
      "Epoch: 8, loss = -2.0484147625310083\n",
      "Epoch: 9, loss = -2.2026917572532385\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5169071459344459\n",
      "Epoch: 1, loss = -1.429932269134692\n",
      "Epoch: 2, loss = -1.6454087937516824\n",
      "Epoch: 3, loss = -1.4279606863856313\n",
      "Epoch: 4, loss = -1.7226826527288983\n",
      "Epoch: 5, loss = -1.653055508221899\n",
      "Epoch: 6, loss = -1.8547084395374573\n",
      "Epoch: 7, loss = -1.6651351537023273\n",
      "Epoch: 8, loss = -1.8978755729539052\n",
      "Epoch: 9, loss = -1.8113131565707075\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.4891112329704421\n",
      "Epoch: 1, loss = -1.5946154264467107\n",
      "Epoch: 2, loss = -1.4843188369912765\n",
      "Epoch: 3, loss = -1.2143551936107022\n",
      "Epoch: 4, loss = -1.5856475819434437\n",
      "Epoch: 5, loss = -1.7422025033405852\n",
      "Epoch: 6, loss = -1.803819796868733\n",
      "Epoch: 7, loss = -1.7973531718764988\n",
      "Epoch: 8, loss = -1.7381549999117851\n",
      "Epoch: 9, loss = -1.971974894404411\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.7947890907526016\n",
      "Epoch: 1, loss = -1.8526901081204417\n",
      "Epoch: 2, loss = -1.713503876168813\n",
      "Epoch: 3, loss = -1.8207571344184026\n",
      "Epoch: 4, loss = -1.612890596900667\n",
      "Epoch: 5, loss = -1.8468194896621362\n",
      "Epoch: 6, loss = -1.8337636558072907\n",
      "Epoch: 7, loss = -1.963783072573798\n",
      "Epoch: 8, loss = -1.9938421291964403\n",
      "Epoch: 9, loss = -2.0344677610056743\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.8434663357006176\n",
      "Epoch: 1, loss = -1.7231379474202795\n",
      "Epoch: 2, loss = -1.9546823021438393\n",
      "Epoch: 3, loss = -1.9316189603673086\n",
      "Epoch: 4, loss = -2.0079286942879357\n",
      "Epoch: 5, loss = -2.0031919926404953\n",
      "Epoch: 6, loss = -2.0453640470902124\n",
      "Epoch: 7, loss = -2.060611953337988\n",
      "Epoch: 8, loss = -2.0903913113805985\n",
      "Epoch: 9, loss = -2.1165093150403766\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.861103650596407\n",
      "Epoch: 1, loss = -1.8653733498520315\n",
      "Epoch: 2, loss = -2.166179441743427\n",
      "Epoch: 3, loss = -2.2488361779186463\n",
      "Epoch: 4, loss = -2.244701282845604\n",
      "Epoch: 5, loss = -2.295996227198177\n",
      "Epoch: 6, loss = -2.307629673017395\n",
      "Epoch: 7, loss = -2.3340601589944634\n",
      "Epoch: 8, loss = -2.3132450216346307\n",
      "Epoch: 9, loss = -2.3756061262554593\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.7326358196636038\n",
      "Epoch: 1, loss = -1.7749684295720531\n",
      "Epoch: 2, loss = -1.617816197996338\n",
      "Epoch: 3, loss = -1.9280999600887299\n",
      "Epoch: 4, loss = -1.9582007245885007\n",
      "Epoch: 5, loss = -1.9333289215962088\n",
      "Epoch: 6, loss = -1.926384369532267\n",
      "Epoch: 7, loss = -1.8967145490977504\n",
      "Epoch: 8, loss = -2.00336513419946\n",
      "Epoch: 9, loss = -2.1090569827291707\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.8101179516977735\n",
      "Epoch: 1, loss = -1.4709880467918186\n",
      "Epoch: 2, loss = -1.866574944721328\n",
      "Epoch: 3, loss = -1.876617507802116\n",
      "Epoch: 4, loss = -1.8841698666413622\n",
      "Epoch: 5, loss = -1.8859944302174776\n",
      "Epoch: 6, loss = -1.9550208573540049\n",
      "Epoch: 7, loss = -1.9759911000728612\n",
      "Epoch: 8, loss = -2.0120880777637162\n",
      "Epoch: 9, loss = -2.073653204573525\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.916273080226448\n",
      "Epoch: 1, loss = -1.9113071271114879\n",
      "Epoch: 2, loss = -1.95431070195304\n",
      "Epoch: 3, loss = -1.983712572190497\n",
      "Epoch: 4, loss = -2.02723710735639\n",
      "Epoch: 5, loss = -2.0779284950759678\n",
      "Epoch: 6, loss = -2.105062819189495\n",
      "Epoch: 7, loss = -2.1494675394561558\n",
      "Epoch: 8, loss = -2.186338245868683\n",
      "Epoch: 9, loss = -2.234097345007791\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5206146620213986\n",
      "Epoch: 1, loss = 0.3379261126741767\n",
      "Epoch: 2, loss = 0.07400590016040952\n",
      "Epoch: 3, loss = -0.30549905709922315\n",
      "Epoch: 4, loss = -0.7933594092726709\n",
      "Epoch: 5, loss = -1.2305168122053147\n",
      "Epoch: 6, loss = -1.4105999082326892\n",
      "Epoch: 7, loss = -1.4613378774374723\n",
      "Epoch: 8, loss = -1.4742617130279538\n",
      "Epoch: 9, loss = -1.5833266302943232\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.23289720639586453\n",
      "Epoch: 1, loss = -0.05744918233831413\n",
      "Epoch: 2, loss = -0.4460001349449158\n",
      "Epoch: 3, loss = -0.8058970645070078\n",
      "Epoch: 4, loss = -0.40749456062912953\n",
      "Epoch: 5, loss = -0.7252522051334381\n",
      "Epoch: 6, loss = -1.0184278830885887\n",
      "Epoch: 7, loss = -1.1560992881655694\n",
      "Epoch: 8, loss = -1.3927916884422302\n",
      "Epoch: 9, loss = -1.5364632576704027\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.4871088437736034\n",
      "Epoch: 1, loss = 0.31945007443428025\n",
      "Epoch: 2, loss = 0.07759700119495393\n",
      "Epoch: 3, loss = -0.2540544902905822\n",
      "Epoch: 4, loss = -0.6834370963275435\n",
      "Epoch: 5, loss = -1.119787259399891\n",
      "Epoch: 6, loss = -1.3908105999231337\n",
      "Epoch: 7, loss = -1.2306237675249576\n",
      "Epoch: 8, loss = -1.1738557457923888\n",
      "Epoch: 9, loss = -1.4173443131148813\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.2943101517856121\n",
      "Epoch: 1, loss = 0.07826153347268701\n",
      "Epoch: 2, loss = -0.2106117037124932\n",
      "Epoch: 3, loss = -0.4863255009055137\n",
      "Epoch: 4, loss = -0.7592290397733448\n",
      "Epoch: 5, loss = -1.0234767585992814\n",
      "Epoch: 6, loss = -1.1986715719103809\n",
      "Epoch: 7, loss = -1.2892988242208958\n",
      "Epoch: 8, loss = -1.368520860373974\n",
      "Epoch: 9, loss = -1.3922772981226448\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.37677396982908257\n",
      "Epoch: 1, loss = 0.19173124618828302\n",
      "Epoch: 2, loss = -0.06702102883718908\n",
      "Epoch: 3, loss = -0.4118320457637309\n",
      "Epoch: 4, loss = -0.7189223736524581\n",
      "Epoch: 5, loss = -1.0006328880786897\n",
      "Epoch: 6, loss = -0.9848042659461497\n",
      "Epoch: 7, loss = -1.201199521124363\n",
      "Epoch: 8, loss = -1.2164227060973642\n",
      "Epoch: 9, loss = -1.1644436575472352\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.5251668108006318\n",
      "Epoch: 1, loss = -1.6336121563282269\n",
      "Epoch: 2, loss = -1.66934916542636\n",
      "Epoch: 3, loss = -1.6594870040814083\n",
      "Epoch: 4, loss = -1.776947794689072\n",
      "Epoch: 5, loss = -1.6520306910905573\n",
      "Epoch: 6, loss = -1.8511536187595785\n",
      "Epoch: 7, loss = -1.7415524870157242\n",
      "Epoch: 8, loss = -1.9317699488666318\n",
      "Epoch: 9, loss = -1.796849561234315\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.2221199745933218\n",
      "Epoch: 1, loss = -1.328735451524456\n",
      "Epoch: 2, loss = -1.637525185528728\n",
      "Epoch: 3, loss = -1.7563728673590555\n",
      "Epoch: 4, loss = -1.7083739675581455\n",
      "Epoch: 5, loss = -1.7708058305498635\n",
      "Epoch: 6, loss = -1.9090020209550858\n",
      "Epoch: 7, loss = -1.836508046835661\n",
      "Epoch: 8, loss = -1.9158792495727544\n",
      "Epoch: 9, loss = -2.0009857097433676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.223916318267584\n",
      "Epoch: 1, loss = -1.2240885036687061\n",
      "Epoch: 2, loss = -1.320417120017939\n",
      "Epoch: 3, loss = -1.385274748214417\n",
      "Epoch: 4, loss = -1.5280278536180656\n",
      "Epoch: 5, loss = -1.5237505758802097\n",
      "Epoch: 6, loss = -1.5659441459510057\n",
      "Epoch: 7, loss = -1.6549494490027428\n",
      "Epoch: 8, loss = -1.7018230391873252\n",
      "Epoch: 9, loss = -1.7825254574418063\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.8956154154406657\n",
      "Epoch: 1, loss = -1.1740056876507068\n",
      "Epoch: 2, loss = -1.37156416165332\n",
      "Epoch: 3, loss = -1.44970698778828\n",
      "Epoch: 4, loss = -1.5159838803940346\n",
      "Epoch: 5, loss = -1.5707441949182095\n",
      "Epoch: 6, loss = -1.6253330575095282\n",
      "Epoch: 7, loss = -1.6694699741072125\n",
      "Epoch: 8, loss = -1.7077611523369949\n",
      "Epoch: 9, loss = -1.7513255795670877\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.1203440725803375\n",
      "Epoch: 1, loss = -1.446875957979096\n",
      "Epoch: 2, loss = -1.5333408754732871\n",
      "Epoch: 3, loss = -1.6837781837417025\n",
      "Epoch: 4, loss = -1.6774338579012291\n",
      "Epoch: 5, loss = -1.8314679091175403\n",
      "Epoch: 6, loss = -1.7150306469864316\n",
      "Epoch: 7, loss = -1.935979415145186\n",
      "Epoch: 8, loss = -1.877111452735133\n",
      "Epoch: 9, loss = -2.04747609835532\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.831800315242547\n",
      "Epoch: 1, loss = -1.9496704658063555\n",
      "Epoch: 2, loss = -1.9265807958749628\n",
      "Epoch: 3, loss = -2.046533182263374\n",
      "Epoch: 4, loss = -2.0391216358313202\n",
      "Epoch: 5, loss = -2.0896407079238153\n",
      "Epoch: 6, loss = -2.1319843364449653\n",
      "Epoch: 7, loss = -2.1754345068564787\n",
      "Epoch: 8, loss = -2.223266340219058\n",
      "Epoch: 9, loss = -2.2645947692485953\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -2.000316537343539\n",
      "Epoch: 1, loss = -1.9275247440315215\n",
      "Epoch: 2, loss = -2.114837841345713\n",
      "Epoch: 3, loss = -2.1099261910869527\n",
      "Epoch: 4, loss = -2.1628732417638488\n",
      "Epoch: 5, loss = -2.20896180661825\n",
      "Epoch: 6, loss = -2.247258483217313\n",
      "Epoch: 7, loss = -2.2900486748952122\n",
      "Epoch: 8, loss = -2.337743263978225\n",
      "Epoch: 9, loss = -2.398089436957469\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.6843008586707013\n",
      "Epoch: 1, loss = -1.899312547479684\n",
      "Epoch: 2, loss = -1.9490764711338748\n",
      "Epoch: 3, loss = -2.052106268703938\n",
      "Epoch: 4, loss = -2.079786760875812\n",
      "Epoch: 5, loss = -2.11240111807218\n",
      "Epoch: 6, loss = -2.156823521336684\n",
      "Epoch: 7, loss = -2.1916790876824117\n",
      "Epoch: 8, loss = -2.2244798237314587\n",
      "Epoch: 9, loss = -2.2590489708460297\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.7383636249086036\n",
      "Epoch: 1, loss = -1.8532672785222528\n",
      "Epoch: 2, loss = -1.9329946416501818\n",
      "Epoch: 3, loss = -2.0002140858425546\n",
      "Epoch: 4, loss = -2.062634895627315\n",
      "Epoch: 5, loss = -2.121638618982756\n",
      "Epoch: 6, loss = -2.1673882787044225\n",
      "Epoch: 7, loss = -2.220724433087386\n",
      "Epoch: 8, loss = -2.2759714267001705\n",
      "Epoch: 9, loss = -2.3170609835248737\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.0708130580874586\n",
      "Epoch: 1, loss = -1.9659076419014192\n",
      "Epoch: 2, loss = -2.107026829312627\n",
      "Epoch: 3, loss = -2.1217433404750548\n",
      "Epoch: 4, loss = -2.206632846823105\n",
      "Epoch: 5, loss = -2.2271428821751713\n",
      "Epoch: 6, loss = -2.3197344335225907\n",
      "Epoch: 7, loss = -2.3964469467218112\n",
      "Epoch: 8, loss = -2.4307748572184495\n",
      "Epoch: 9, loss = -2.43591917019624\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -2.2189566764761435\n",
      "Epoch: 1, loss = -2.257606824531274\n",
      "Epoch: 2, loss = -2.2979962010593966\n",
      "Epoch: 3, loss = -2.3451336332980324\n",
      "Epoch: 4, loss = -2.389067996074171\n",
      "Epoch: 5, loss = -2.4233183054363026\n",
      "Epoch: 6, loss = -2.4676205770057793\n",
      "Epoch: 7, loss = -2.509862889261808\n",
      "Epoch: 8, loss = -2.5541928857564917\n",
      "Epoch: 9, loss = -2.602462091866662\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -2.468883613453192\n",
      "Epoch: 1, loss = -2.134289942243519\n",
      "Epoch: 2, loss = -2.5353682216475995\n",
      "Epoch: 3, loss = -2.5764809522558663\n",
      "Epoch: 4, loss = -2.6474951943930436\n",
      "Epoch: 5, loss = -2.7274130924659623\n",
      "Epoch: 6, loss = -2.7603959371061886\n",
      "Epoch: 7, loss = -2.8246766556711758\n",
      "Epoch: 8, loss = -2.85828417890212\n",
      "Epoch: 9, loss = -2.90044307007509\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -2.2627785999108747\n",
      "Epoch: 1, loss = -2.3406234925941503\n",
      "Epoch: 2, loss = -2.3986459356897014\n",
      "Epoch: 3, loss = -2.472331594894914\n",
      "Epoch: 4, loss = -2.536599827163361\n",
      "Epoch: 5, loss = -2.595619298079436\n",
      "Epoch: 6, loss = -2.6507965519147767\n",
      "Epoch: 7, loss = -2.703558678136151\n",
      "Epoch: 8, loss = -2.7475628239267014\n",
      "Epoch: 9, loss = -2.793942600488662\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -2.3021643621956605\n",
      "Epoch: 1, loss = -2.268084073548807\n",
      "Epoch: 2, loss = -2.375409475144219\n",
      "Epoch: 3, loss = -2.4571061309646156\n",
      "Epoch: 4, loss = -2.5197976457283793\n",
      "Epoch: 5, loss = -2.5681910107240955\n",
      "Epoch: 6, loss = -2.620109023416744\n",
      "Epoch: 7, loss = -2.668194572715199\n",
      "Epoch: 8, loss = -2.7086180799147663\n",
      "Epoch: 9, loss = -2.7593826252747986\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.4837520078701134\n",
      "Epoch: 1, loss = -2.5700747721335464\n",
      "Epoch: 2, loss = -2.6093258358099876\n",
      "Epoch: 3, loss = -2.649551230318405\n",
      "Epoch: 4, loss = -2.6916285201030616\n",
      "Epoch: 5, loss = -2.7328262416755447\n",
      "Epoch: 6, loss = -2.765599970431888\n",
      "Epoch: 7, loss = -2.795945113196094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss = -2.8342818573993798\n",
      "Epoch: 9, loss = -2.8784192467437073\n"
     ]
    }
   ],
   "source": [
    "errors_al = with_al(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749a86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_err_plot(frac_err_baseline,frac_err_AL_ens):\n",
    "    \n",
    "    K_train_list = [16, 32, 64, 128, 256, 512]  # make it global\n",
    "    ninit =128\n",
    "    T=4\n",
    "    N_train_list = ninit + T * np.array(K_train_list)\n",
    "    plt.style.use(\"classic\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(N_train_list,frac_err_baseline, \".-\", label=\"Baseline\")\n",
    "    plt.plot(N_train_list,frac_err_AL_ens, \".-\", label=\"Active learning, ensemble\")\n",
    "    plt.ylabel('Fractional error on test set')\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf8aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_err_plot(errors_baseline,errors_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba49c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b39ef66b",
   "metadata": {},
   "source": [
    "## Part 2 save the weights to make predictions on the unseen data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc1d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8344416245818138\n",
      "Epoch: 1, loss = 0.7974907830357552\n",
      "Epoch: 2, loss = 0.7642046883702278\n",
      "Epoch: 3, loss = 0.7311419323086739\n",
      "Epoch: 4, loss = 0.6972347423434258\n",
      "Epoch: 5, loss = 0.6621711403131485\n",
      "Epoch: 6, loss = 0.6250587925314903\n",
      "Epoch: 7, loss = 0.5853038504719734\n",
      "Epoch: 8, loss = 0.5423849634826183\n",
      "Epoch: 9, loss = 0.4958737939596176\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7736414968967438\n",
      "Epoch: 1, loss = 0.7150424495339394\n",
      "Epoch: 2, loss = 0.6651066765189171\n",
      "Epoch: 3, loss = 0.6177576035261154\n",
      "Epoch: 4, loss = 0.5691270306706429\n",
      "Epoch: 5, loss = 0.5189583599567413\n",
      "Epoch: 6, loss = 0.4671752266585827\n",
      "Epoch: 7, loss = 0.41288335993885994\n",
      "Epoch: 8, loss = 0.355633269995451\n",
      "Epoch: 9, loss = 0.29482607915997505\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.807803139090538\n",
      "Epoch: 1, loss = 0.7767249867320061\n",
      "Epoch: 2, loss = 0.7454440221190453\n",
      "Epoch: 3, loss = 0.7131995260715485\n",
      "Epoch: 4, loss = 0.6794783547520638\n",
      "Epoch: 5, loss = 0.6438019871711731\n",
      "Epoch: 6, loss = 0.6057177484035492\n",
      "Epoch: 7, loss = 0.5647127330303192\n",
      "Epoch: 8, loss = 0.5202970057725906\n",
      "Epoch: 9, loss = 0.4719347506761551\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7300005555152893\n",
      "Epoch: 1, loss = 0.6836096346378326\n",
      "Epoch: 2, loss = 0.6413294970989227\n",
      "Epoch: 3, loss = 0.5997105091810226\n",
      "Epoch: 4, loss = 0.557178795337677\n",
      "Epoch: 5, loss = 0.5134793445467949\n",
      "Epoch: 6, loss = 0.4680880345404148\n",
      "Epoch: 7, loss = 0.4202974699437618\n",
      "Epoch: 8, loss = 0.36940673366189003\n",
      "Epoch: 9, loss = 0.3150567561388016\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.73338932543993\n",
      "Epoch: 1, loss = 0.6987508237361908\n",
      "Epoch: 2, loss = 0.6643062233924866\n",
      "Epoch: 3, loss = 0.6292145848274231\n",
      "Epoch: 4, loss = 0.5930988490581512\n",
      "Epoch: 5, loss = 0.5556176230311394\n",
      "Epoch: 6, loss = 0.5164519399404526\n",
      "Epoch: 7, loss = 0.4752686806023121\n",
      "Epoch: 8, loss = 0.4317913390696049\n",
      "Epoch: 9, loss = 0.38566718250513077\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4635593063301511\n",
      "Epoch: 1, loss = 0.41496842768457204\n",
      "Epoch: 2, loss = 0.3640258378452724\n",
      "Epoch: 3, loss = 0.30970504383246106\n",
      "Epoch: 4, loss = 0.251527313556936\n",
      "Epoch: 5, loss = 0.18896440789103508\n",
      "Epoch: 6, loss = 0.12166911198033226\n",
      "Epoch: 7, loss = 0.04938091782646047\n",
      "Epoch: 8, loss = -0.02821777471237713\n",
      "Epoch: 9, loss = -0.11088917031884193\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2399344013796912\n",
      "Epoch: 1, loss = 0.17415515250629848\n",
      "Epoch: 2, loss = 0.10545694972905847\n",
      "Epoch: 3, loss = 0.033193146602975\n",
      "Epoch: 4, loss = -0.043537216261029237\n",
      "Epoch: 5, loss = -0.12473154792355166\n",
      "Epoch: 6, loss = -0.21116480314069325\n",
      "Epoch: 7, loss = -0.3026941153738234\n",
      "Epoch: 8, loss = -0.39950910872883266\n",
      "Epoch: 9, loss = -0.5016251371966468\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.43416361014048255\n",
      "Epoch: 1, loss = 0.38395483626259697\n",
      "Epoch: 2, loss = 0.3315184977319506\n",
      "Epoch: 3, loss = 0.27589492499828344\n",
      "Epoch: 4, loss = 0.21673651039600372\n",
      "Epoch: 5, loss = 0.15353365035520655\n",
      "Epoch: 6, loss = 0.0860797990527418\n",
      "Epoch: 7, loss = 0.01397553469157881\n",
      "Epoch: 8, loss = -0.06309952338536579\n",
      "Epoch: 9, loss = -0.14518752445777255\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.27208062012990314\n",
      "Epoch: 1, loss = 0.21425792409314048\n",
      "Epoch: 2, loss = 0.15490200701687074\n",
      "Epoch: 3, loss = 0.09154873734547034\n",
      "Epoch: 4, loss = 0.02466463545958201\n",
      "Epoch: 5, loss = -0.04676134139299393\n",
      "Epoch: 6, loss = -0.12252073176205157\n",
      "Epoch: 7, loss = -0.20266267905632657\n",
      "Epoch: 8, loss = -0.28704261945353615\n",
      "Epoch: 9, loss = -0.3758997139003542\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3486979537540012\n",
      "Epoch: 1, loss = 0.30070258842574227\n",
      "Epoch: 2, loss = 0.2511765940321816\n",
      "Epoch: 3, loss = 0.19922107954819995\n",
      "Epoch: 4, loss = 0.14433149703674844\n",
      "Epoch: 5, loss = 0.08593457668191858\n",
      "Epoch: 6, loss = 0.023604570577541985\n",
      "Epoch: 7, loss = -0.043133086110982634\n",
      "Epoch: 8, loss = -0.11459688883688714\n",
      "Epoch: 9, loss = -0.19118318582574526\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.16871007345616817\n",
      "Epoch: 1, loss = -0.24966636300086975\n",
      "Epoch: 2, loss = -0.33082264587283133\n",
      "Epoch: 3, loss = -0.4188434101641178\n",
      "Epoch: 4, loss = -0.5030308872461319\n",
      "Epoch: 5, loss = -0.5794428437948227\n",
      "Epoch: 6, loss = -0.6670791983604432\n",
      "Epoch: 7, loss = -0.7606742948293685\n",
      "Epoch: 8, loss = -0.8377457588911055\n",
      "Epoch: 9, loss = -0.8857958674430848\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.5668035089969635\n",
      "Epoch: 1, loss = -0.6672838747501373\n",
      "Epoch: 2, loss = -0.7676237344741821\n",
      "Epoch: 3, loss = -0.8710167646408081\n",
      "Epoch: 4, loss = -0.9763156235218047\n",
      "Epoch: 5, loss = -1.0815558075904845\n",
      "Epoch: 6, loss = -1.1882278144359588\n",
      "Epoch: 7, loss = -1.2948479890823363\n",
      "Epoch: 8, loss = -1.3971078813076017\n",
      "Epoch: 9, loss = -1.4914939641952514\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.19792136624455453\n",
      "Epoch: 1, loss = -0.2800671968609094\n",
      "Epoch: 2, loss = -0.36571337059140213\n",
      "Epoch: 3, loss = -0.45353507995605463\n",
      "Epoch: 4, loss = -0.5444744765758515\n",
      "Epoch: 5, loss = -0.6384782910346986\n",
      "Epoch: 6, loss = -0.7337072610855102\n",
      "Epoch: 7, loss = -0.8277075409889221\n",
      "Epoch: 8, loss = -0.9158306896686554\n",
      "Epoch: 9, loss = -0.994474071264267\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.42708277702331543\n",
      "Epoch: 1, loss = -0.5138442099094391\n",
      "Epoch: 2, loss = -0.6074847966432572\n",
      "Epoch: 3, loss = -0.6948028624057769\n",
      "Epoch: 4, loss = -0.7699132680892944\n",
      "Epoch: 5, loss = -0.8710964143276215\n",
      "Epoch: 6, loss = -0.967941665649414\n",
      "Epoch: 7, loss = -1.0558598160743713\n",
      "Epoch: 8, loss = -1.0888164997100829\n",
      "Epoch: 9, loss = -0.7381678193807603\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.24110266510397196\n",
      "Epoch: 1, loss = -0.31773920506238934\n",
      "Epoch: 2, loss = -0.39922129213809965\n",
      "Epoch: 3, loss = -0.4829373598098755\n",
      "Epoch: 4, loss = -0.5712851107120513\n",
      "Epoch: 5, loss = -0.664307874441147\n",
      "Epoch: 6, loss = -0.7599267333745957\n",
      "Epoch: 7, loss = -0.8569386541843415\n",
      "Epoch: 8, loss = -0.9565378189086914\n",
      "Epoch: 9, loss = -1.0563571155071259\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.9207964051853526\n",
      "Epoch: 1, loss = -0.9729787707328797\n",
      "Epoch: 2, loss = -1.004054383798079\n",
      "Epoch: 3, loss = -1.1095001697540283\n",
      "Epoch: 4, loss = -1.1405068039894104\n",
      "Epoch: 5, loss = -1.2366575869646939\n",
      "Epoch: 6, loss = -1.3041689233346418\n",
      "Epoch: 7, loss = -1.3208531087095088\n",
      "Epoch: 8, loss = -1.2284149256619539\n",
      "Epoch: 9, loss = -1.3863400708545337\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.4992320104078813\n",
      "Epoch: 1, loss = -1.5848991220647637\n",
      "Epoch: 2, loss = -1.6571738611568103\n",
      "Epoch: 3, loss = -1.724781946702437\n",
      "Epoch: 4, loss = -1.7032720392400569\n",
      "Epoch: 5, loss = -1.5214537165381694\n",
      "Epoch: 6, loss = -1.7839559208263052\n",
      "Epoch: 7, loss = -1.7263357422568582\n",
      "Epoch: 8, loss = -1.9003835699775002\n",
      "Epoch: 9, loss = -1.8833609169179744\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.017719729380174\n",
      "Epoch: 1, loss = -1.0936091921546243\n",
      "Epoch: 2, loss = -1.1996327476067976\n",
      "Epoch: 3, loss = -1.282901558009061\n",
      "Epoch: 4, loss = -1.330936312675476\n",
      "Epoch: 5, loss = -1.2783047394319014\n",
      "Epoch: 6, loss = -1.451420074159449\n",
      "Epoch: 7, loss = -1.5195374543016607\n",
      "Epoch: 8, loss = -1.584772678938779\n",
      "Epoch: 9, loss = -1.5534423806450584\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.1575197848406704\n",
      "Epoch: 1, loss = -1.2421616749329998\n",
      "Epoch: 2, loss = -1.22117587111213\n",
      "Epoch: 3, loss = -1.2122136787934739\n",
      "Epoch: 4, loss = -1.175808397206393\n",
      "Epoch: 5, loss = -1.3001880103891545\n",
      "Epoch: 6, loss = -1.4454681981693616\n",
      "Epoch: 7, loss = -1.487798636609858\n",
      "Epoch: 8, loss = -1.461877302689986\n",
      "Epoch: 9, loss = -1.5982901291413742\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.0967332504012366\n",
      "Epoch: 1, loss = -1.193007761781866\n",
      "Epoch: 2, loss = -1.2817932692441072\n",
      "Epoch: 3, loss = -1.3493843891403892\n",
      "Epoch: 4, loss = -1.4217576980590818\n",
      "Epoch: 5, loss = -1.4969872344623913\n",
      "Epoch: 6, loss = -1.5562160394408486\n",
      "Epoch: 7, loss = -1.5871902379122649\n",
      "Epoch: 8, loss = -1.6484553272073916\n",
      "Epoch: 9, loss = -1.7530664964155716\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.367286498347918\n",
      "Epoch: 1, loss = -1.439305916428566\n",
      "Epoch: 2, loss = -1.4363181591033936\n",
      "Epoch: 3, loss = -1.488239695628484\n",
      "Epoch: 4, loss = -1.4415686031182606\n",
      "Epoch: 5, loss = -1.4791465898354845\n",
      "Epoch: 6, loss = -1.386013587315877\n",
      "Epoch: 7, loss = -1.391787980993589\n",
      "Epoch: 8, loss = -1.172506369650364\n",
      "Epoch: 9, loss = -0.8962338541944821\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.8511219720045724\n",
      "Epoch: 1, loss = -1.9167125324408212\n",
      "Epoch: 2, loss = -1.9850128094355262\n",
      "Epoch: 3, loss = -1.873079111178716\n",
      "Epoch: 4, loss = -1.7555571496486662\n",
      "Epoch: 5, loss = -1.8931968907515209\n",
      "Epoch: 6, loss = -1.7636443972587585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss = -1.9556300938129425\n",
      "Epoch: 8, loss = -2.0335583190123243\n",
      "Epoch: 9, loss = -2.0741897920767465\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5284046580394108\n",
      "Epoch: 1, loss = -1.5735684235890708\n",
      "Epoch: 2, loss = -1.6747030913829803\n",
      "Epoch: 3, loss = -1.7406587203343706\n",
      "Epoch: 4, loss = -1.7622078160444894\n",
      "Epoch: 5, loss = -1.6771304706732433\n",
      "Epoch: 6, loss = -1.442042628924052\n",
      "Epoch: 7, loss = -1.658596048752467\n",
      "Epoch: 8, loss = -1.492231920361519\n",
      "Epoch: 9, loss = -1.5455191632111869\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.4070620338122048\n",
      "Epoch: 1, loss = -1.430319428443909\n",
      "Epoch: 2, loss = -1.1363088823854923\n",
      "Epoch: 3, loss = -1.2790035754442215\n",
      "Epoch: 4, loss = -1.2426727364460628\n",
      "Epoch: 5, loss = -1.291507214307785\n",
      "Epoch: 6, loss = -1.3437020778656004\n",
      "Epoch: 7, loss = -1.4412337442239125\n",
      "Epoch: 8, loss = -1.5379763940970104\n",
      "Epoch: 9, loss = -1.5942226747671762\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.7317940096060436\n",
      "Epoch: 1, loss = -1.781889299551646\n",
      "Epoch: 2, loss = -1.642958124478658\n",
      "Epoch: 3, loss = -1.7291936675707498\n",
      "Epoch: 4, loss = -1.7087308565775552\n",
      "Epoch: 5, loss = -1.8470199704170225\n",
      "Epoch: 6, loss = -1.8328049778938291\n",
      "Epoch: 7, loss = -1.9330613911151888\n",
      "Epoch: 8, loss = -1.9552310307820637\n",
      "Epoch: 9, loss = -1.9577795167764027\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7930283322930336\n",
      "Epoch: 1, loss = 0.7523109391331673\n",
      "Epoch: 2, loss = 0.7144019827246666\n",
      "Epoch: 3, loss = 0.6773763746023178\n",
      "Epoch: 4, loss = 0.6399806141853333\n",
      "Epoch: 5, loss = 0.6012193784117699\n",
      "Epoch: 6, loss = 0.5603281557559967\n",
      "Epoch: 7, loss = 0.5166700109839439\n",
      "Epoch: 8, loss = 0.46976394951343536\n",
      "Epoch: 9, loss = 0.4192032963037491\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.8313609808683395\n",
      "Epoch: 1, loss = 0.7619078308343887\n",
      "Epoch: 2, loss = 0.704172782599926\n",
      "Epoch: 3, loss = 0.653107076883316\n",
      "Epoch: 4, loss = 0.6046323701739311\n",
      "Epoch: 5, loss = 0.556377574801445\n",
      "Epoch: 6, loss = 0.5065088123083115\n",
      "Epoch: 7, loss = 0.45380761101841927\n",
      "Epoch: 8, loss = 0.397946335375309\n",
      "Epoch: 9, loss = 0.3385269083082676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8141471296548843\n",
      "Epoch: 1, loss = 0.7787958979606628\n",
      "Epoch: 2, loss = 0.7446495071053505\n",
      "Epoch: 3, loss = 0.7103998884558678\n",
      "Epoch: 4, loss = 0.675416387617588\n",
      "Epoch: 5, loss = 0.6392217725515366\n",
      "Epoch: 6, loss = 0.6013956069946289\n",
      "Epoch: 7, loss = 0.5614079907536507\n",
      "Epoch: 8, loss = 0.5187893062829971\n",
      "Epoch: 9, loss = 0.4730595424771309\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7053331956267357\n",
      "Epoch: 1, loss = 0.6636583507061005\n",
      "Epoch: 2, loss = 0.6224204152822495\n",
      "Epoch: 3, loss = 0.5798479616641998\n",
      "Epoch: 4, loss = 0.535397220402956\n",
      "Epoch: 5, loss = 0.4886329509317875\n",
      "Epoch: 6, loss = 0.43916021287441254\n",
      "Epoch: 7, loss = 0.38655776903033257\n",
      "Epoch: 8, loss = 0.33041018806397915\n",
      "Epoch: 9, loss = 0.2702309973537922\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7818650752305984\n",
      "Epoch: 1, loss = 0.7420015409588814\n",
      "Epoch: 2, loss = 0.7046777978539467\n",
      "Epoch: 3, loss = 0.6686465293169022\n",
      "Epoch: 4, loss = 0.6327197402715683\n",
      "Epoch: 5, loss = 0.5960599407553673\n",
      "Epoch: 6, loss = 0.5581148713827133\n",
      "Epoch: 7, loss = 0.5184247605502605\n",
      "Epoch: 8, loss = 0.4766390211880207\n",
      "Epoch: 9, loss = 0.4324333593249321\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.3933301359415054\n",
      "Epoch: 1, loss = 0.3376535832881927\n",
      "Epoch: 2, loss = 0.2791505761444569\n",
      "Epoch: 3, loss = 0.21648096367716788\n",
      "Epoch: 4, loss = 0.14914681129157542\n",
      "Epoch: 5, loss = 0.07657971759326755\n",
      "Epoch: 6, loss = -0.0017475536093115758\n",
      "Epoch: 7, loss = -0.08597492575645446\n",
      "Epoch: 8, loss = -0.17678331993520258\n",
      "Epoch: 9, loss = -0.2732225056737661\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2930486336350441\n",
      "Epoch: 1, loss = 0.22307113856077196\n",
      "Epoch: 2, loss = 0.14996836744248868\n",
      "Epoch: 3, loss = 0.07203182689845562\n",
      "Epoch: 4, loss = -0.011267202813178301\n",
      "Epoch: 5, loss = -0.10046557653695345\n",
      "Epoch: 6, loss = -0.19589377418160442\n",
      "Epoch: 7, loss = -0.2976281940937042\n",
      "Epoch: 8, loss = -0.4056595623493195\n",
      "Epoch: 9, loss = -0.5197190403938293\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.4476247191429138\n",
      "Epoch: 1, loss = 0.3962682545185089\n",
      "Epoch: 2, loss = 0.34293072968721394\n",
      "Epoch: 3, loss = 0.2859687902033329\n",
      "Epoch: 4, loss = 0.22487202137708664\n",
      "Epoch: 5, loss = 0.15905039496719836\n",
      "Epoch: 6, loss = 0.08801043331623076\n",
      "Epoch: 7, loss = 0.011365124769508836\n",
      "Epoch: 8, loss = -0.07137095257639885\n",
      "Epoch: 9, loss = -0.16058099549263719\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.24818410426378246\n",
      "Epoch: 1, loss = 0.1820767743512988\n",
      "Epoch: 2, loss = 0.11299889460206032\n",
      "Epoch: 3, loss = 0.039820611663162704\n",
      "Epoch: 4, loss = -0.03866085931658744\n",
      "Epoch: 5, loss = -0.12271636798977854\n",
      "Epoch: 6, loss = -0.21237138742581013\n",
      "Epoch: 7, loss = -0.3073450095951557\n",
      "Epoch: 8, loss = -0.4064486650750041\n",
      "Epoch: 9, loss = -0.5060542732477188\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.39826003611087796\n",
      "Epoch: 1, loss = 0.34763970971107483\n",
      "Epoch: 2, loss = 0.2953152388334275\n",
      "Epoch: 3, loss = 0.23983206003904342\n",
      "Epoch: 4, loss = 0.18055437207221986\n",
      "Epoch: 5, loss = 0.1167229624465108\n",
      "Epoch: 6, loss = 0.04779044408351184\n",
      "Epoch: 7, loss = -0.02675572568550706\n",
      "Epoch: 8, loss = -0.10739925317466259\n",
      "Epoch: 9, loss = -0.19443082846701146\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.3123972785348693\n",
      "Epoch: 1, loss = -0.40535752816746634\n",
      "Epoch: 2, loss = -0.507428415119648\n",
      "Epoch: 3, loss = -0.5901123583316803\n",
      "Epoch: 4, loss = -0.6897936637202897\n",
      "Epoch: 5, loss = -0.7219000880916914\n",
      "Epoch: 6, loss = -0.7661724910140038\n",
      "Epoch: 7, loss = -0.7511055320501329\n",
      "Epoch: 8, loss = -0.8566978772481283\n",
      "Epoch: 9, loss = -1.0163180430730185\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.5769462138414382\n",
      "Epoch: 1, loss = -0.6927827969193459\n",
      "Epoch: 2, loss = -0.8146629010637603\n",
      "Epoch: 3, loss = -0.9370950708786646\n",
      "Epoch: 4, loss = -1.0589130123456318\n",
      "Epoch: 5, loss = -1.1612083365519843\n",
      "Epoch: 6, loss = -1.2233418077230453\n",
      "Epoch: 7, loss = -1.3487020780642827\n",
      "Epoch: 8, loss = -1.4758584996064503\n",
      "Epoch: 9, loss = -1.5742380519707997\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.1937775396121045\n",
      "Epoch: 1, loss = -0.28447566643202055\n",
      "Epoch: 2, loss = -0.3827302781865001\n",
      "Epoch: 3, loss = -0.48208907246589666\n",
      "Epoch: 4, loss = -0.5893127806484698\n",
      "Epoch: 5, loss = -0.6976940023402374\n",
      "Epoch: 6, loss = -0.8098590771357218\n",
      "Epoch: 7, loss = -0.913439966738224\n",
      "Epoch: 8, loss = -1.031909781197707\n",
      "Epoch: 9, loss = -1.1204431951045988\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.5330524270733197\n",
      "Epoch: 1, loss = -0.6371859349310398\n",
      "Epoch: 2, loss = -0.7415008569757143\n",
      "Epoch: 3, loss = -0.8370478476087253\n",
      "Epoch: 4, loss = -0.9182832514246304\n",
      "Epoch: 5, loss = -0.8822213461001713\n",
      "Epoch: 6, loss = -1.0784914394219716\n",
      "Epoch: 7, loss = -1.12917256851991\n",
      "Epoch: 8, loss = -1.2244740873575213\n",
      "Epoch: 9, loss = -1.2915630837281544\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.23467921651899815\n",
      "Epoch: 1, loss = -0.3257766884441177\n",
      "Epoch: 2, loss = -0.4196955651665727\n",
      "Epoch: 3, loss = -0.5196538716554641\n",
      "Epoch: 4, loss = -0.6237000487744808\n",
      "Epoch: 5, loss = -0.7273403505484263\n",
      "Epoch: 6, loss = -0.8192558735609055\n",
      "Epoch: 7, loss = -0.9289121056596437\n",
      "Epoch: 8, loss = -1.0490274528662362\n",
      "Epoch: 9, loss = -1.1367633442083993\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.0862105701650893\n",
      "Epoch: 1, loss = -1.192523053714207\n",
      "Epoch: 2, loss = -1.281315748180662\n",
      "Epoch: 3, loss = -1.3632937967777252\n",
      "Epoch: 4, loss = -1.4685391783714294\n",
      "Epoch: 5, loss = -1.3897164506571633\n",
      "Epoch: 6, loss = -1.5790885686874387\n",
      "Epoch: 7, loss = -1.5377016748700825\n",
      "Epoch: 8, loss = -1.6289440734045844\n",
      "Epoch: 9, loss = -1.5053798386028836\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.5612048506736755\n",
      "Epoch: 1, loss = -1.6480625186647686\n",
      "Epoch: 2, loss = -1.6556616510663715\n",
      "Epoch: 3, loss = -1.3921974822878838\n",
      "Epoch: 4, loss = -1.7435534511293684\n",
      "Epoch: 5, loss = -1.757810115814209\n",
      "Epoch: 6, loss = -1.8146806529590065\n",
      "Epoch: 7, loss = -1.7877589464187624\n",
      "Epoch: 8, loss = -1.8448648708207267\n",
      "Epoch: 9, loss = -1.9110727735928126\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.1592893643038615\n",
      "Epoch: 1, loss = -1.1195383455072132\n",
      "Epoch: 2, loss = -1.2106773086956568\n",
      "Epoch: 3, loss = -1.1785349122115545\n",
      "Epoch: 4, loss = -1.3172313145228791\n",
      "Epoch: 5, loss = -1.363782674074173\n",
      "Epoch: 6, loss = -1.351604823555265\n",
      "Epoch: 7, loss = -1.3761874011584692\n",
      "Epoch: 8, loss = -1.2503924582685741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss = -0.9590060157435281\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.2287910495485581\n",
      "Epoch: 1, loss = -1.1765170565673282\n",
      "Epoch: 2, loss = -1.3779937922954562\n",
      "Epoch: 3, loss = -1.439528001206262\n",
      "Epoch: 4, loss = -1.4833287852151054\n",
      "Epoch: 5, loss = -1.439815491437912\n",
      "Epoch: 6, loss = -1.3306934578078133\n",
      "Epoch: 7, loss = -1.5719641872814722\n",
      "Epoch: 8, loss = -1.5220189435141427\n",
      "Epoch: 9, loss = -1.5764223081724986\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.0739157455308095\n",
      "Epoch: 1, loss = -1.1390717795916965\n",
      "Epoch: 2, loss = -1.01841402053833\n",
      "Epoch: 3, loss = -0.9547961354255675\n",
      "Epoch: 4, loss = -0.8439610472747258\n",
      "Epoch: 5, loss = -0.909392808164869\n",
      "Epoch: 6, loss = -1.0909175404480524\n",
      "Epoch: 7, loss = -1.2470534571579526\n",
      "Epoch: 8, loss = -1.3429303424698968\n",
      "Epoch: 9, loss = -1.4131459891796112\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.6483953148126602\n",
      "Epoch: 1, loss = -1.5139280706644058\n",
      "Epoch: 2, loss = -1.2133687548339367\n",
      "Epoch: 3, loss = -0.9372328603640199\n",
      "Epoch: 4, loss = -0.9600540334358811\n",
      "Epoch: 5, loss = -1.287470482289791\n",
      "Epoch: 6, loss = -1.4567211493849754\n",
      "Epoch: 7, loss = -1.5112790390849113\n",
      "Epoch: 8, loss = -1.5551206544041634\n",
      "Epoch: 9, loss = -1.5535647496581078\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.7938699498772621\n",
      "Epoch: 1, loss = -1.537536546587944\n",
      "Epoch: 2, loss = -1.7955447360873222\n",
      "Epoch: 3, loss = -1.7074325531721115\n",
      "Epoch: 4, loss = -1.6531821228563786\n",
      "Epoch: 5, loss = -1.5035835839807987\n",
      "Epoch: 6, loss = -1.4749154914170504\n",
      "Epoch: 7, loss = -0.9305285215377808\n",
      "Epoch: 8, loss = -0.4974867654964328\n",
      "Epoch: 9, loss = -0.7191644953563809\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.254409285262227\n",
      "Epoch: 1, loss = -1.1645186766982079\n",
      "Epoch: 2, loss = -1.2355134636163712\n",
      "Epoch: 3, loss = -1.3827876225113869\n",
      "Epoch: 4, loss = -1.5305273681879044\n",
      "Epoch: 5, loss = -1.5326864048838615\n",
      "Epoch: 6, loss = -1.6175330430269241\n",
      "Epoch: 7, loss = -1.6392605751752853\n",
      "Epoch: 8, loss = -1.519491471350193\n",
      "Epoch: 9, loss = -1.5680410414934158\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.5770234316587448\n",
      "Epoch: 1, loss = -1.1857601860538125\n",
      "Epoch: 2, loss = -1.1772453729063272\n",
      "Epoch: 3, loss = -1.274247869849205\n",
      "Epoch: 4, loss = -1.40574661642313\n",
      "Epoch: 5, loss = -1.4836455583572388\n",
      "Epoch: 6, loss = -1.53983573615551\n",
      "Epoch: 7, loss = -1.5305983126163483\n",
      "Epoch: 8, loss = -1.5277453288435936\n",
      "Epoch: 9, loss = -1.5028157904744148\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.4264152757823467\n",
      "Epoch: 1, loss = -1.521115180104971\n",
      "Epoch: 2, loss = -1.449601475149393\n",
      "Epoch: 3, loss = -1.5800077021121979\n",
      "Epoch: 4, loss = -1.6626278385519981\n",
      "Epoch: 5, loss = -1.4866617396473885\n",
      "Epoch: 6, loss = -1.5403535887598991\n",
      "Epoch: 7, loss = -1.6329094767570496\n",
      "Epoch: 8, loss = -1.5736738815903664\n",
      "Epoch: 9, loss = -1.7217264920473099\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7930283322930336\n",
      "Epoch: 1, loss = 0.7523109391331673\n",
      "Epoch: 2, loss = 0.7144019827246666\n",
      "Epoch: 3, loss = 0.6773763746023178\n",
      "Epoch: 4, loss = 0.6399806141853333\n",
      "Epoch: 5, loss = 0.6012193784117699\n",
      "Epoch: 6, loss = 0.5603281557559967\n",
      "Epoch: 7, loss = 0.5166700109839439\n",
      "Epoch: 8, loss = 0.46976394951343536\n",
      "Epoch: 9, loss = 0.4192032963037491\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.8313609808683395\n",
      "Epoch: 1, loss = 0.7619078308343887\n",
      "Epoch: 2, loss = 0.704172782599926\n",
      "Epoch: 3, loss = 0.653107076883316\n",
      "Epoch: 4, loss = 0.6046323701739311\n",
      "Epoch: 5, loss = 0.556377574801445\n",
      "Epoch: 6, loss = 0.5065088123083115\n",
      "Epoch: 7, loss = 0.45380761101841927\n",
      "Epoch: 8, loss = 0.397946335375309\n",
      "Epoch: 9, loss = 0.3385269083082676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8141471296548843\n",
      "Epoch: 1, loss = 0.7787958979606628\n",
      "Epoch: 2, loss = 0.7446495071053505\n",
      "Epoch: 3, loss = 0.7103998884558678\n",
      "Epoch: 4, loss = 0.675416387617588\n",
      "Epoch: 5, loss = 0.6392217725515366\n",
      "Epoch: 6, loss = 0.6013956069946289\n",
      "Epoch: 7, loss = 0.5614079907536507\n",
      "Epoch: 8, loss = 0.5187893062829971\n",
      "Epoch: 9, loss = 0.4730595424771309\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7053331956267357\n",
      "Epoch: 1, loss = 0.6636583507061005\n",
      "Epoch: 2, loss = 0.6224204152822495\n",
      "Epoch: 3, loss = 0.5798479616641998\n",
      "Epoch: 4, loss = 0.535397220402956\n",
      "Epoch: 5, loss = 0.4886329509317875\n",
      "Epoch: 6, loss = 0.43916021287441254\n",
      "Epoch: 7, loss = 0.38655776903033257\n",
      "Epoch: 8, loss = 0.33041018806397915\n",
      "Epoch: 9, loss = 0.2702309973537922\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7818650752305984\n",
      "Epoch: 1, loss = 0.7420015409588814\n",
      "Epoch: 2, loss = 0.7046777978539467\n",
      "Epoch: 3, loss = 0.6686465293169022\n",
      "Epoch: 4, loss = 0.6327197402715683\n",
      "Epoch: 5, loss = 0.5960599407553673\n",
      "Epoch: 6, loss = 0.5581148713827133\n",
      "Epoch: 7, loss = 0.5184247605502605\n",
      "Epoch: 8, loss = 0.4766390211880207\n",
      "Epoch: 9, loss = 0.4324333593249321\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4172647669911385\n",
      "Epoch: 1, loss = 0.3554673952360948\n",
      "Epoch: 2, loss = 0.28969821458061534\n",
      "Epoch: 3, loss = 0.21822296548634768\n",
      "Epoch: 4, loss = 0.13999431859701872\n",
      "Epoch: 5, loss = 0.05448261043056846\n",
      "Epoch: 6, loss = -0.03973280390103659\n",
      "Epoch: 7, loss = -0.14207229763269424\n",
      "Epoch: 8, loss = -0.2539454335346818\n",
      "Epoch: 9, loss = -0.37325075982759404\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.3042452447116375\n",
      "Epoch: 1, loss = 0.22360337525606155\n",
      "Epoch: 2, loss = 0.13807499408721924\n",
      "Epoch: 3, loss = 0.04561623053935667\n",
      "Epoch: 4, loss = -0.054840583121404045\n",
      "Epoch: 5, loss = -0.1637668805196881\n",
      "Epoch: 6, loss = -0.2813464148590962\n",
      "Epoch: 7, loss = -0.40713344638546306\n",
      "Epoch: 8, loss = -0.5395758971571922\n",
      "Epoch: 9, loss = -0.6759211868047714\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.46532246967156726\n",
      "Epoch: 1, loss = 0.40896456440289813\n",
      "Epoch: 2, loss = 0.3498092095057169\n",
      "Epoch: 3, loss = 0.2854145901898543\n",
      "Epoch: 4, loss = 0.21502451691776514\n",
      "Epoch: 5, loss = 0.137582598409305\n",
      "Epoch: 6, loss = 0.052412399013216295\n",
      "Epoch: 7, loss = -0.041234578316410385\n",
      "Epoch: 8, loss = -0.14398907575135433\n",
      "Epoch: 9, loss = -0.255854982106636\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.28083919361233706\n",
      "Epoch: 1, loss = 0.20824704117452103\n",
      "Epoch: 2, loss = 0.13069659642254314\n",
      "Epoch: 3, loss = 0.04830311331897974\n",
      "Epoch: 4, loss = -0.04255998786538838\n",
      "Epoch: 5, loss = -0.1413836053883036\n",
      "Epoch: 6, loss = -0.24782270208622018\n",
      "Epoch: 7, loss = -0.36257044443239766\n",
      "Epoch: 8, loss = -0.4794883069892724\n",
      "Epoch: 9, loss = -0.5718036939700444\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.4102298418680827\n",
      "Epoch: 1, loss = 0.3525311971704165\n",
      "Epoch: 2, loss = 0.2922331802546978\n",
      "Epoch: 3, loss = 0.227145679295063\n",
      "Epoch: 4, loss = 0.15636384766548872\n",
      "Epoch: 5, loss = 0.07868304724494615\n",
      "Epoch: 6, loss = -0.006654290171960996\n",
      "Epoch: 7, loss = -0.10054412359992664\n",
      "Epoch: 8, loss = -0.2036035284399986\n",
      "Epoch: 9, loss = -0.3162928444022933\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.43052612664178014\n",
      "Epoch: 1, loss = -0.5594805860891938\n",
      "Epoch: 2, loss = -0.6980745010077953\n",
      "Epoch: 3, loss = -0.822133120149374\n",
      "Epoch: 4, loss = -0.9489472731947899\n",
      "Epoch: 5, loss = -1.0665342397987843\n",
      "Epoch: 6, loss = -1.2062803246080875\n",
      "Epoch: 7, loss = -1.2746224999427795\n",
      "Epoch: 8, loss = -1.2974666617810726\n",
      "Epoch: 9, loss = -1.3398238942027092\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.7229571882635355\n",
      "Epoch: 1, loss = -0.8528119046241045\n",
      "Epoch: 2, loss = -1.0119853019714355\n",
      "Epoch: 3, loss = -1.1570203006267548\n",
      "Epoch: 4, loss = -1.3045691438019276\n",
      "Epoch: 5, loss = -1.4429758787155151\n",
      "Epoch: 6, loss = -1.5519962832331657\n",
      "Epoch: 7, loss = -1.6535509377717972\n",
      "Epoch: 8, loss = -1.5102680698037148\n",
      "Epoch: 9, loss = -1.435428086668253\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.298589721089229\n",
      "Epoch: 1, loss = -0.4190245228819549\n",
      "Epoch: 2, loss = -0.5536098452284932\n",
      "Epoch: 3, loss = -0.676428722217679\n",
      "Epoch: 4, loss = -0.8223892990499735\n",
      "Epoch: 5, loss = -0.9188432209193707\n",
      "Epoch: 6, loss = -1.0544492192566395\n",
      "Epoch: 7, loss = -1.089132059365511\n",
      "Epoch: 8, loss = -1.1691371574997902\n",
      "Epoch: 9, loss = -1.1419182009994984\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.6008958155289292\n",
      "Epoch: 1, loss = -0.6597695099189878\n",
      "Epoch: 2, loss = -0.6196669805794954\n",
      "Epoch: 3, loss = -0.6067627919837832\n",
      "Epoch: 4, loss = -0.5213191770017147\n",
      "Epoch: 5, loss = -0.6129107009619474\n",
      "Epoch: 6, loss = -0.8033228293061256\n",
      "Epoch: 7, loss = -0.95178890414536\n",
      "Epoch: 8, loss = -1.057569520547986\n",
      "Epoch: 9, loss = -1.1466379761695862\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.3815683713182807\n",
      "Epoch: 1, loss = -0.5079095317050815\n",
      "Epoch: 2, loss = -0.6391104869544506\n",
      "Epoch: 3, loss = -0.765271257609129\n",
      "Epoch: 4, loss = -0.8283651173114777\n",
      "Epoch: 5, loss = -0.8828214555978775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss = -1.0277909077703953\n",
      "Epoch: 7, loss = -1.17489143460989\n",
      "Epoch: 8, loss = -1.2651892229914665\n",
      "Epoch: 9, loss = -1.1306459456682205\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.3824535995721816\n",
      "Epoch: 1, loss = -1.4374658942222598\n",
      "Epoch: 2, loss = -1.4013781696558\n",
      "Epoch: 3, loss = -1.2468035101890564\n",
      "Epoch: 4, loss = -1.2934492096304895\n",
      "Epoch: 5, loss = -1.324181067943573\n",
      "Epoch: 6, loss = -1.2030240878462792\n",
      "Epoch: 7, loss = -1.2787399649620055\n",
      "Epoch: 8, loss = -1.2897857531905175\n",
      "Epoch: 9, loss = -1.5590531706809991\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.1126955986022948\n",
      "Epoch: 1, loss = -1.3025306165218358\n",
      "Epoch: 2, loss = -1.2223327003419397\n",
      "Epoch: 3, loss = -0.8883532613515854\n",
      "Epoch: 4, loss = -0.857507289201021\n",
      "Epoch: 5, loss = -0.8879190884530546\n",
      "Epoch: 6, loss = -1.1764803677797318\n",
      "Epoch: 7, loss = -1.2399712204933167\n",
      "Epoch: 8, loss = -1.2769089877605437\n",
      "Epoch: 9, loss = -1.264356079697609\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.0751167513430115\n",
      "Epoch: 1, loss = -0.9168333947658538\n",
      "Epoch: 2, loss = -1.1408383339643478\n",
      "Epoch: 3, loss = -1.3136611819267274\n",
      "Epoch: 4, loss = -1.4218903124332427\n",
      "Epoch: 5, loss = -1.4309367835521696\n",
      "Epoch: 6, loss = -1.3792687773704528\n",
      "Epoch: 7, loss = -1.567426860332489\n",
      "Epoch: 8, loss = -1.5805651664733884\n",
      "Epoch: 9, loss = -1.4304974615573884\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.1818234384059907\n",
      "Epoch: 1, loss = -1.2143077999353409\n",
      "Epoch: 2, loss = -1.3429269909858705\n",
      "Epoch: 3, loss = -1.288456991314888\n",
      "Epoch: 4, loss = -1.3570743083953858\n",
      "Epoch: 5, loss = -1.1349988758563998\n",
      "Epoch: 6, loss = -1.1222365662455558\n",
      "Epoch: 7, loss = -1.0717694401741027\n",
      "Epoch: 8, loss = -1.1234055757522583\n",
      "Epoch: 9, loss = -1.1628290817141533\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.4524791181087494\n",
      "Epoch: 1, loss = -0.5042140729725361\n",
      "Epoch: 2, loss = -0.4980278268456459\n",
      "Epoch: 3, loss = -0.8716877385973931\n",
      "Epoch: 4, loss = -1.1128597259521489\n",
      "Epoch: 5, loss = -1.2299505144357679\n",
      "Epoch: 6, loss = -1.2864613115787507\n",
      "Epoch: 7, loss = -1.3449078947305682\n",
      "Epoch: 8, loss = -1.3764770507812496\n",
      "Epoch: 9, loss = -1.4025158524513246\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.4913433616360028\n",
      "Epoch: 1, loss = -1.0813691367705662\n",
      "Epoch: 2, loss = -0.8929437628636757\n",
      "Epoch: 3, loss = -0.6771138707796733\n",
      "Epoch: 4, loss = -1.009664751899739\n",
      "Epoch: 5, loss = -1.4519093881050749\n",
      "Epoch: 6, loss = -1.5185177773237228\n",
      "Epoch: 7, loss = -1.6214796354373298\n",
      "Epoch: 8, loss = -1.6643193513154984\n",
      "Epoch: 9, loss = -1.7008561690648394\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.3663482442498205\n",
      "Epoch: 1, loss = -1.4849983205397925\n",
      "Epoch: 2, loss = -1.4399690590798855\n",
      "Epoch: 3, loss = -1.517319679260254\n",
      "Epoch: 4, loss = -1.6426432430744173\n",
      "Epoch: 5, loss = -1.4969705094893775\n",
      "Epoch: 6, loss = -0.9305632549027603\n",
      "Epoch: 7, loss = -1.472368687391281\n",
      "Epoch: 8, loss = -1.3187960560123129\n",
      "Epoch: 9, loss = -1.4417101095120113\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.2099395381907623\n",
      "Epoch: 1, loss = -1.02507502771914\n",
      "Epoch: 2, loss = -1.2580852831403415\n",
      "Epoch: 3, loss = -1.4768674969673157\n",
      "Epoch: 4, loss = -1.564109742641449\n",
      "Epoch: 5, loss = -1.6477201928695038\n",
      "Epoch: 6, loss = -1.699639762441317\n",
      "Epoch: 7, loss = -1.7202943861484525\n",
      "Epoch: 8, loss = -1.4963909238576891\n",
      "Epoch: 9, loss = -1.5630329872171083\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.2935465797781942\n",
      "Epoch: 1, loss = -1.3476018706957504\n",
      "Epoch: 2, loss = -1.4718096554279332\n",
      "Epoch: 3, loss = -1.3317392667134604\n",
      "Epoch: 4, loss = -1.3956630552808447\n",
      "Epoch: 5, loss = -1.122766668597857\n",
      "Epoch: 6, loss = -1.2283412385731933\n",
      "Epoch: 7, loss = -1.2515478755036988\n",
      "Epoch: 8, loss = -1.4870918492476144\n",
      "Epoch: 9, loss = -1.4998557046055798\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.32771431406339\n",
      "Epoch: 1, loss = -1.0759743091960745\n",
      "Epoch: 2, loss = -0.944597671429316\n",
      "Epoch: 3, loss = -0.7470338232815266\n",
      "Epoch: 4, loss = -0.8665319457650185\n",
      "Epoch: 5, loss = -1.0136402547359467\n",
      "Epoch: 6, loss = -0.9604035864273707\n",
      "Epoch: 7, loss = -0.9107193760573863\n",
      "Epoch: 8, loss = -1.187390814224879\n",
      "Epoch: 9, loss = -1.3032866095503173\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7930283322930336\n",
      "Epoch: 1, loss = 0.7523109391331673\n",
      "Epoch: 2, loss = 0.7144019827246666\n",
      "Epoch: 3, loss = 0.6773763746023178\n",
      "Epoch: 4, loss = 0.6399806141853333\n",
      "Epoch: 5, loss = 0.6012193784117699\n",
      "Epoch: 6, loss = 0.5603281557559967\n",
      "Epoch: 7, loss = 0.5166700109839439\n",
      "Epoch: 8, loss = 0.46976394951343536\n",
      "Epoch: 9, loss = 0.4192032963037491\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.8313609808683395\n",
      "Epoch: 1, loss = 0.7619078308343887\n",
      "Epoch: 2, loss = 0.704172782599926\n",
      "Epoch: 3, loss = 0.653107076883316\n",
      "Epoch: 4, loss = 0.6046323701739311\n",
      "Epoch: 5, loss = 0.556377574801445\n",
      "Epoch: 6, loss = 0.5065088123083115\n",
      "Epoch: 7, loss = 0.45380761101841927\n",
      "Epoch: 8, loss = 0.397946335375309\n",
      "Epoch: 9, loss = 0.3385269083082676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8141471296548843\n",
      "Epoch: 1, loss = 0.7787958979606628\n",
      "Epoch: 2, loss = 0.7446495071053505\n",
      "Epoch: 3, loss = 0.7103998884558678\n",
      "Epoch: 4, loss = 0.675416387617588\n",
      "Epoch: 5, loss = 0.6392217725515366\n",
      "Epoch: 6, loss = 0.6013956069946289\n",
      "Epoch: 7, loss = 0.5614079907536507\n",
      "Epoch: 8, loss = 0.5187893062829971\n",
      "Epoch: 9, loss = 0.4730595424771309\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7053331956267357\n",
      "Epoch: 1, loss = 0.6636583507061005\n",
      "Epoch: 2, loss = 0.6224204152822495\n",
      "Epoch: 3, loss = 0.5798479616641998\n",
      "Epoch: 4, loss = 0.535397220402956\n",
      "Epoch: 5, loss = 0.4886329509317875\n",
      "Epoch: 6, loss = 0.43916021287441254\n",
      "Epoch: 7, loss = 0.38655776903033257\n",
      "Epoch: 8, loss = 0.33041018806397915\n",
      "Epoch: 9, loss = 0.2702309973537922\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7818650752305984\n",
      "Epoch: 1, loss = 0.7420015409588814\n",
      "Epoch: 2, loss = 0.7046777978539467\n",
      "Epoch: 3, loss = 0.6686465293169022\n",
      "Epoch: 4, loss = 0.6327197402715683\n",
      "Epoch: 5, loss = 0.5960599407553673\n",
      "Epoch: 6, loss = 0.5581148713827133\n",
      "Epoch: 7, loss = 0.5184247605502605\n",
      "Epoch: 8, loss = 0.4766390211880207\n",
      "Epoch: 9, loss = 0.4324333593249321\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.441300705075264\n",
      "Epoch: 1, loss = 0.36532019451260567\n",
      "Epoch: 2, loss = 0.2819363232702017\n",
      "Epoch: 3, loss = 0.1881290227174759\n",
      "Epoch: 4, loss = 0.08171821071300656\n",
      "Epoch: 5, loss = -0.03837152395863086\n",
      "Epoch: 6, loss = -0.17549286899156868\n",
      "Epoch: 7, loss = -0.32413200609153137\n",
      "Epoch: 8, loss = -0.49641514802351594\n",
      "Epoch: 9, loss = -0.6689994148910046\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.3154613049700856\n",
      "Epoch: 1, loss = 0.213039415422827\n",
      "Epoch: 2, loss = 0.10089412552770227\n",
      "Epoch: 3, loss = -0.024427622673101723\n",
      "Epoch: 4, loss = -0.1642664244864136\n",
      "Epoch: 5, loss = -0.31864084396511316\n",
      "Epoch: 6, loss = -0.48477742075920105\n",
      "Epoch: 7, loss = -0.6562217324972153\n",
      "Epoch: 8, loss = -0.8202057853341103\n",
      "Epoch: 9, loss = -0.9563988596200943\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48120083287358284\n",
      "Epoch: 1, loss = 0.41350577119737864\n",
      "Epoch: 2, loss = 0.33944597467780113\n",
      "Epoch: 3, loss = 0.2562332940287888\n",
      "Epoch: 4, loss = 0.16128069395199418\n",
      "Epoch: 5, loss = 0.05298124463297427\n",
      "Epoch: 6, loss = -0.07028614467708394\n",
      "Epoch: 7, loss = -0.2094188858754933\n",
      "Epoch: 8, loss = -0.36376730096526444\n",
      "Epoch: 9, loss = -0.5308379093185067\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.3208033526316285\n",
      "Epoch: 1, loss = 0.23641578597016633\n",
      "Epoch: 2, loss = 0.14091274968814105\n",
      "Epoch: 3, loss = 0.04163066274486482\n",
      "Epoch: 4, loss = -0.07436339452397078\n",
      "Epoch: 5, loss = -0.1925314839463681\n",
      "Epoch: 6, loss = -0.32433090661652386\n",
      "Epoch: 7, loss = -0.4713670238852501\n",
      "Epoch: 8, loss = -0.6251082848757505\n",
      "Epoch: 9, loss = -0.7780021596699953\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.41190289333462715\n",
      "Epoch: 1, loss = 0.33778418228030205\n",
      "Epoch: 2, loss = 0.25694249849766493\n",
      "Epoch: 3, loss = 0.16698727197945118\n",
      "Epoch: 4, loss = 0.06480943714268506\n",
      "Epoch: 5, loss = -0.051441324525512755\n",
      "Epoch: 6, loss = -0.1833208230091259\n",
      "Epoch: 7, loss = -0.3314507296308875\n",
      "Epoch: 8, loss = -0.49556663539260626\n",
      "Epoch: 9, loss = -0.6723479982465506\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.814512596776088\n",
      "Epoch: 1, loss = -1.0145669281482697\n",
      "Epoch: 2, loss = -1.1983037491639454\n",
      "Epoch: 3, loss = -1.3495031222701075\n",
      "Epoch: 4, loss = -1.3684424807627995\n",
      "Epoch: 5, loss = -1.4683754146099088\n",
      "Epoch: 6, loss = -1.5279356390237813\n",
      "Epoch: 7, loss = -1.4176405295729635\n",
      "Epoch: 8, loss = -1.3875779335697491\n",
      "Epoch: 9, loss = -0.9121851082891227\n",
      "\n",
      "Training model 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = -0.9573244204123814\n",
      "Epoch: 1, loss = -1.143225600322088\n",
      "Epoch: 2, loss = -1.3332397093375523\n",
      "Epoch: 3, loss = -1.4510455131530762\n",
      "Epoch: 4, loss = -1.487467403213183\n",
      "Epoch: 5, loss = -1.393613158414761\n",
      "Epoch: 6, loss = -1.4019930437207222\n",
      "Epoch: 7, loss = -1.5927585512399673\n",
      "Epoch: 8, loss = -1.6713468035062153\n",
      "Epoch: 9, loss = -1.710672025879224\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.6539924430350462\n",
      "Epoch: 1, loss = -0.8498410234848658\n",
      "Epoch: 2, loss = -1.0354849298795064\n",
      "Epoch: 3, loss = -1.1439209828774135\n",
      "Epoch: 4, loss = -1.2009235148628554\n",
      "Epoch: 5, loss = -1.3330517013867698\n",
      "Epoch: 6, loss = -1.3167670940359437\n",
      "Epoch: 7, loss = -1.2919188936551411\n",
      "Epoch: 8, loss = -1.3220697542031608\n",
      "Epoch: 9, loss = -1.0713014230132105\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.8312343123058479\n",
      "Epoch: 1, loss = -0.9987346852819123\n",
      "Epoch: 2, loss = -1.114240137239297\n",
      "Epoch: 3, loss = -1.2052483782172203\n",
      "Epoch: 4, loss = -1.2478123630086577\n",
      "Epoch: 5, loss = -1.2974353581666949\n",
      "Epoch: 6, loss = -1.1534348080555599\n",
      "Epoch: 7, loss = -1.130024728675683\n",
      "Epoch: 8, loss = -1.0625164570907755\n",
      "Epoch: 9, loss = -1.2195265541474027\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.6486608274281025\n",
      "Epoch: 1, loss = -0.7997317984700203\n",
      "Epoch: 2, loss = -0.7682396744688353\n",
      "Epoch: 3, loss = -0.9363420878847438\n",
      "Epoch: 4, loss = -1.0671494305133822\n",
      "Epoch: 5, loss = -1.2157311265667279\n",
      "Epoch: 6, loss = -1.334963579972585\n",
      "Epoch: 7, loss = -1.3412935038407643\n",
      "Epoch: 8, loss = -1.1078069036205611\n",
      "Epoch: 9, loss = 0.18065299342075988\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.1152719259262085\n",
      "Epoch: 1, loss = -1.3376237954944372\n",
      "Epoch: 2, loss = -1.6239427216351032\n",
      "Epoch: 3, loss = -1.6707753241062164\n",
      "Epoch: 4, loss = -1.7324772030115128\n",
      "Epoch: 5, loss = -1.702819585800171\n",
      "Epoch: 6, loss = -1.7028143536299467\n",
      "Epoch: 7, loss = -1.4918271256610751\n",
      "Epoch: 8, loss = -1.5480678253807127\n",
      "Epoch: 9, loss = -1.754682321101427\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.7658009827136993\n",
      "Epoch: 1, loss = -1.800579473376274\n",
      "Epoch: 2, loss = -1.4476102236658335\n",
      "Epoch: 3, loss = -1.7372228745371103\n",
      "Epoch: 4, loss = -1.8996788784861565\n",
      "Epoch: 5, loss = -1.9172907434403896\n",
      "Epoch: 6, loss = -1.9251213520765305\n",
      "Epoch: 7, loss = -1.7873188704252243\n",
      "Epoch: 8, loss = -1.3732831813395023\n",
      "Epoch: 9, loss = -1.3156788046471775\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.8983256565406919\n",
      "Epoch: 1, loss = -1.361073810607195\n",
      "Epoch: 2, loss = -1.4110780991613865\n",
      "Epoch: 3, loss = -1.5314294397830963\n",
      "Epoch: 4, loss = -1.6327196843922138\n",
      "Epoch: 5, loss = -1.7154820188879967\n",
      "Epoch: 6, loss = -1.7818058840930462\n",
      "Epoch: 7, loss = -1.8116871044039726\n",
      "Epoch: 8, loss = -0.9400596059858799\n",
      "Epoch: 9, loss = -1.4522525742650032\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.4700594022870064\n",
      "Epoch: 1, loss = -1.5128797460347414\n",
      "Epoch: 2, loss = -1.7211347445845604\n",
      "Epoch: 3, loss = -1.6619892194867134\n",
      "Epoch: 4, loss = -1.3084170632064342\n",
      "Epoch: 5, loss = -1.1331651862710714\n",
      "Epoch: 6, loss = -1.6218053102493286\n",
      "Epoch: 7, loss = -1.7463961578905582\n",
      "Epoch: 8, loss = -1.7876320108771324\n",
      "Epoch: 9, loss = -1.8204326555132866\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.24449515994638205\n",
      "Epoch: 1, loss = -1.0106377582997084\n",
      "Epoch: 2, loss = -1.1674030888825655\n",
      "Epoch: 3, loss = -1.3732560724020004\n",
      "Epoch: 4, loss = -1.4286493677645922\n",
      "Epoch: 5, loss = -1.4741680063307285\n",
      "Epoch: 6, loss = -1.493618629872799\n",
      "Epoch: 7, loss = -1.5507316030561924\n",
      "Epoch: 8, loss = -1.6101724468171597\n",
      "Epoch: 9, loss = -1.706268310546875\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.846673068404198\n",
      "Epoch: 1, loss = -1.8959141761064529\n",
      "Epoch: 2, loss = -1.7814720883965491\n",
      "Epoch: 3, loss = -1.8228494465351108\n",
      "Epoch: 4, loss = -1.8413291603326798\n",
      "Epoch: 5, loss = -1.8656765192747118\n",
      "Epoch: 6, loss = -1.888294166326523\n",
      "Epoch: 7, loss = -1.90090160369873\n",
      "Epoch: 8, loss = -1.9190389871597289\n",
      "Epoch: 9, loss = -1.9659493058919904\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.7736609250307085\n",
      "Epoch: 1, loss = -1.6516241498291495\n",
      "Epoch: 2, loss = -1.9755932718515394\n",
      "Epoch: 3, loss = -1.5036525070667262\n",
      "Epoch: 4, loss = -1.5893755231052635\n",
      "Epoch: 5, loss = -1.802608621120453\n",
      "Epoch: 6, loss = -1.9961263537406917\n",
      "Epoch: 7, loss = -2.091520416736603\n",
      "Epoch: 8, loss = -1.9148286685347553\n",
      "Epoch: 9, loss = -1.3536581553518774\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.7649081617593763\n",
      "Epoch: 1, loss = -1.2802549406886101\n",
      "Epoch: 2, loss = -1.2402793955057858\n",
      "Epoch: 3, loss = -1.7473965376615523\n",
      "Epoch: 4, loss = -1.7922737300395968\n",
      "Epoch: 5, loss = -1.8863011211156848\n",
      "Epoch: 6, loss = -1.8834582060575489\n",
      "Epoch: 7, loss = -1.7008665941655636\n",
      "Epoch: 8, loss = -1.7123148709535596\n",
      "Epoch: 9, loss = -1.7626429855823513\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.718021553754807\n",
      "Epoch: 1, loss = -1.6253084331750867\n",
      "Epoch: 2, loss = -1.6208422698080542\n",
      "Epoch: 3, loss = -1.6454278692603113\n",
      "Epoch: 4, loss = -1.732982462644577\n",
      "Epoch: 5, loss = -1.8511577993631365\n",
      "Epoch: 6, loss = -1.957092332839966\n",
      "Epoch: 7, loss = -2.004400613904\n",
      "Epoch: 8, loss = -1.9780919909477233\n",
      "Epoch: 9, loss = -1.8662560775876045\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.5960677549242974\n",
      "Epoch: 1, loss = -1.7621426314115523\n",
      "Epoch: 2, loss = -1.812389397621155\n",
      "Epoch: 3, loss = -1.74365346878767\n",
      "Epoch: 4, loss = -1.6928624078631398\n",
      "Epoch: 5, loss = -1.9283043354749678\n",
      "Epoch: 6, loss = -1.890856875479221\n",
      "Epoch: 7, loss = -1.9788175225257871\n",
      "Epoch: 8, loss = -1.984367176890373\n",
      "Epoch: 9, loss = -1.8780122458934785\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7930283322930336\n",
      "Epoch: 1, loss = 0.7523109391331673\n",
      "Epoch: 2, loss = 0.7144019827246666\n",
      "Epoch: 3, loss = 0.6773763746023178\n",
      "Epoch: 4, loss = 0.6399806141853333\n",
      "Epoch: 5, loss = 0.6012193784117699\n",
      "Epoch: 6, loss = 0.5603281557559967\n",
      "Epoch: 7, loss = 0.5166700109839439\n",
      "Epoch: 8, loss = 0.46976394951343536\n",
      "Epoch: 9, loss = 0.4192032963037491\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.8313609808683395\n",
      "Epoch: 1, loss = 0.7619078308343887\n",
      "Epoch: 2, loss = 0.704172782599926\n",
      "Epoch: 3, loss = 0.653107076883316\n",
      "Epoch: 4, loss = 0.6046323701739311\n",
      "Epoch: 5, loss = 0.556377574801445\n",
      "Epoch: 6, loss = 0.5065088123083115\n",
      "Epoch: 7, loss = 0.45380761101841927\n",
      "Epoch: 8, loss = 0.397946335375309\n",
      "Epoch: 9, loss = 0.3385269083082676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8141471296548843\n",
      "Epoch: 1, loss = 0.7787958979606628\n",
      "Epoch: 2, loss = 0.7446495071053505\n",
      "Epoch: 3, loss = 0.7103998884558678\n",
      "Epoch: 4, loss = 0.675416387617588\n",
      "Epoch: 5, loss = 0.6392217725515366\n",
      "Epoch: 6, loss = 0.6013956069946289\n",
      "Epoch: 7, loss = 0.5614079907536507\n",
      "Epoch: 8, loss = 0.5187893062829971\n",
      "Epoch: 9, loss = 0.4730595424771309\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7053331956267357\n",
      "Epoch: 1, loss = 0.6636583507061005\n",
      "Epoch: 2, loss = 0.6224204152822495\n",
      "Epoch: 3, loss = 0.5798479616641998\n",
      "Epoch: 4, loss = 0.535397220402956\n",
      "Epoch: 5, loss = 0.4886329509317875\n",
      "Epoch: 6, loss = 0.43916021287441254\n",
      "Epoch: 7, loss = 0.38655776903033257\n",
      "Epoch: 8, loss = 0.33041018806397915\n",
      "Epoch: 9, loss = 0.2702309973537922\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7818650752305984\n",
      "Epoch: 1, loss = 0.7420015409588814\n",
      "Epoch: 2, loss = 0.7046777978539467\n",
      "Epoch: 3, loss = 0.6686465293169022\n",
      "Epoch: 4, loss = 0.6327197402715683\n",
      "Epoch: 5, loss = 0.5960599407553673\n",
      "Epoch: 6, loss = 0.5581148713827133\n",
      "Epoch: 7, loss = 0.5184247605502605\n",
      "Epoch: 8, loss = 0.4766390211880207\n",
      "Epoch: 9, loss = 0.4324333593249321\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.45616655672589945\n",
      "Epoch: 1, loss = 0.3472088916848103\n",
      "Epoch: 2, loss = 0.21764930741240582\n",
      "Epoch: 3, loss = 0.059022678139929965\n",
      "Epoch: 4, loss = -0.13547007359253865\n",
      "Epoch: 5, loss = -0.36997779707113904\n",
      "Epoch: 6, loss = -0.6475170118113359\n",
      "Epoch: 7, loss = -0.9483001058300337\n",
      "Epoch: 8, loss = -1.2036527072389922\n",
      "Epoch: 9, loss = -1.4437082757552464\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.3119030750046174\n",
      "Epoch: 1, loss = 0.15812100485588113\n",
      "Epoch: 2, loss = -0.02460030951381972\n",
      "Epoch: 3, loss = -0.24341718231638274\n",
      "Epoch: 4, loss = -0.4985243491828442\n",
      "Epoch: 5, loss = -0.7693309535582861\n",
      "Epoch: 6, loss = -0.9902870257695516\n",
      "Epoch: 7, loss = -1.1694701785842578\n",
      "Epoch: 8, loss = -1.3340092301368713\n",
      "Epoch: 9, loss = -1.4574848165114718\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48875365033745766\n",
      "Epoch: 1, loss = 0.3944501429796219\n",
      "Epoch: 2, loss = 0.27865811778853333\n",
      "Epoch: 3, loss = 0.13873169687576592\n",
      "Epoch: 4, loss = -0.03514442779123783\n",
      "Epoch: 5, loss = -0.25031837404821994\n",
      "Epoch: 6, loss = -0.5061355580886203\n",
      "Epoch: 7, loss = -0.7854594091574352\n",
      "Epoch: 8, loss = -1.0511114870508511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss = -1.261043931047122\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.345979101335009\n",
      "Epoch: 1, loss = 0.23450352600775656\n",
      "Epoch: 2, loss = 0.08806731753672163\n",
      "Epoch: 3, loss = -0.059280517123018676\n",
      "Epoch: 4, loss = -0.24318862314491219\n",
      "Epoch: 5, loss = -0.42284535647680355\n",
      "Epoch: 6, loss = -0.5786162006358306\n",
      "Epoch: 7, loss = -0.7176971572140853\n",
      "Epoch: 8, loss = -0.7196448702986041\n",
      "Epoch: 9, loss = -0.6598308092604082\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.41342066476742434\n",
      "Epoch: 1, loss = 0.3067093112816413\n",
      "Epoch: 2, loss = 0.17681155571093166\n",
      "Epoch: 3, loss = 0.021144522819668055\n",
      "Epoch: 4, loss = -0.16924735265395915\n",
      "Epoch: 5, loss = -0.3968609366565942\n",
      "Epoch: 6, loss = -0.6469142735004426\n",
      "Epoch: 7, loss = -0.856243619074424\n",
      "Epoch: 8, loss = -0.9851627647876742\n",
      "Epoch: 9, loss = -0.9894432413081329\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.2056705817580222\n",
      "Epoch: 1, loss = -0.9322294853627682\n",
      "Epoch: 2, loss = -1.348079348355532\n",
      "Epoch: 3, loss = -1.3187406815588478\n",
      "Epoch: 4, loss = -1.3773402597755195\n",
      "Epoch: 5, loss = -1.3097237531095742\n",
      "Epoch: 6, loss = -1.3660876207053663\n",
      "Epoch: 7, loss = -1.3777556762099263\n",
      "Epoch: 8, loss = -1.5374111399054526\n",
      "Epoch: 9, loss = -1.6184031039476396\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.3587887048721312\n",
      "Epoch: 1, loss = -1.3316776670515533\n",
      "Epoch: 2, loss = -1.3819821789860722\n",
      "Epoch: 3, loss = -1.5551929309964176\n",
      "Epoch: 4, loss = -1.6915380150079726\n",
      "Epoch: 5, loss = -1.7779162675142293\n",
      "Epoch: 6, loss = -1.8658031046390533\n",
      "Epoch: 7, loss = -1.8099815115332607\n",
      "Epoch: 8, loss = -1.9597948908805847\n",
      "Epoch: 9, loss = -1.9117520645260808\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.3548239096999166\n",
      "Epoch: 1, loss = -1.3937885977327824\n",
      "Epoch: 2, loss = -1.5880427062511446\n",
      "Epoch: 3, loss = -1.7398615926504135\n",
      "Epoch: 4, loss = -1.59135928042233\n",
      "Epoch: 5, loss = -1.1900317080318927\n",
      "Epoch: 6, loss = -1.6190669655799867\n",
      "Epoch: 7, loss = -1.5229298532009126\n",
      "Epoch: 8, loss = -1.629957509040833\n",
      "Epoch: 9, loss = -1.8514155477285381\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.9097310088574887\n",
      "Epoch: 1, loss = -1.2319112703204158\n",
      "Epoch: 2, loss = -1.4702215909957888\n",
      "Epoch: 3, loss = -1.375627866946161\n",
      "Epoch: 4, loss = -1.661068570613861\n",
      "Epoch: 5, loss = -1.6320249564945697\n",
      "Epoch: 6, loss = -1.7404843747615815\n",
      "Epoch: 7, loss = -1.7421922743320464\n",
      "Epoch: 8, loss = -1.86384849846363\n",
      "Epoch: 9, loss = -1.8232531994581223\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.7693425208330154\n",
      "Epoch: 1, loss = -0.9959335550665855\n",
      "Epoch: 2, loss = -1.1750018090009688\n",
      "Epoch: 3, loss = -1.265507084131241\n",
      "Epoch: 4, loss = -1.390875768661499\n",
      "Epoch: 5, loss = -1.4049002856016157\n",
      "Epoch: 6, loss = -1.4356039099395277\n",
      "Epoch: 7, loss = -1.6033711150288583\n",
      "Epoch: 8, loss = -1.6998062551021578\n",
      "Epoch: 9, loss = -1.825735613703728\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.704143696597644\n",
      "Epoch: 1, loss = -1.773395514913967\n",
      "Epoch: 2, loss = -1.7666819457496914\n",
      "Epoch: 3, loss = -1.8689326729093279\n",
      "Epoch: 4, loss = -1.9159589324678687\n",
      "Epoch: 5, loss = -1.9317514853818079\n",
      "Epoch: 6, loss = -1.9869756954056876\n",
      "Epoch: 7, loss = -2.009589844516345\n",
      "Epoch: 8, loss = -1.9550905238304817\n",
      "Epoch: 9, loss = -2.085133905921664\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.931903345244271\n",
      "Epoch: 1, loss = -1.5862667142812694\n",
      "Epoch: 2, loss = -1.7525865313197884\n",
      "Epoch: 3, loss = -1.4256084242037368\n",
      "Epoch: 4, loss = -1.6312836629471608\n",
      "Epoch: 5, loss = -1.8275565962706295\n",
      "Epoch: 6, loss = -2.003140856112752\n",
      "Epoch: 7, loss = -2.049489406602724\n",
      "Epoch: 8, loss = -2.0779419647795816\n",
      "Epoch: 9, loss = -2.093850040010043\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.6573395803570745\n",
      "Epoch: 1, loss = -1.3673900794237854\n",
      "Epoch: 2, loss = -1.8208696650607243\n",
      "Epoch: 3, loss = -1.9839521369763788\n",
      "Epoch: 4, loss = -2.05226044356823\n",
      "Epoch: 5, loss = -1.983779179198401\n",
      "Epoch: 6, loss = -1.9617218023964338\n",
      "Epoch: 7, loss = -2.1173312749181474\n",
      "Epoch: 8, loss = -1.9267257356217924\n",
      "Epoch: 9, loss = -2.1167219387633462\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.871648028492928\n",
      "Epoch: 1, loss = -1.906760726656233\n",
      "Epoch: 2, loss = -1.9360124628458706\n",
      "Epoch: 3, loss = -1.9331994141851148\n",
      "Epoch: 4, loss = -1.9450355640479495\n",
      "Epoch: 5, loss = -1.9139707663229528\n",
      "Epoch: 6, loss = -1.888749724520104\n",
      "Epoch: 7, loss = -1.8944603790129928\n",
      "Epoch: 8, loss = -2.0550273741994585\n",
      "Epoch: 9, loss = -2.086079816733088\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.7944107162100926\n",
      "Epoch: 1, loss = -1.8899647444486622\n",
      "Epoch: 2, loss = -1.986666351556778\n",
      "Epoch: 3, loss = -1.975076219865254\n",
      "Epoch: 4, loss = -1.9799914764506477\n",
      "Epoch: 5, loss = -2.0253902290548598\n",
      "Epoch: 6, loss = -2.090822141085352\n",
      "Epoch: 7, loss = -2.091720316026892\n",
      "Epoch: 8, loss = -2.117372778909547\n",
      "Epoch: 9, loss = -2.042620550841093\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.9883063861893286\n",
      "Epoch: 1, loss = -1.8851079336471028\n",
      "Epoch: 2, loss = -2.1250142123964104\n",
      "Epoch: 3, loss = -2.0534148472878675\n",
      "Epoch: 4, loss = -1.9564370885491371\n",
      "Epoch: 5, loss = -1.9641665551397525\n",
      "Epoch: 6, loss = -2.011508285999298\n",
      "Epoch: 7, loss = -2.0214377062188253\n",
      "Epoch: 8, loss = -2.0698867407109995\n",
      "Epoch: 9, loss = -2.083972689178254\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.9352359945575393\n",
      "Epoch: 1, loss = -2.010200588239564\n",
      "Epoch: 2, loss = -2.0645326127608614\n",
      "Epoch: 3, loss = -2.10923396382067\n",
      "Epoch: 4, loss = -2.1164427830113293\n",
      "Epoch: 5, loss = -2.1519279744890003\n",
      "Epoch: 6, loss = -2.1750934355788765\n",
      "Epoch: 7, loss = -2.1991611950927314\n",
      "Epoch: 8, loss = -2.228581661979357\n",
      "Epoch: 9, loss = -2.24318700697687\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -2.0976536472638454\n",
      "Epoch: 1, loss = -1.9791856225993898\n",
      "Epoch: 2, loss = -2.1072658002376548\n",
      "Epoch: 3, loss = -2.1790308041705027\n",
      "Epoch: 4, loss = -2.1940184016194597\n",
      "Epoch: 5, loss = -2.2500349399116297\n",
      "Epoch: 6, loss = -2.2959194928407665\n",
      "Epoch: 7, loss = -2.3441837165090775\n",
      "Epoch: 8, loss = -2.3847198742959246\n",
      "Epoch: 9, loss = -2.418815996911792\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.9220404976771936\n",
      "Epoch: 1, loss = -1.894671523736583\n",
      "Epoch: 2, loss = -2.0625783618953495\n",
      "Epoch: 3, loss = -2.1343561311562853\n",
      "Epoch: 4, loss = -1.9663645223610922\n",
      "Epoch: 5, loss = -2.072016757395532\n",
      "Epoch: 6, loss = -2.200431469413969\n",
      "Epoch: 7, loss = -2.144984189007017\n",
      "Epoch: 8, loss = -2.154127205411593\n",
      "Epoch: 9, loss = -2.2244356092479487\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.0768081388539743\n",
      "Epoch: 1, loss = -2.203132251898447\n",
      "Epoch: 2, loss = -2.248324281639522\n",
      "Epoch: 3, loss = -2.09230488207605\n",
      "Epoch: 4, loss = -2.232692057887713\n",
      "Epoch: 5, loss = -2.22975020772881\n",
      "Epoch: 6, loss = -2.3255015942785473\n",
      "Epoch: 7, loss = -2.3090734365913606\n",
      "Epoch: 8, loss = -2.3661257078250255\n",
      "Epoch: 9, loss = -2.4122092690732737\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7930283322930336\n",
      "Epoch: 1, loss = 0.7523109391331673\n",
      "Epoch: 2, loss = 0.7144019827246666\n",
      "Epoch: 3, loss = 0.6773763746023178\n",
      "Epoch: 4, loss = 0.6399806141853333\n",
      "Epoch: 5, loss = 0.6012193784117699\n",
      "Epoch: 6, loss = 0.5603281557559967\n",
      "Epoch: 7, loss = 0.5166700109839439\n",
      "Epoch: 8, loss = 0.46976394951343536\n",
      "Epoch: 9, loss = 0.4192032963037491\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.8313609808683395\n",
      "Epoch: 1, loss = 0.7619078308343887\n",
      "Epoch: 2, loss = 0.704172782599926\n",
      "Epoch: 3, loss = 0.653107076883316\n",
      "Epoch: 4, loss = 0.6046323701739311\n",
      "Epoch: 5, loss = 0.556377574801445\n",
      "Epoch: 6, loss = 0.5065088123083115\n",
      "Epoch: 7, loss = 0.45380761101841927\n",
      "Epoch: 8, loss = 0.397946335375309\n",
      "Epoch: 9, loss = 0.3385269083082676\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8141471296548843\n",
      "Epoch: 1, loss = 0.7787958979606628\n",
      "Epoch: 2, loss = 0.7446495071053505\n",
      "Epoch: 3, loss = 0.7103998884558678\n",
      "Epoch: 4, loss = 0.675416387617588\n",
      "Epoch: 5, loss = 0.6392217725515366\n",
      "Epoch: 6, loss = 0.6013956069946289\n",
      "Epoch: 7, loss = 0.5614079907536507\n",
      "Epoch: 8, loss = 0.5187893062829971\n",
      "Epoch: 9, loss = 0.4730595424771309\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7053331956267357\n",
      "Epoch: 1, loss = 0.6636583507061005\n",
      "Epoch: 2, loss = 0.6224204152822495\n",
      "Epoch: 3, loss = 0.5798479616641998\n",
      "Epoch: 4, loss = 0.535397220402956\n",
      "Epoch: 5, loss = 0.4886329509317875\n",
      "Epoch: 6, loss = 0.43916021287441254\n",
      "Epoch: 7, loss = 0.38655776903033257\n",
      "Epoch: 8, loss = 0.33041018806397915\n",
      "Epoch: 9, loss = 0.2702309973537922\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7818650752305984\n",
      "Epoch: 1, loss = 0.7420015409588814\n",
      "Epoch: 2, loss = 0.7046777978539467\n",
      "Epoch: 3, loss = 0.6686465293169022\n",
      "Epoch: 4, loss = 0.6327197402715683\n",
      "Epoch: 5, loss = 0.5960599407553673\n",
      "Epoch: 6, loss = 0.5581148713827133\n",
      "Epoch: 7, loss = 0.5184247605502605\n",
      "Epoch: 8, loss = 0.4766390211880207\n",
      "Epoch: 9, loss = 0.4324333593249321\n",
      "\n",
      "T = 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.44413199424743655\n",
      "Epoch: 1, loss = 0.24771065185777844\n",
      "Epoch: 2, loss = -0.033612817764515045\n",
      "Epoch: 3, loss = -0.4322574097663165\n",
      "Epoch: 4, loss = -0.9374657958745954\n",
      "Epoch: 5, loss = -1.347611603140831\n",
      "Epoch: 6, loss = -1.4589401572942737\n",
      "Epoch: 7, loss = -1.5183967612683775\n",
      "Epoch: 8, loss = -1.6118127509951596\n",
      "Epoch: 9, loss = -1.6641302913427354\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2759959906339645\n",
      "Epoch: 1, loss = -0.008207638701424004\n",
      "Epoch: 2, loss = -0.3941320285201073\n",
      "Epoch: 3, loss = -0.8534154206514356\n",
      "Epoch: 4, loss = -1.189074018597603\n",
      "Epoch: 5, loss = -1.424460193514824\n",
      "Epoch: 6, loss = -1.404942189902067\n",
      "Epoch: 7, loss = -1.4508722729980947\n",
      "Epoch: 8, loss = -1.6151409596204758\n",
      "Epoch: 9, loss = -1.668490944802761\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.4758018508553505\n",
      "Epoch: 1, loss = 0.30945291947573417\n",
      "Epoch: 2, loss = 0.06741091043222695\n",
      "Epoch: 3, loss = -0.2793239962309598\n",
      "Epoch: 4, loss = -0.7475153177976609\n",
      "Epoch: 5, loss = -1.0342924669384956\n",
      "Epoch: 6, loss = -1.1979473568499088\n",
      "Epoch: 7, loss = -1.5301144599914551\n",
      "Epoch: 8, loss = -1.650374233722687\n",
      "Epoch: 9, loss = -1.3457488931715487\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.34003687165677554\n",
      "Epoch: 1, loss = 0.1479939803946763\n",
      "Epoch: 2, loss = -0.14763327804394064\n",
      "Epoch: 3, loss = -0.49370371326804163\n",
      "Epoch: 4, loss = -0.9372757330536842\n",
      "Epoch: 5, loss = -1.2712268650531764\n",
      "Epoch: 6, loss = -0.6999694446101785\n",
      "Epoch: 7, loss = -0.8283812060952186\n",
      "Epoch: 8, loss = -0.8141350120306017\n",
      "Epoch: 9, loss = -1.0513617767021062\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3876972295343875\n",
      "Epoch: 1, loss = 0.19051094204187394\n",
      "Epoch: 2, loss = -0.08661448357161136\n",
      "Epoch: 3, loss = -0.4664172332733871\n",
      "Epoch: 4, loss = -0.8454285062849521\n",
      "Epoch: 5, loss = -1.0748904258012768\n",
      "Epoch: 6, loss = -1.2281959280371662\n",
      "Epoch: 7, loss = -1.4496985971927638\n",
      "Epoch: 8, loss = -1.5363791197538372\n",
      "Epoch: 9, loss = -0.8700051560997961\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.6073492293556542\n",
      "Epoch: 1, loss = -1.5695987886024845\n",
      "Epoch: 2, loss = -0.7688588429656293\n",
      "Epoch: 3, loss = -1.7144442896048229\n",
      "Epoch: 4, loss = -1.7439126488235257\n",
      "Epoch: 5, loss = -1.813191841046015\n",
      "Epoch: 6, loss = -1.786545744372739\n",
      "Epoch: 7, loss = -1.7120012164943752\n",
      "Epoch: 8, loss = -1.7703987804965844\n",
      "Epoch: 9, loss = -1.8933907987342942\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.528097023980485\n",
      "Epoch: 1, loss = -0.646523310078515\n",
      "Epoch: 2, loss = -1.5334873087704182\n",
      "Epoch: 3, loss = -1.7290314104821947\n",
      "Epoch: 4, loss = -1.8286628127098083\n",
      "Epoch: 5, loss = -1.8704619896080763\n",
      "Epoch: 6, loss = -1.915729894406266\n",
      "Epoch: 7, loss = -1.9377258626951106\n",
      "Epoch: 8, loss = -2.0022931206557493\n",
      "Epoch: 9, loss = -2.0717488543854823\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.6070469617843623\n",
      "Epoch: 1, loss = -1.6457817612422834\n",
      "Epoch: 2, loss = -1.8251300048496992\n",
      "Epoch: 3, loss = -1.959404134915935\n",
      "Epoch: 4, loss = -2.052592015928692\n",
      "Epoch: 5, loss = -2.045727848178811\n",
      "Epoch: 6, loss = -2.1256556080447297\n",
      "Epoch: 7, loss = -2.040979800952805\n",
      "Epoch: 8, loss = -2.2779328044917846\n",
      "Epoch: 9, loss = -1.8365698556105297\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.1771408793412979\n",
      "Epoch: 1, loss = -1.2748009311035275\n",
      "Epoch: 2, loss = -1.4971529344717662\n",
      "Epoch: 3, loss = -1.4662056747410033\n",
      "Epoch: 4, loss = -1.5747296238938966\n",
      "Epoch: 5, loss = -1.6977370273735792\n",
      "Epoch: 6, loss = -1.7304379575782356\n",
      "Epoch: 7, loss = -1.7793398913409977\n",
      "Epoch: 8, loss = -1.7961732794841136\n",
      "Epoch: 9, loss = -1.846572518348694\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.8581286047895751\n",
      "Epoch: 1, loss = -1.3216000248988464\n",
      "Epoch: 2, loss = -1.5279061628712547\n",
      "Epoch: 3, loss = -1.679110815127691\n",
      "Epoch: 4, loss = -1.7552213122447338\n",
      "Epoch: 5, loss = -1.6255278868807685\n",
      "Epoch: 6, loss = -1.5947633269760346\n",
      "Epoch: 7, loss = -1.7485432198478112\n",
      "Epoch: 8, loss = -1.9293851554393764\n",
      "Epoch: 9, loss = -1.9842551350593571\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.752308944096932\n",
      "Epoch: 1, loss = -1.9689128238421227\n",
      "Epoch: 2, loss = -1.8960211589359315\n",
      "Epoch: 3, loss = -2.0441141224537898\n",
      "Epoch: 4, loss = -2.0964489556275883\n",
      "Epoch: 5, loss = -2.149504402509103\n",
      "Epoch: 6, loss = -2.213998842697877\n",
      "Epoch: 7, loss = -2.246205878945497\n",
      "Epoch: 8, loss = -2.3247767640994157\n",
      "Epoch: 9, loss = -2.3356451690196987\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.747139114599961\n",
      "Epoch: 1, loss = -1.7377845163528736\n",
      "Epoch: 2, loss = -1.9546346125694432\n",
      "Epoch: 3, loss = -1.9263984368970763\n",
      "Epoch: 4, loss = -2.0001979126380043\n",
      "Epoch: 5, loss = -2.0463576540350914\n",
      "Epoch: 6, loss = -2.099626506750401\n",
      "Epoch: 7, loss = -2.153071704965371\n",
      "Epoch: 8, loss = -2.211499521078972\n",
      "Epoch: 9, loss = -2.260499407179081\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.9874808444426606\n",
      "Epoch: 1, loss = -2.1886171371890937\n",
      "Epoch: 2, loss = -2.3300467798343076\n",
      "Epoch: 3, loss = -2.3424996561728992\n",
      "Epoch: 4, loss = -2.3841490138035555\n",
      "Epoch: 5, loss = -2.442193870361034\n",
      "Epoch: 6, loss = -2.4481962007971925\n",
      "Epoch: 7, loss = -2.4876051052258568\n",
      "Epoch: 8, loss = -2.544793783472134\n",
      "Epoch: 9, loss = -2.584803933707568\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.780050972906442\n",
      "Epoch: 1, loss = -1.9015048937155645\n",
      "Epoch: 2, loss = -1.9320839093281665\n",
      "Epoch: 3, loss = -1.9696931214286733\n",
      "Epoch: 4, loss = -2.020469712523314\n",
      "Epoch: 5, loss = -2.05725111755041\n",
      "Epoch: 6, loss = -2.1053868916172247\n",
      "Epoch: 7, loss = -2.150812989244095\n",
      "Epoch: 8, loss = -2.196452946617054\n",
      "Epoch: 9, loss = -2.2384737638326797\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.8166404039813928\n",
      "Epoch: 1, loss = -1.9591965274168894\n",
      "Epoch: 2, loss = -1.9844874149331684\n",
      "Epoch: 3, loss = -2.0135674545398126\n",
      "Epoch: 4, loss = -2.0353340724339857\n",
      "Epoch: 5, loss = -2.0496817385921102\n",
      "Epoch: 6, loss = -2.065669942360658\n",
      "Epoch: 7, loss = -2.087063753834137\n",
      "Epoch: 8, loss = -2.122256511679063\n",
      "Epoch: 9, loss = -2.1692816890203037\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -2.157395238166347\n",
      "Epoch: 1, loss = -2.4327647361685236\n",
      "Epoch: 2, loss = -2.367438393371072\n",
      "Epoch: 3, loss = -2.2385317407110157\n",
      "Epoch: 4, loss = -2.4627308193594226\n",
      "Epoch: 5, loss = -2.5013672680977512\n",
      "Epoch: 6, loss = -2.291912930634092\n",
      "Epoch: 7, loss = -2.5341134667396554\n",
      "Epoch: 8, loss = -2.5749005784883217\n",
      "Epoch: 9, loss = -2.385188549318735\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -2.028088011285838\n",
      "Epoch: 1, loss = -2.0450370218604803\n",
      "Epoch: 2, loss = -2.1389181587625954\n",
      "Epoch: 3, loss = -2.2122012262835224\n",
      "Epoch: 4, loss = -2.1305820529951753\n",
      "Epoch: 5, loss = -2.283156904227595\n",
      "Epoch: 6, loss = -2.219821103355463\n",
      "Epoch: 7, loss = -2.2852856306468734\n",
      "Epoch: 8, loss = -2.2776681960505596\n",
      "Epoch: 9, loss = -2.3700766642304036\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -2.4847693327156923\n",
      "Epoch: 1, loss = -2.4669778789667527\n",
      "Epoch: 2, loss = -2.5962788006838626\n",
      "Epoch: 3, loss = -2.6623512375004164\n",
      "Epoch: 4, loss = -2.6987465663867845\n",
      "Epoch: 5, loss = -2.7702905763598062\n",
      "Epoch: 6, loss = -2.8086445603300554\n",
      "Epoch: 7, loss = -2.854288804180482\n",
      "Epoch: 8, loss = -2.8888572962845074\n",
      "Epoch: 9, loss = -2.9204405423472903\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -2.090973861077253\n",
      "Epoch: 1, loss = -2.2297913140672088\n",
      "Epoch: 2, loss = -2.2893364902804887\n",
      "Epoch: 3, loss = -2.252687847570461\n",
      "Epoch: 4, loss = -2.339068117825424\n",
      "Epoch: 5, loss = -2.3735963956398125\n",
      "Epoch: 6, loss = -2.42734386991052\n",
      "Epoch: 7, loss = -2.506223286775982\n",
      "Epoch: 8, loss = -2.535380229353905\n",
      "Epoch: 9, loss = -2.591726824641229\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.0351461005561493\n",
      "Epoch: 1, loss = -2.253165525548597\n",
      "Epoch: 2, loss = -2.4291174630908388\n",
      "Epoch: 3, loss = -2.423826450810713\n",
      "Epoch: 4, loss = -2.4836954895187837\n",
      "Epoch: 5, loss = -2.5084632740301243\n",
      "Epoch: 6, loss = -2.4866293966770168\n",
      "Epoch: 7, loss = -2.5950502700665425\n",
      "Epoch: 8, loss = -2.4867877302800907\n",
      "Epoch: 9, loss = -2.667599223115865\n"
     ]
    }
   ],
   "source": [
    "frac_err_AL_ens = []\n",
    "device = torch.device(\"cpu\")\n",
    "K_train_list = [16, 32, 64, 128, 256, 512] # make it as a global variable\n",
    "N_test = 512\n",
    "ninit=128\n",
    "T=4\n",
    "for i in range(len(K_train_list)):\n",
    "\n",
    "    # Update dictiorary for the correct amount of points\n",
    "    config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "    config_AL[\"num_init\"] = ninit\n",
    "    config_AL[\"K\"] = K_train_list[i]\n",
    "    config_AL[\"M\"] = 4\n",
    "    config_AL[\"T\"] = T\n",
    "\n",
    "    # Instantiate the class object and train the model\n",
    "    uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "    uq_model = uq_model.fit()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1be754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11695072001951151]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "filepath='/workspace/malathi/mm/active_learning_weights.h5'\n",
    "torch.save(uq_model,filepath)\n",
    "\n",
    "# load the saved model\n",
    "uq_model_loaded = torch.load('active_learning_weights.h5')\n",
    "\n",
    "          \n",
    "# Create a test dataset\n",
    "X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "y_test = np.reshape(y_test, (-1,))\n",
    "\n",
    "res = uq_model_loaded.predict(X_test)\n",
    "y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "frac_err_AL_ens.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "\n",
    "# this error is the last one(best one) in the error_list if you see the below code\n",
    "frac_err_AL_ens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b2e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
