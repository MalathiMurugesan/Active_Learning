{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq360 version 0.2 needs to be installed\n",
    "#!pip install uq360\n",
    "\n",
    "# results are same if we select 60K or 10K points the graphs look same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6743d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the libraries are found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from uq360.metrics import picp, mpiw, compute_regression_metrics\n",
    "    from uq360.metrics import UncertaintyCharacteristicsCurve as ucc\n",
    "\n",
    "    from uq360.algorithms import * \n",
    "    from uq360.algorithms.actively_learned_model import ActivelyLearnedModel\n",
    "    from uq360.algorithms.ensemble_heteroscedastic_regression import EnsembleHeteroscedasticRegression\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print('All the libraries are found')\n",
    "    \n",
    "except:\n",
    "    print(\"One or more libraries need to be installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d413a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/data/MGP/TestPointsN2_CH4_H2O_000.xlsx'\n",
    "df=pd.read_excel(file_name,header=1).dropna(how='all', axis=1)\n",
    "df.drop('#',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed02bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    \n",
    "    #xls_new = pd.ExcelFile(file_name)\n",
    "    df=pd.read_excel(file_name,header=1).dropna(how='all', axis=1)\n",
    "    df.drop('#',axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = read_data(r'/data/MGP/TestPointsN2_CH4_H2O_000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac7b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63116, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82295a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_col(df,col1,col2):\n",
    "    phi_surge = 0.076\n",
    "    df[col2] = 100*(df[col1]-phi_surge)/phi_surge\n",
    "    \n",
    "    return df\n",
    "\n",
    "col1 = 'phi'\n",
    "col2 = 'surge_distance_from_eq'\n",
    "data = create_new_col(data,col1,col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caadd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df,columns,input_columns,output_columns):\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    df = pd.concat([df[input_columns],df[output_columns]],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c73908",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Pin [kPa]','Tin [K]','N [rpm]','Differential Pressure [kPa]','Total Consumed power','phi',\n",
    "         'Surge Distance','surge_distance_from_eq','GVFin','Qin [m3/s]','GVFout','Qv_out [m3/s]']\n",
    "INPUT_C = ['Pin [kPa]','Tin [K]','N [rpm]','Differential Pressure [kPa]','Total Consumed power']\n",
    "OUTPUT_C = ['surge_distance_from_eq']\n",
    "data_1 = select_columns(data,columns,INPUT_C,OUTPUT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1886282a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63116, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data and select the number of samples to be considered\n",
    "def scale_data(df,samples):\n",
    "    df_1 = df[0:samples]\n",
    "    df_x = df_1.iloc[:, :-1].values\n",
    "    y_labels = np.squeeze(df_1.iloc[:, -1:].values, axis=1)\n",
    "    y_labels = y_labels.reshape((-1,1))\n",
    "\n",
    "    # scale the values\n",
    "    scaler = StandardScaler()\n",
    "    scaling = scaler.fit(df_x)\n",
    "    x_data = scaling.transform(df_x)\n",
    "    \n",
    "    \n",
    "    return df, y_labels, x_data\n",
    "\n",
    "data,y_labels,x_data = scale_data(data_1,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e41d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Offline sample and query, two mandatory arguments (and the data):\n",
    "    - Position where to start sampling\n",
    "    - Number of points to sample\n",
    "'''\n",
    "def sample_(start_index, n_points, X_data=x_data):\n",
    "    return x_data[start_index:start_index+n_points,:]\n",
    "\n",
    "def querry_(start_index, n_points, y_labels=y_labels):\n",
    "    return y_labels[start_index:start_index+n_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed8f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configuration for both models, regression baseline and regression with Active Learning\n",
    "def config_():\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # define config for Heteroscedastic regression\n",
    "    config_HR = {\"num_features\": 5, \"num_hidden\": 32, \"num_outputs\": 1, \"batch_size\": 16, \"num_epochs\": 10,\n",
    "                      \"lr\": 0.001}\n",
    "    HR_kwargs = {\"model_type\":'mlp',\n",
    "                   \"config\": config_HR,\n",
    "                   \"device\": device}\n",
    "    # define config for ensemble\n",
    "    config_ensemble = {\"num_models\": 1, \n",
    "              \"batch_size\": 16,\n",
    "              \"model_kwargs\":HR_kwargs, }\n",
    "\n",
    "    ninit = 128 \n",
    "    T = 2 #4 # do not change this,\n",
    "    # define config for active learning object\n",
    "    # T = # no of iterations\n",
    "    # K = # no of uncertain points\n",
    "    #K=64\n",
    "    config_AL = {\"num_init\": 512 , \n",
    "     \"T\": 2, \n",
    "     \"K\": 16, \n",
    "     \"M\": 4, \n",
    "     \"sampling_function\": sample_, \n",
    "     \"querry_function\" : querry_,\n",
    "     \"model_function\": EnsembleHeteroscedasticRegression,\n",
    "     \"model_kwargs\": {\"model_type\":'ensembleheteroscedasticregression', \n",
    "                                                 \"config\":config_ensemble, \n",
    "                                                 \"device\":device}, }\n",
    "    \n",
    "    return config_HR,HR_kwargs,config_AL\n",
    "config_HR,HR_kwargs,config_AL = config_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e82f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the data set has the good dimension\n",
    "def verify_dimension(data_x,config_AL,config_HR):\n",
    "    \n",
    "    assert(data_x.shape[0] >= config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"])\n",
    "    assert(data_x.shape[1] == config_HR[\"num_features\"])\n",
    "    \n",
    "    return True\n",
    "\n",
    "verify_dimension(x_data,config_AL,config_HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f16289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import al_model\n",
    "from al_model import ActivelyLearnedModel\n",
    "\n",
    "def baseline(config_AL):\n",
    "    # Baseline without AL\n",
    "    \n",
    "    K_train_list = [8,16, 32, 64, 128, 256,512,1024]  # T=2 better graph\n",
    "    #K_train_list = [10,20,40,80,160,320,640,1280]   # T=2 better graph\n",
    "    \n",
    "    frac_err_baseline = []\n",
    "    ninit=128\n",
    "    N_test = 512\n",
    "    device = torch.device(\"cpu\")\n",
    "    T=2\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary to have no active learning and the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit + K_train_list[i] * T\n",
    "        print(config_AL[\"num_init\"])\n",
    "        config_AL[\"T\"] = 0  # no AL here\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit() \n",
    "\n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "        print(X_test.shape,y_test.shape)\n",
    "\n",
    "        res = uq_model.predict(X_test) \n",
    "        \n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_baseline.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        print('iteration---------',i)\n",
    "        \n",
    "    return  frac_err_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8623052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "(144, 5) (144, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 1339.5959472656252\n",
      "Epoch: 1, loss = 1230.609219021267\n",
      "Epoch: 2, loss = 1138.1463216145833\n",
      "Epoch: 3, loss = 1059.0402018229167\n",
      "Epoch: 4, loss = 990.7792426215276\n",
      "Epoch: 5, loss = 931.0671488444011\n",
      "Epoch: 6, loss = 877.9655015733506\n",
      "Epoch: 7, loss = 830.0348239474826\n",
      "Epoch: 8, loss = 786.2442660861547\n",
      "Epoch: 9, loss = 745.7560356987847\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 1093.1488037109375\n",
      "Epoch: 1, loss = 1012.4629380967881\n",
      "Epoch: 2, loss = 941.2650553385419\n",
      "Epoch: 3, loss = 877.8430955674913\n",
      "Epoch: 4, loss = 821.1180623372397\n",
      "Epoch: 5, loss = 770.0280253092448\n",
      "Epoch: 6, loss = 723.4728190104166\n",
      "Epoch: 7, loss = 680.8946228027344\n",
      "Epoch: 8, loss = 641.7275288899739\n",
      "Epoch: 9, loss = 605.594723171658\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 1159.1131117078994\n",
      "Epoch: 1, loss = 1068.4368218315974\n",
      "Epoch: 2, loss = 989.362772623698\n",
      "Epoch: 3, loss = 919.8985358344185\n",
      "Epoch: 4, loss = 858.6429578993055\n",
      "Epoch: 5, loss = 804.3587578667534\n",
      "Epoch: 6, loss = 755.9063991970486\n",
      "Epoch: 7, loss = 712.2912936740452\n",
      "Epoch: 8, loss = 672.7546624077689\n",
      "Epoch: 9, loss = 636.6910536024305\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1082.2735866970486\n",
      "Epoch: 1, loss = 1015.6304456922744\n",
      "Epoch: 2, loss = 956.6724243164064\n",
      "Epoch: 3, loss = 904.0189853244358\n",
      "Epoch: 4, loss = 856.6976148817274\n",
      "Epoch: 5, loss = 813.7522447374132\n",
      "Epoch: 6, loss = 774.3416273328992\n",
      "Epoch: 7, loss = 737.8622436523438\n",
      "Epoch: 8, loss = 703.9153103298611\n",
      "Epoch: 9, loss = 672.1573757595486\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 972.0327419704861\n",
      "Epoch: 1, loss = 900.9290262858073\n",
      "Epoch: 2, loss = 838.5811089409723\n",
      "Epoch: 3, loss = 783.3475409613716\n",
      "Epoch: 4, loss = 734.2505866156685\n",
      "Epoch: 5, loss = 690.2228597005209\n",
      "Epoch: 6, loss = 650.3597479926216\n",
      "Epoch: 7, loss = 613.8419291178385\n",
      "Epoch: 8, loss = 580.263682047526\n",
      "Epoch: 9, loss = 549.3331841362847\n",
      "(512, 5) (512,)\n",
      "iteration--------- 0\n",
      "160\n",
      "(160, 5) (160, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 882.50859375\n",
      "Epoch: 1, loss = 821.3185913085938\n",
      "Epoch: 2, loss = 767.3850677490235\n",
      "Epoch: 3, loss = 719.1618408203125\n",
      "Epoch: 4, loss = 675.5511047363282\n",
      "Epoch: 5, loss = 635.7135131835938\n",
      "Epoch: 6, loss = 598.9176452636718\n",
      "Epoch: 7, loss = 564.7230224609375\n",
      "Epoch: 8, loss = 532.874478149414\n",
      "Epoch: 9, loss = 503.1114929199219\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 952.1072784423828\n",
      "Epoch: 1, loss = 864.0552062988281\n",
      "Epoch: 2, loss = 788.9970001220704\n",
      "Epoch: 3, loss = 724.595184326172\n",
      "Epoch: 4, loss = 668.9012481689452\n",
      "Epoch: 5, loss = 620.2309387207031\n",
      "Epoch: 6, loss = 577.2549530029297\n",
      "Epoch: 7, loss = 538.9963592529297\n",
      "Epoch: 8, loss = 504.7407333374024\n",
      "Epoch: 9, loss = 473.92133483886715\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 819.7340759277345\n",
      "Epoch: 1, loss = 765.5364593505859\n",
      "Epoch: 2, loss = 716.8229553222658\n",
      "Epoch: 3, loss = 672.4264251708984\n",
      "Epoch: 4, loss = 631.6969024658204\n",
      "Epoch: 5, loss = 594.1743255615235\n",
      "Epoch: 6, loss = 559.5123046875\n",
      "Epoch: 7, loss = 527.3482849121094\n",
      "Epoch: 8, loss = 497.41986999511715\n",
      "Epoch: 9, loss = 469.5227447509766\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1008.7223449707033\n",
      "Epoch: 1, loss = 924.905340576172\n",
      "Epoch: 2, loss = 853.0080200195313\n",
      "Epoch: 3, loss = 790.9037506103516\n",
      "Epoch: 4, loss = 736.9481964111328\n",
      "Epoch: 5, loss = 689.4773132324218\n",
      "Epoch: 6, loss = 647.1974639892578\n",
      "Epoch: 7, loss = 609.2098175048827\n",
      "Epoch: 8, loss = 574.7482482910157\n",
      "Epoch: 9, loss = 543.2688812255859\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1008.7081420898438\n",
      "Epoch: 1, loss = 934.6851043701172\n",
      "Epoch: 2, loss = 868.9210876464845\n",
      "Epoch: 3, loss = 809.7014434814454\n",
      "Epoch: 4, loss = 756.3710571289063\n",
      "Epoch: 5, loss = 708.1307220458983\n",
      "Epoch: 6, loss = 664.2665496826172\n",
      "Epoch: 7, loss = 624.1395904541016\n",
      "Epoch: 8, loss = 587.3445190429687\n",
      "Epoch: 9, loss = 553.4993896484375\n",
      "(512, 5) (512,)\n",
      "iteration--------- 1\n",
      "192\n",
      "(192, 5) (192, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 830.3148040771484\n",
      "Epoch: 1, loss = 763.0236206054688\n",
      "Epoch: 2, loss = 705.1840108235677\n",
      "Epoch: 3, loss = 654.2455800374348\n",
      "Epoch: 4, loss = 608.5687713623047\n",
      "Epoch: 5, loss = 567.0647430419922\n",
      "Epoch: 6, loss = 529.0538279215494\n",
      "Epoch: 7, loss = 494.1242192586262\n",
      "Epoch: 8, loss = 462.00592041015625\n",
      "Epoch: 9, loss = 432.43460845947266\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 888.2414830525717\n",
      "Epoch: 1, loss = 793.4170735677083\n",
      "Epoch: 2, loss = 715.0792617797853\n",
      "Epoch: 3, loss = 649.3289794921875\n",
      "Epoch: 4, loss = 593.3679428100587\n",
      "Epoch: 5, loss = 545.0907414754232\n",
      "Epoch: 6, loss = 502.96907806396484\n",
      "Epoch: 7, loss = 465.9418245951335\n",
      "Epoch: 8, loss = 433.1602592468262\n",
      "Epoch: 9, loss = 404.0047861735026\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 763.9989674886067\n",
      "Epoch: 1, loss = 704.7145741780599\n",
      "Epoch: 2, loss = 652.5413970947267\n",
      "Epoch: 3, loss = 605.6554539998373\n",
      "Epoch: 4, loss = 563.217394510905\n",
      "Epoch: 5, loss = 524.5650431315104\n",
      "Epoch: 6, loss = 489.21810277303047\n",
      "Epoch: 7, loss = 456.77769088745106\n",
      "Epoch: 8, loss = 426.9285761515299\n",
      "Epoch: 9, loss = 399.45609792073566\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 943.397689819336\n",
      "Epoch: 1, loss = 852.4138565063475\n",
      "Epoch: 2, loss = 776.7289784749348\n",
      "Epoch: 3, loss = 712.8208923339844\n",
      "Epoch: 4, loss = 658.1840794881186\n",
      "Epoch: 5, loss = 610.6518580118815\n",
      "Epoch: 6, loss = 568.7853622436522\n",
      "Epoch: 7, loss = 531.4367701212566\n",
      "Epoch: 8, loss = 497.7875569661458\n",
      "Epoch: 9, loss = 467.2719802856446\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 942.1561787923177\n",
      "Epoch: 1, loss = 862.0452346801758\n",
      "Epoch: 2, loss = 792.2148971557617\n",
      "Epoch: 3, loss = 730.3372243245443\n",
      "Epoch: 4, loss = 675.3806355794271\n",
      "Epoch: 5, loss = 626.2705739339193\n",
      "Epoch: 6, loss = 582.0184911092122\n",
      "Epoch: 7, loss = 542.0424168904623\n",
      "Epoch: 8, loss = 505.7485733032226\n",
      "Epoch: 9, loss = 472.7329864501953\n",
      "(512, 5) (512,)\n",
      "iteration--------- 2\n",
      "256\n",
      "(256, 5) (256, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 830.1729755401611\n",
      "Epoch: 1, loss = 742.6242733001709\n",
      "Epoch: 2, loss = 670.2146701812744\n",
      "Epoch: 3, loss = 608.2415809631348\n",
      "Epoch: 4, loss = 553.8851699829102\n",
      "Epoch: 5, loss = 505.5382785797119\n",
      "Epoch: 6, loss = 462.18032455444336\n",
      "Epoch: 7, loss = 423.4003734588623\n",
      "Epoch: 8, loss = 388.67849349975586\n",
      "Epoch: 9, loss = 357.63154315948486\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 878.7822170257568\n",
      "Epoch: 1, loss = 760.3611164093018\n",
      "Epoch: 2, loss = 666.9982891082764\n",
      "Epoch: 3, loss = 591.8748531341553\n",
      "Epoch: 4, loss = 529.9639339447021\n",
      "Epoch: 5, loss = 478.04821014404297\n",
      "Epoch: 6, loss = 433.966365814209\n",
      "Epoch: 7, loss = 396.1751356124878\n",
      "Epoch: 8, loss = 363.4598608016968\n",
      "Epoch: 9, loss = 335.02644443511963\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 761.501054763794\n",
      "Epoch: 1, loss = 684.5067672729492\n",
      "Epoch: 2, loss = 618.7366542816162\n",
      "Epoch: 3, loss = 561.4894618988037\n",
      "Epoch: 4, loss = 511.17380714416504\n",
      "Epoch: 5, loss = 466.5693988800049\n",
      "Epoch: 6, loss = 426.8486375808716\n",
      "Epoch: 7, loss = 391.32091522216797\n",
      "Epoch: 8, loss = 359.6202201843262\n",
      "Epoch: 9, loss = 331.3529815673828\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 928.7342376708984\n",
      "Epoch: 1, loss = 815.567060470581\n",
      "Epoch: 2, loss = 725.794111251831\n",
      "Epoch: 3, loss = 653.1245059967041\n",
      "Epoch: 4, loss = 592.6911354064941\n",
      "Epoch: 5, loss = 541.1999492645264\n",
      "Epoch: 6, loss = 496.59205055236816\n",
      "Epoch: 7, loss = 457.3916931152344\n",
      "Epoch: 8, loss = 422.5753993988037\n",
      "Epoch: 9, loss = 391.4497947692871\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 942.2236404418945\n",
      "Epoch: 1, loss = 840.8072128295898\n",
      "Epoch: 2, loss = 754.7539539337158\n",
      "Epoch: 3, loss = 680.9360065460205\n",
      "Epoch: 4, loss = 617.0206661224365\n",
      "Epoch: 5, loss = 561.1886768341064\n",
      "Epoch: 6, loss = 512.0322494506836\n",
      "Epoch: 7, loss = 468.6468315124512\n",
      "Epoch: 8, loss = 430.385009765625\n",
      "Epoch: 9, loss = 396.6424732208252\n",
      "(512, 5) (512,)\n",
      "iteration--------- 3\n",
      "384\n",
      "(384, 5) (384, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 814.4134928385416\n",
      "Epoch: 1, loss = 696.8223203023274\n",
      "Epoch: 2, loss = 604.5288632710775\n",
      "Epoch: 3, loss = 527.7386042277019\n",
      "Epoch: 4, loss = 462.4685611724853\n",
      "Epoch: 5, loss = 406.82611719767254\n",
      "Epoch: 6, loss = 359.6029961903889\n",
      "Epoch: 7, loss = 319.57368151346844\n",
      "Epoch: 8, loss = 285.7239290873209\n",
      "Epoch: 9, loss = 257.096025466919\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 867.0015970865884\n",
      "Epoch: 1, loss = 704.8658472696941\n",
      "Epoch: 2, loss = 589.6626981099446\n",
      "Epoch: 3, loss = 503.2168591817221\n",
      "Epoch: 4, loss = 435.7899328867595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss = 381.9777914683024\n",
      "Epoch: 6, loss = 338.32680066426593\n",
      "Epoch: 7, loss = 302.54032834370935\n",
      "Epoch: 8, loss = 272.85818862915033\n",
      "Epoch: 9, loss = 247.94705645243323\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 759.3615201314291\n",
      "Epoch: 1, loss = 651.3670476277667\n",
      "Epoch: 2, loss = 564.3905232747395\n",
      "Epoch: 3, loss = 492.19024785359704\n",
      "Epoch: 4, loss = 431.4542719523112\n",
      "Epoch: 5, loss = 380.10530853271484\n",
      "Epoch: 6, loss = 336.8119335174561\n",
      "Epoch: 7, loss = 300.3490091959635\n",
      "Epoch: 8, loss = 269.5759569803874\n",
      "Epoch: 9, loss = 243.56820551554358\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 924.4806709289552\n",
      "Epoch: 1, loss = 768.8586273193358\n",
      "Epoch: 2, loss = 655.981669108073\n",
      "Epoch: 3, loss = 569.4523035685221\n",
      "Epoch: 4, loss = 499.9615828196208\n",
      "Epoch: 5, loss = 442.40200297037774\n",
      "Epoch: 6, loss = 393.8150018056234\n",
      "Epoch: 7, loss = 352.5420627593994\n",
      "Epoch: 8, loss = 317.4135106404622\n",
      "Epoch: 9, loss = 287.45487213134766\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 938.7757466634114\n",
      "Epoch: 1, loss = 795.5588912963865\n",
      "Epoch: 2, loss = 683.058380126953\n",
      "Epoch: 3, loss = 592.3082656860352\n",
      "Epoch: 4, loss = 517.825299580892\n",
      "Epoch: 5, loss = 456.0482756296794\n",
      "Epoch: 6, loss = 404.51555315653474\n",
      "Epoch: 7, loss = 361.29622650146496\n",
      "Epoch: 8, loss = 324.88408279418945\n",
      "Epoch: 9, loss = 294.03942044576013\n",
      "(512, 5) (512,)\n",
      "iteration--------- 4\n",
      "640\n",
      "(640, 5) (640, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 791.614559173584\n",
      "Epoch: 1, loss = 611.4147544860839\n",
      "Epoch: 2, loss = 485.01753463745104\n",
      "Epoch: 3, loss = 390.75274391174315\n",
      "Epoch: 4, loss = 320.2558025360107\n",
      "Epoch: 5, loss = 267.06499748229976\n",
      "Epoch: 6, loss = 226.62385482788093\n",
      "Epoch: 7, loss = 195.3562498092651\n",
      "Epoch: 8, loss = 170.78220443725587\n",
      "Epoch: 9, loss = 151.05873622894288\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 820.0585632324219\n",
      "Epoch: 1, loss = 596.7796241760253\n",
      "Epoch: 2, loss = 460.75957908630375\n",
      "Epoch: 3, loss = 369.4566688537598\n",
      "Epoch: 4, loss = 305.0504947662354\n",
      "Epoch: 5, loss = 258.00844955444336\n",
      "Epoch: 6, loss = 222.47834720611573\n",
      "Epoch: 7, loss = 194.82033729553217\n",
      "Epoch: 8, loss = 172.73349361419676\n",
      "Epoch: 9, loss = 154.7247837066651\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 724.2401412963868\n",
      "Epoch: 1, loss = 562.7863914489745\n",
      "Epoch: 2, loss = 448.15275077819825\n",
      "Epoch: 3, loss = 363.3498001098634\n",
      "Epoch: 4, loss = 299.8983291625976\n",
      "Epoch: 5, loss = 252.07669258117676\n",
      "Epoch: 6, loss = 215.4822086334228\n",
      "Epoch: 7, loss = 187.01153259277345\n",
      "Epoch: 8, loss = 164.40758571624755\n",
      "Epoch: 9, loss = 146.13900661468506\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 883.3078361511232\n",
      "Epoch: 1, loss = 661.6238357543945\n",
      "Epoch: 2, loss = 524.7879791259764\n",
      "Epoch: 3, loss = 428.4444976806641\n",
      "Epoch: 4, loss = 356.04141235351574\n",
      "Epoch: 5, loss = 300.4973197937012\n",
      "Epoch: 6, loss = 257.4867597579956\n",
      "Epoch: 7, loss = 223.7986179351806\n",
      "Epoch: 8, loss = 196.8658798217774\n",
      "Epoch: 9, loss = 174.99501152038576\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 904.5363937377931\n",
      "Epoch: 1, loss = 696.9375984191895\n",
      "Epoch: 2, loss = 552.1134162902832\n",
      "Epoch: 3, loss = 446.76477546691893\n",
      "Epoch: 4, loss = 368.4601566314697\n",
      "Epoch: 5, loss = 309.6007904052734\n",
      "Epoch: 6, loss = 264.697599029541\n",
      "Epoch: 7, loss = 229.8043947219848\n",
      "Epoch: 8, loss = 202.13923034667962\n",
      "Epoch: 9, loss = 179.79850769042966\n",
      "(512, 5) (512,)\n",
      "iteration--------- 5\n",
      "1152\n",
      "(1152, 5) (1152, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 714.2793379889595\n",
      "Epoch: 1, loss = 466.1013899909127\n",
      "Epoch: 2, loss = 321.1135908762614\n",
      "Epoch: 3, loss = 233.84375180138485\n",
      "Epoch: 4, loss = 179.61365477244073\n",
      "Epoch: 5, loss = 143.78866714901397\n",
      "Epoch: 6, loss = 118.68117157618208\n",
      "Epoch: 7, loss = 100.11982817120023\n",
      "Epoch: 8, loss = 85.86470450295339\n",
      "Epoch: 9, loss = 74.5756400956048\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 726.0907406277125\n",
      "Epoch: 1, loss = 442.9210648006863\n",
      "Epoch: 2, loss = 306.3374212053086\n",
      "Epoch: 3, loss = 229.24022939470078\n",
      "Epoch: 4, loss = 181.0242929458618\n",
      "Epoch: 5, loss = 148.24426672193738\n",
      "Epoch: 6, loss = 124.51076889038087\n",
      "Epoch: 7, loss = 106.48871766196352\n",
      "Epoch: 8, loss = 92.32920837402345\n",
      "Epoch: 9, loss = 80.93010658688019\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 657.9206509060328\n",
      "Epoch: 1, loss = 432.53910424974237\n",
      "Epoch: 2, loss = 301.9572294023301\n",
      "Epoch: 3, loss = 223.12605306837298\n",
      "Epoch: 4, loss = 173.41067451900912\n",
      "Epoch: 5, loss = 140.11151737636993\n",
      "Epoch: 6, loss = 116.3830974366929\n",
      "Epoch: 7, loss = 98.64359739091663\n",
      "Epoch: 8, loss = 84.90614440706041\n",
      "Epoch: 9, loss = 73.97734705607098\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 785.1458468967014\n",
      "Epoch: 1, loss = 503.02255566914874\n",
      "Epoch: 2, loss = 355.90547858344195\n",
      "Epoch: 3, loss = 265.0126675499811\n",
      "Epoch: 4, loss = 206.52407805124918\n",
      "Epoch: 5, loss = 166.95624891916913\n",
      "Epoch: 6, loss = 138.84205214182532\n",
      "Epoch: 7, loss = 117.90912474526297\n",
      "Epoch: 8, loss = 101.72205951478745\n",
      "Epoch: 9, loss = 88.85500065485637\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 810.8708703782827\n",
      "Epoch: 1, loss = 527.1525944603817\n",
      "Epoch: 2, loss = 367.05796623229975\n",
      "Epoch: 3, loss = 271.38050121731226\n",
      "Epoch: 4, loss = 211.13971953921842\n",
      "Epoch: 5, loss = 170.77477603488492\n",
      "Epoch: 6, loss = 142.15181430180863\n",
      "Epoch: 7, loss = 120.87495390574131\n",
      "Epoch: 8, loss = 104.43711339102855\n",
      "Epoch: 9, loss = 91.38486978742813\n",
      "(512, 5) (512,)\n",
      "iteration--------- 6\n",
      "2176\n",
      "(2176, 5) (2176, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 602.4348432877487\n",
      "Epoch: 1, loss = 292.1477274614223\n",
      "Epoch: 2, loss = 172.07318502313953\n",
      "Epoch: 3, loss = 116.85076839783613\n",
      "Epoch: 4, loss = 85.92743556639726\n",
      "Epoch: 5, loss = 66.25705075263976\n",
      "Epoch: 6, loss = 52.767532965716185\n",
      "Epoch: 7, loss = 43.10830424813664\n",
      "Epoch: 8, loss = 36.01476087289701\n",
      "Epoch: 9, loss = 30.720912351327787\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 596.2768016142006\n",
      "Epoch: 1, loss = 280.8117759367998\n",
      "Epoch: 2, loss = 173.64816732967606\n",
      "Epoch: 3, loss = 122.25638574712416\n",
      "Epoch: 4, loss = 92.02552422355204\n",
      "Epoch: 5, loss = 72.08935859624076\n",
      "Epoch: 6, loss = 58.05833749210135\n",
      "Epoch: 7, loss = 47.797985848258506\n",
      "Epoch: 8, loss = 40.128115611917835\n",
      "Epoch: 9, loss = 34.32389954959646\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 555.1999887578626\n",
      "Epoch: 1, loss = 275.5579779568841\n",
      "Epoch: 2, loss = 165.82894594529094\n",
      "Epoch: 3, loss = 114.1210487029132\n",
      "Epoch: 4, loss = 84.57342658323407\n",
      "Epoch: 5, loss = 65.53766932206992\n",
      "Epoch: 6, loss = 52.386629104614244\n",
      "Epoch: 7, loss = 42.9216209299424\n",
      "Epoch: 8, loss = 35.9455412275651\n",
      "Epoch: 9, loss = 30.738844941644114\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 656.7843927495619\n",
      "Epoch: 1, loss = 325.69731403799597\n",
      "Epoch: 2, loss = 197.13053075005018\n",
      "Epoch: 3, loss = 135.8117610987495\n",
      "Epoch: 4, loss = 101.00542360193583\n",
      "Epoch: 5, loss = 78.69642612513374\n",
      "Epoch: 6, loss = 63.24361760476058\n",
      "Epoch: 7, loss = 52.00575462509603\n",
      "Epoch: 8, loss = 43.591831024955304\n",
      "Epoch: 9, loss = 37.175032783957114\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 686.327489516314\n",
      "Epoch: 1, loss = 335.5489262412576\n",
      "Epoch: 2, loss = 201.99288536520555\n",
      "Epoch: 3, loss = 139.52561838486614\n",
      "Epoch: 4, loss = 104.178957378163\n",
      "Epoch: 5, loss = 81.48567485809325\n",
      "Epoch: 6, loss = 65.76476450527414\n",
      "Epoch: 7, loss = 54.33050551133998\n",
      "Epoch: 8, loss = 45.74204892270705\n",
      "Epoch: 9, loss = 39.16230722034678\n",
      "(512, 5) (512,)\n",
      "iteration--------- 7\n"
     ]
    }
   ],
   "source": [
    "errors_baseline=baseline(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e3d9025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9857035541465546,\n",
       " 0.9812534058777639,\n",
       " 0.9772264974048933,\n",
       " 0.968115522238074,\n",
       " 0.9476199500144877,\n",
       " 0.9030822492576017,\n",
       " 0.8047329166560927,\n",
       " 0.6545328163490248]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b36fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import al_model\n",
    "from al_model import ActivelyLearnedModel\n",
    "\n",
    "\n",
    "def with_al(config_AL):\n",
    "    # AL, ensemble of 5 NNs\n",
    "    frac_err_AL_ens = []\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    #checkpoint=keras.callbacks.ModelCheckpoint(\"mcp_AL.h5\", save_best_only=True)\n",
    "    K_train_list = [8,16, 32, 64, 128, 256,512,1024] # make it as a global variable\n",
    "    #K_train_list = [10,20,40,80,160,320,640,1280]\n",
    "    N_test = 512\n",
    "    ninit=128\n",
    "    T=2\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary for the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit\n",
    "        config_AL[\"K\"] = K_train_list[i]\n",
    "        config_AL[\"M\"] = 4\n",
    "        config_AL[\"T\"] = T\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit()\n",
    "\n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "        \n",
    "        print('test set size is', X_test.shape)\n",
    "\n",
    "        res = uq_model.predict(X_test)\n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_AL_ens.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        \n",
    "    return frac_err_AL_ens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e285fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(8, 5) (8, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 550.3421596950955\n",
      "Epoch: 1, loss = 516.0718892415364\n",
      "Epoch: 2, loss = 484.9382544623481\n",
      "Epoch: 3, loss = 456.4662916395399\n",
      "Epoch: 4, loss = 430.4010721842448\n",
      "Epoch: 5, loss = 406.4645724826389\n",
      "Epoch: 6, loss = 384.4706370035807\n",
      "Epoch: 7, loss = 364.2384677463108\n",
      "Epoch: 8, loss = 345.59810723198785\n",
      "Epoch: 9, loss = 328.38298543294263\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 515.1665479871962\n",
      "Epoch: 1, loss = 476.7686564127605\n",
      "Epoch: 2, loss = 442.6244472927517\n",
      "Epoch: 3, loss = 412.18840026855474\n",
      "Epoch: 4, loss = 385.0900573730469\n",
      "Epoch: 5, loss = 360.9134334988064\n",
      "Epoch: 6, loss = 339.270994398329\n",
      "Epoch: 7, loss = 319.8077867296007\n",
      "Epoch: 8, loss = 302.21527269151477\n",
      "Epoch: 9, loss = 286.26453484429254\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 505.42358398437506\n",
      "Epoch: 1, loss = 474.6133083767361\n",
      "Epoch: 2, loss = 446.2039218478733\n",
      "Epoch: 3, loss = 419.8666042751736\n",
      "Epoch: 4, loss = 395.49294704861114\n",
      "Epoch: 5, loss = 372.96555413140186\n",
      "Epoch: 6, loss = 352.09846157497833\n",
      "Epoch: 7, loss = 332.80605740017364\n",
      "Epoch: 8, loss = 315.00754801432294\n",
      "Epoch: 9, loss = 298.6032206217448\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 589.2527058919272\n",
      "Epoch: 1, loss = 550.5375162760417\n",
      "Epoch: 2, loss = 515.655034383138\n",
      "Epoch: 3, loss = 483.9232465955946\n",
      "Epoch: 4, loss = 455.08971150716144\n",
      "Epoch: 5, loss = 428.7961222330729\n",
      "Epoch: 6, loss = 404.79144287109375\n",
      "Epoch: 7, loss = 382.8007880316841\n",
      "Epoch: 8, loss = 362.5869344075521\n",
      "Epoch: 9, loss = 344.00721571180554\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 600.7291429307726\n",
      "Epoch: 1, loss = 561.9285685221355\n",
      "Epoch: 2, loss = 526.8546990288628\n",
      "Epoch: 3, loss = 494.94596354166663\n",
      "Epoch: 4, loss = 465.920910305447\n",
      "Epoch: 5, loss = 439.52650960286456\n",
      "Epoch: 6, loss = 415.44607035319007\n",
      "Epoch: 7, loss = 393.40630933973523\n",
      "Epoch: 8, loss = 373.1624857584635\n",
      "Epoch: 9, loss = 354.4816504584418\n",
      "(136, 5) (136, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(8, 5) (8, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 308.8092956542969\n",
      "Epoch: 1, loss = 290.154288397895\n",
      "Epoch: 2, loss = 273.101075914171\n",
      "Epoch: 3, loss = 257.48104519314234\n",
      "Epoch: 4, loss = 243.22265455457898\n",
      "Epoch: 5, loss = 230.21244896782773\n",
      "Epoch: 6, loss = 218.32378726535376\n",
      "Epoch: 7, loss = 207.43218824598523\n",
      "Epoch: 8, loss = 197.44438425699872\n",
      "Epoch: 9, loss = 188.25159708658856\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 266.9225158691406\n",
      "Epoch: 1, loss = 249.1819661458333\n",
      "Epoch: 2, loss = 233.21556769476996\n",
      "Epoch: 3, loss = 218.86749860975476\n",
      "Epoch: 4, loss = 205.99085828993054\n",
      "Epoch: 5, loss = 194.4327206081814\n",
      "Epoch: 6, loss = 184.0272547403971\n",
      "Epoch: 7, loss = 174.62039608425562\n",
      "Epoch: 8, loss = 166.0781538221571\n",
      "Epoch: 9, loss = 158.28081936306424\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 280.30222913954\n",
      "Epoch: 1, loss = 262.8461744520399\n",
      "Epoch: 2, loss = 246.93530951605902\n",
      "Epoch: 3, loss = 232.43600548638238\n",
      "Epoch: 4, loss = 219.26551818847653\n",
      "Epoch: 5, loss = 207.33559502495658\n",
      "Epoch: 6, loss = 196.5071258544922\n",
      "Epoch: 7, loss = 186.64453718397354\n",
      "Epoch: 8, loss = 177.64933607313367\n",
      "Epoch: 9, loss = 169.40929158528644\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 319.2965664333767\n",
      "Epoch: 1, loss = 299.49874030219183\n",
      "Epoch: 2, loss = 281.5354292127821\n",
      "Epoch: 3, loss = 265.18696763780383\n",
      "Epoch: 4, loss = 250.32903374565973\n",
      "Epoch: 5, loss = 236.79617055257157\n",
      "Epoch: 6, loss = 224.45625050862628\n",
      "Epoch: 7, loss = 213.17211235894098\n",
      "Epoch: 8, loss = 202.81851196289062\n",
      "Epoch: 9, loss = 193.2866685655382\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 328.36289978027344\n",
      "Epoch: 1, loss = 308.0970001220703\n",
      "Epoch: 2, loss = 289.533192952474\n",
      "Epoch: 3, loss = 272.51248338487414\n",
      "Epoch: 4, loss = 256.9568447536892\n",
      "Epoch: 5, loss = 242.7675111558702\n",
      "Epoch: 6, loss = 229.832767062717\n",
      "Epoch: 7, loss = 218.00823974609375\n",
      "Epoch: 8, loss = 207.15586429172092\n",
      "Epoch: 9, loss = 197.17863294813367\n",
      "(144, 5) (144, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(16, 5) (16, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 540.8125508626301\n",
      "Epoch: 1, loss = 507.26764594184027\n",
      "Epoch: 2, loss = 476.7073092990452\n",
      "Epoch: 3, loss = 448.7168036566841\n",
      "Epoch: 4, loss = 423.0574917263455\n",
      "Epoch: 5, loss = 399.48328653971356\n",
      "Epoch: 6, loss = 377.7981940375434\n",
      "Epoch: 7, loss = 357.82502916124133\n",
      "Epoch: 8, loss = 339.40970696343317\n",
      "Epoch: 9, loss = 322.40269978841144\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 505.23798624674475\n",
      "Epoch: 1, loss = 467.6647644042969\n",
      "Epoch: 2, loss = 434.23424445258246\n",
      "Epoch: 3, loss = 404.4252624511718\n",
      "Epoch: 4, loss = 377.88219875759546\n",
      "Epoch: 5, loss = 354.186525132921\n",
      "Epoch: 6, loss = 332.95220438639325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss = 313.84133232964405\n",
      "Epoch: 8, loss = 296.57304043240015\n",
      "Epoch: 9, loss = 280.91895039876306\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 496.0865851508247\n",
      "Epoch: 1, loss = 465.86676025390625\n",
      "Epoch: 2, loss = 437.9652540418837\n",
      "Epoch: 3, loss = 412.0892605251736\n",
      "Epoch: 4, loss = 388.117436726888\n",
      "Epoch: 5, loss = 365.9635128445096\n",
      "Epoch: 6, loss = 345.4506310356988\n",
      "Epoch: 7, loss = 326.4936625162761\n",
      "Epoch: 8, loss = 309.00893147786456\n",
      "Epoch: 9, loss = 292.87135314941406\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 571.5410902235244\n",
      "Epoch: 1, loss = 534.1484205457899\n",
      "Epoch: 2, loss = 500.50803290473084\n",
      "Epoch: 3, loss = 469.9461144341363\n",
      "Epoch: 4, loss = 442.18251715766064\n",
      "Epoch: 5, loss = 416.87645128038196\n",
      "Epoch: 6, loss = 393.73914082845056\n",
      "Epoch: 7, loss = 372.5487891303169\n",
      "Epoch: 8, loss = 353.07392205132373\n",
      "Epoch: 9, loss = 335.1445617675781\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 586.887196858724\n",
      "Epoch: 1, loss = 549.0422939724392\n",
      "Epoch: 2, loss = 514.7956475151909\n",
      "Epoch: 3, loss = 483.61088053385413\n",
      "Epoch: 4, loss = 455.2398223876953\n",
      "Epoch: 5, loss = 429.41488986545136\n",
      "Epoch: 6, loss = 405.844484117296\n",
      "Epoch: 7, loss = 384.25248379177515\n",
      "Epoch: 8, loss = 364.4022572835286\n",
      "Epoch: 9, loss = 346.0717468261719\n",
      "(144, 5) (144, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(16, 5) (16, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 295.71338806152346\n",
      "Epoch: 1, loss = 275.82741851806645\n",
      "Epoch: 2, loss = 257.8635177612305\n",
      "Epoch: 3, loss = 241.6166061401367\n",
      "Epoch: 4, loss = 226.9654884338379\n",
      "Epoch: 5, loss = 213.74222106933595\n",
      "Epoch: 6, loss = 201.77908935546876\n",
      "Epoch: 7, loss = 190.90726318359376\n",
      "Epoch: 8, loss = 181.00165634155272\n",
      "Epoch: 9, loss = 171.95676498413087\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 256.6276870727539\n",
      "Epoch: 1, loss = 237.86856994628906\n",
      "Epoch: 2, loss = 221.244066619873\n",
      "Epoch: 3, loss = 206.4911880493164\n",
      "Epoch: 4, loss = 193.41467895507813\n",
      "Epoch: 5, loss = 181.79283294677737\n",
      "Epoch: 6, loss = 171.40859909057616\n",
      "Epoch: 7, loss = 162.08346176147464\n",
      "Epoch: 8, loss = 153.66869964599613\n",
      "Epoch: 9, loss = 146.02630386352538\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 265.35258483886724\n",
      "Epoch: 1, loss = 247.17001342773438\n",
      "Epoch: 2, loss = 230.83157806396483\n",
      "Epoch: 3, loss = 216.11836471557618\n",
      "Epoch: 4, loss = 202.9166488647461\n",
      "Epoch: 5, loss = 191.0652587890625\n",
      "Epoch: 6, loss = 180.38970336914062\n",
      "Epoch: 7, loss = 170.74598770141603\n",
      "Epoch: 8, loss = 162.0126533508301\n",
      "Epoch: 9, loss = 154.0654457092285\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 305.7159698486328\n",
      "Epoch: 1, loss = 284.9569686889648\n",
      "Epoch: 2, loss = 266.33847427368164\n",
      "Epoch: 3, loss = 249.54421310424806\n",
      "Epoch: 4, loss = 234.39960479736325\n",
      "Epoch: 5, loss = 220.73369598388675\n",
      "Epoch: 6, loss = 208.34893417358398\n",
      "Epoch: 7, loss = 197.09326553344727\n",
      "Epoch: 8, loss = 186.82530212402344\n",
      "Epoch: 9, loss = 177.40775527954102\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 320.16092681884766\n",
      "Epoch: 1, loss = 298.2135314941406\n",
      "Epoch: 2, loss = 278.3290420532226\n",
      "Epoch: 3, loss = 260.31834716796874\n",
      "Epoch: 4, loss = 244.06367568969725\n",
      "Epoch: 5, loss = 229.3735336303711\n",
      "Epoch: 6, loss = 216.07735977172854\n",
      "Epoch: 7, loss = 204.01435394287108\n",
      "Epoch: 8, loss = 193.0240478515625\n",
      "Epoch: 9, loss = 182.97657623291013\n",
      "(160, 5) (160, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(32, 5) (32, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 519.7538848876952\n",
      "Epoch: 1, loss = 484.2017486572265\n",
      "Epoch: 2, loss = 452.38174133300777\n",
      "Epoch: 3, loss = 423.55990447998045\n",
      "Epoch: 4, loss = 397.36253814697267\n",
      "Epoch: 5, loss = 373.4940475463867\n",
      "Epoch: 6, loss = 351.7033935546875\n",
      "Epoch: 7, loss = 331.78981323242186\n",
      "Epoch: 8, loss = 313.5430633544922\n",
      "Epoch: 9, loss = 296.78893127441404\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 482.58730163574216\n",
      "Epoch: 1, loss = 443.37409973144526\n",
      "Epoch: 2, loss = 409.1285583496094\n",
      "Epoch: 3, loss = 378.98397369384764\n",
      "Epoch: 4, loss = 352.42780151367185\n",
      "Epoch: 5, loss = 328.9357192993165\n",
      "Epoch: 6, loss = 308.0676635742187\n",
      "Epoch: 7, loss = 289.41677551269527\n",
      "Epoch: 8, loss = 272.67492065429684\n",
      "Epoch: 9, loss = 257.5796661376953\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 469.3596710205078\n",
      "Epoch: 1, loss = 437.8968795776367\n",
      "Epoch: 2, loss = 409.35101623535155\n",
      "Epoch: 3, loss = 383.16686706542964\n",
      "Epoch: 4, loss = 359.1846282958985\n",
      "Epoch: 5, loss = 337.2171005249023\n",
      "Epoch: 6, loss = 317.0447463989258\n",
      "Epoch: 7, loss = 298.56378479003905\n",
      "Epoch: 8, loss = 281.64745483398434\n",
      "Epoch: 9, loss = 266.15223693847656\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 546.8883209228516\n",
      "Epoch: 1, loss = 507.73765563964844\n",
      "Epoch: 2, loss = 473.170671081543\n",
      "Epoch: 3, loss = 442.1257827758789\n",
      "Epoch: 4, loss = 414.1865447998046\n",
      "Epoch: 5, loss = 388.8918701171875\n",
      "Epoch: 6, loss = 365.93492431640624\n",
      "Epoch: 7, loss = 345.0034957885742\n",
      "Epoch: 8, loss = 325.8594833374023\n",
      "Epoch: 9, loss = 308.3167160034179\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 563.519400024414\n",
      "Epoch: 1, loss = 524.1004684448243\n",
      "Epoch: 2, loss = 489.0293762207031\n",
      "Epoch: 3, loss = 457.3693038940429\n",
      "Epoch: 4, loss = 428.75239715576174\n",
      "Epoch: 5, loss = 402.8553985595703\n",
      "Epoch: 6, loss = 379.3185317993164\n",
      "Epoch: 7, loss = 357.83300018310547\n",
      "Epoch: 8, loss = 338.1442581176758\n",
      "Epoch: 9, loss = 320.04795532226564\n",
      "(160, 5) (160, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(32, 5) (32, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 285.4306526184082\n",
      "Epoch: 1, loss = 262.82933171590173\n",
      "Epoch: 2, loss = 242.83935101826984\n",
      "Epoch: 3, loss = 225.16923777262372\n",
      "Epoch: 4, loss = 209.53049341837564\n",
      "Epoch: 5, loss = 195.64816919962564\n",
      "Epoch: 6, loss = 183.2791938781738\n",
      "Epoch: 7, loss = 172.20794677734375\n",
      "Epoch: 8, loss = 162.2418270111084\n",
      "Epoch: 9, loss = 153.23289108276367\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 244.43239784240725\n",
      "Epoch: 1, loss = 223.4785950978597\n",
      "Epoch: 2, loss = 205.3748893737793\n",
      "Epoch: 3, loss = 189.71195093790695\n",
      "Epoch: 4, loss = 176.12658309936523\n",
      "Epoch: 5, loss = 164.26607259114584\n",
      "Epoch: 6, loss = 153.8186601003011\n",
      "Epoch: 7, loss = 144.54394721984866\n",
      "Epoch: 8, loss = 136.24149322509766\n",
      "Epoch: 9, loss = 128.76711591084796\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 255.30702718098954\n",
      "Epoch: 1, loss = 234.58955001831055\n",
      "Epoch: 2, loss = 216.4216340382894\n",
      "Epoch: 3, loss = 200.46300252278644\n",
      "Epoch: 4, loss = 186.48158518473304\n",
      "Epoch: 5, loss = 174.15568415323895\n",
      "Epoch: 6, loss = 163.21965599060061\n",
      "Epoch: 7, loss = 153.47683143615725\n",
      "Epoch: 8, loss = 144.7517236073812\n",
      "Epoch: 9, loss = 136.89354451497397\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 297.0966682434082\n",
      "Epoch: 1, loss = 272.82894579569495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss = 251.59333038330075\n",
      "Epoch: 3, loss = 232.90170923868817\n",
      "Epoch: 4, loss = 216.43096160888672\n",
      "Epoch: 5, loss = 201.87908871968588\n",
      "Epoch: 6, loss = 188.93476994832358\n",
      "Epoch: 7, loss = 177.32235908508298\n",
      "Epoch: 8, loss = 166.86341094970703\n",
      "Epoch: 9, loss = 157.3921750386556\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 296.88513946533203\n",
      "Epoch: 1, loss = 272.9752324422201\n",
      "Epoch: 2, loss = 251.81521097819012\n",
      "Epoch: 3, loss = 233.0875091552734\n",
      "Epoch: 4, loss = 216.51594543457028\n",
      "Epoch: 5, loss = 201.8022263844808\n",
      "Epoch: 6, loss = 188.66959381103516\n",
      "Epoch: 7, loss = 176.90728378295898\n",
      "Epoch: 8, loss = 166.34072240193686\n",
      "Epoch: 9, loss = 156.81050109863284\n",
      "(192, 5) (192, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(64, 5) (64, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 526.4842427571615\n",
      "Epoch: 1, loss = 483.41489664713544\n",
      "Epoch: 2, loss = 445.39400227864587\n",
      "Epoch: 3, loss = 411.61353556315106\n",
      "Epoch: 4, loss = 381.51257832845056\n",
      "Epoch: 5, loss = 354.57625325520837\n",
      "Epoch: 6, loss = 330.43251927693683\n",
      "Epoch: 7, loss = 308.6924514770508\n",
      "Epoch: 8, loss = 289.105837504069\n",
      "Epoch: 9, loss = 271.40772247314453\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 488.76193491617835\n",
      "Epoch: 1, loss = 440.51947275797534\n",
      "Epoch: 2, loss = 399.57275136311847\n",
      "Epoch: 3, loss = 364.6724548339844\n",
      "Epoch: 4, loss = 334.79814147949224\n",
      "Epoch: 5, loss = 309.02611541748047\n",
      "Epoch: 6, loss = 286.60387420654297\n",
      "Epoch: 7, loss = 266.9637794494629\n",
      "Epoch: 8, loss = 249.63371912638345\n",
      "Epoch: 9, loss = 234.23247973124185\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 480.92029571533203\n",
      "Epoch: 1, loss = 441.83342234293616\n",
      "Epoch: 2, loss = 406.99167887369794\n",
      "Epoch: 3, loss = 375.6956278483073\n",
      "Epoch: 4, loss = 347.6114400227865\n",
      "Epoch: 5, loss = 322.38588333129877\n",
      "Epoch: 6, loss = 299.71899032592773\n",
      "Epoch: 7, loss = 279.37169138590497\n",
      "Epoch: 8, loss = 261.0763740539551\n",
      "Epoch: 9, loss = 244.59289169311523\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 567.0883636474609\n",
      "Epoch: 1, loss = 517.2275975545248\n",
      "Epoch: 2, loss = 473.9749259948731\n",
      "Epoch: 3, loss = 436.0800959269206\n",
      "Epoch: 4, loss = 402.6963322957357\n",
      "Epoch: 5, loss = 373.13789621988934\n",
      "Epoch: 6, loss = 346.80406824747723\n",
      "Epoch: 7, loss = 323.30628204345703\n",
      "Epoch: 8, loss = 302.23873011271155\n",
      "Epoch: 9, loss = 283.28319040934247\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 557.1698506673177\n",
      "Epoch: 1, loss = 509.3185297648113\n",
      "Epoch: 2, loss = 467.729860941569\n",
      "Epoch: 3, loss = 431.27187983194995\n",
      "Epoch: 4, loss = 399.2123641967773\n",
      "Epoch: 5, loss = 370.85696283976245\n",
      "Epoch: 6, loss = 345.6147931416829\n",
      "Epoch: 7, loss = 322.99582799275714\n",
      "Epoch: 8, loss = 302.61797587076825\n",
      "Epoch: 9, loss = 284.19554901123047\n",
      "(192, 5) (192, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(64, 5) (64, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 245.2735505104065\n",
      "Epoch: 1, loss = 219.63423824310303\n",
      "Epoch: 2, loss = 198.1141176223755\n",
      "Epoch: 3, loss = 180.02216958999634\n",
      "Epoch: 4, loss = 164.70051097869873\n",
      "Epoch: 5, loss = 151.54293537139893\n",
      "Epoch: 6, loss = 140.11988306045532\n",
      "Epoch: 7, loss = 130.13155817985535\n",
      "Epoch: 8, loss = 121.32094526290894\n",
      "Epoch: 9, loss = 113.50141191482544\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 211.53570365905762\n",
      "Epoch: 1, loss = 188.39132928848267\n",
      "Epoch: 2, loss = 169.3166732788086\n",
      "Epoch: 3, loss = 153.4920620918274\n",
      "Epoch: 4, loss = 140.21305084228516\n",
      "Epoch: 5, loss = 128.90522456169128\n",
      "Epoch: 6, loss = 119.14537715911865\n",
      "Epoch: 7, loss = 110.62537384033203\n",
      "Epoch: 8, loss = 103.10593676567078\n",
      "Epoch: 9, loss = 96.40514016151428\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 216.13652753829956\n",
      "Epoch: 1, loss = 193.58403635025024\n",
      "Epoch: 2, loss = 174.7225580215454\n",
      "Epoch: 3, loss = 158.84742832183838\n",
      "Epoch: 4, loss = 145.38823986053467\n",
      "Epoch: 5, loss = 133.8779273033142\n",
      "Epoch: 6, loss = 123.93179130554199\n",
      "Epoch: 7, loss = 115.23732113838196\n",
      "Epoch: 8, loss = 107.56870150566101\n",
      "Epoch: 9, loss = 100.7541401386261\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 252.59588098526\n",
      "Epoch: 1, loss = 225.77227210998535\n",
      "Epoch: 2, loss = 203.38813591003418\n",
      "Epoch: 3, loss = 184.59200954437256\n",
      "Epoch: 4, loss = 168.66859817504883\n",
      "Epoch: 5, loss = 155.0023217201233\n",
      "Epoch: 6, loss = 143.1138515472412\n",
      "Epoch: 7, loss = 132.65440011024475\n",
      "Epoch: 8, loss = 123.36411499977112\n",
      "Epoch: 9, loss = 115.04207468032837\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 255.41480350494385\n",
      "Epoch: 1, loss = 228.7800211906433\n",
      "Epoch: 2, loss = 206.30747747421265\n",
      "Epoch: 3, loss = 187.2194323539734\n",
      "Epoch: 4, loss = 170.93332433700562\n",
      "Epoch: 5, loss = 156.92190980911255\n",
      "Epoch: 6, loss = 144.76812744140625\n",
      "Epoch: 7, loss = 134.15664958953857\n",
      "Epoch: 8, loss = 124.8272180557251\n",
      "Epoch: 9, loss = 116.55205416679382\n",
      "(256, 5) (256, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 530.8883991241455\n",
      "Epoch: 1, loss = 470.4007978439331\n",
      "Epoch: 2, loss = 420.3075866699219\n",
      "Epoch: 3, loss = 378.23023414611816\n",
      "Epoch: 4, loss = 342.45516204833984\n",
      "Epoch: 5, loss = 311.7868938446045\n",
      "Epoch: 6, loss = 285.3089599609375\n",
      "Epoch: 7, loss = 262.30015563964844\n",
      "Epoch: 8, loss = 242.19718265533447\n",
      "Epoch: 9, loss = 224.55310344696045\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 484.8396415710449\n",
      "Epoch: 1, loss = 421.4496383666992\n",
      "Epoch: 2, loss = 371.05803203582764\n",
      "Epoch: 3, loss = 330.5278911590576\n",
      "Epoch: 4, loss = 297.3754873275757\n",
      "Epoch: 5, loss = 269.833945274353\n",
      "Epoch: 6, loss = 246.6099157333374\n",
      "Epoch: 7, loss = 226.7713770866394\n",
      "Epoch: 8, loss = 209.6322422027588\n",
      "Epoch: 9, loss = 194.67218017578125\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 467.53407096862793\n",
      "Epoch: 1, loss = 415.7057685852051\n",
      "Epoch: 2, loss = 371.9167137145996\n",
      "Epoch: 3, loss = 334.5950222015381\n",
      "Epoch: 4, loss = 302.6195068359375\n",
      "Epoch: 5, loss = 275.1696376800537\n",
      "Epoch: 6, loss = 251.52628326416016\n",
      "Epoch: 7, loss = 231.02668857574463\n",
      "Epoch: 8, loss = 213.20159435272217\n",
      "Epoch: 9, loss = 197.61819458007812\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 559.15260887146\n",
      "Epoch: 1, loss = 492.096981048584\n",
      "Epoch: 2, loss = 437.48120880126953\n",
      "Epoch: 3, loss = 392.2518358230591\n",
      "Epoch: 4, loss = 354.2561330795288\n",
      "Epoch: 5, loss = 321.93488121032715\n",
      "Epoch: 6, loss = 294.1891164779663\n",
      "Epoch: 7, loss = 270.15580654144287\n",
      "Epoch: 8, loss = 249.2220220565796\n",
      "Epoch: 9, loss = 230.87793493270874\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 551.5785675048828\n",
      "Epoch: 1, loss = 489.1897163391113\n",
      "Epoch: 2, loss = 437.58917808532715\n",
      "Epoch: 3, loss = 394.2505702972412\n",
      "Epoch: 4, loss = 357.4702682495117\n",
      "Epoch: 5, loss = 325.83418369293213\n",
      "Epoch: 6, loss = 298.42681980133057\n",
      "Epoch: 7, loss = 274.54997062683105\n",
      "Epoch: 8, loss = 253.6208357810974\n",
      "Epoch: 9, loss = 235.13555431365967\n",
      "(256, 5) (256, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 204.03358109792075\n",
      "Epoch: 1, loss = 173.22642358144125\n",
      "Epoch: 2, loss = 149.76476351420087\n",
      "Epoch: 3, loss = 131.5081605911255\n",
      "Epoch: 4, loss = 116.85811964670816\n",
      "Epoch: 5, loss = 104.8237543106079\n",
      "Epoch: 6, loss = 94.75819889704387\n",
      "Epoch: 7, loss = 86.21855338414511\n",
      "Epoch: 8, loss = 78.87160523732504\n",
      "Epoch: 9, loss = 72.4794119199117\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 175.40316327412924\n",
      "Epoch: 1, loss = 148.22655963897702\n",
      "Epoch: 2, loss = 127.71972942352295\n",
      "Epoch: 3, loss = 111.87089856465658\n",
      "Epoch: 4, loss = 99.24049472808838\n",
      "Epoch: 5, loss = 88.90258582433066\n",
      "Epoch: 6, loss = 80.28223768870036\n",
      "Epoch: 7, loss = 72.97645473480225\n",
      "Epoch: 8, loss = 66.70660368601482\n",
      "Epoch: 9, loss = 61.271722634633385\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 176.3567705154419\n",
      "Epoch: 1, loss = 149.97989209493002\n",
      "Epoch: 2, loss = 129.78681500752765\n",
      "Epoch: 3, loss = 114.02309354146323\n",
      "Epoch: 4, loss = 101.36578114827472\n",
      "Epoch: 5, loss = 90.96665891011554\n",
      "Epoch: 6, loss = 82.25777705510458\n",
      "Epoch: 7, loss = 74.87613709767659\n",
      "Epoch: 8, loss = 68.54307460784912\n",
      "Epoch: 9, loss = 63.056502978006996\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 204.6821505228678\n",
      "Epoch: 1, loss = 173.72132587432864\n",
      "Epoch: 2, loss = 150.10264460245767\n",
      "Epoch: 3, loss = 131.60592683156332\n",
      "Epoch: 4, loss = 116.68344656626384\n",
      "Epoch: 5, loss = 104.33875052134198\n",
      "Epoch: 6, loss = 93.92814127604167\n",
      "Epoch: 7, loss = 85.04455534617108\n",
      "Epoch: 8, loss = 77.37051471074423\n",
      "Epoch: 9, loss = 70.70439195632935\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 207.4724966684977\n",
      "Epoch: 1, loss = 176.6499176025391\n",
      "Epoch: 2, loss = 152.77684942881268\n",
      "Epoch: 3, loss = 134.02019278208417\n",
      "Epoch: 4, loss = 118.96656862894694\n",
      "Epoch: 5, loss = 106.60051472981772\n",
      "Epoch: 6, loss = 96.24927028020223\n",
      "Epoch: 7, loss = 87.46673679351807\n",
      "Epoch: 8, loss = 79.93432871500652\n",
      "Epoch: 9, loss = 73.39786958694457\n",
      "(384, 5) (384, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(256, 5) (256, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 511.0400384267171\n",
      "Epoch: 1, loss = 424.6244672139485\n",
      "Epoch: 2, loss = 360.1853904724121\n",
      "Epoch: 3, loss = 310.23094431559247\n",
      "Epoch: 4, loss = 270.7349109649658\n",
      "Epoch: 5, loss = 238.93097305297852\n",
      "Epoch: 6, loss = 212.95478693644205\n",
      "Epoch: 7, loss = 191.41347376505536\n",
      "Epoch: 8, loss = 173.28961722056073\n",
      "Epoch: 9, loss = 157.89637692769367\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 459.6004441579184\n",
      "Epoch: 1, loss = 373.4724858601889\n",
      "Epoch: 2, loss = 312.7366956075033\n",
      "Epoch: 3, loss = 268.0380538304647\n",
      "Epoch: 4, loss = 233.85062630971274\n",
      "Epoch: 5, loss = 206.84869384765628\n",
      "Epoch: 6, loss = 184.98692385355628\n",
      "Epoch: 7, loss = 166.92603397369385\n",
      "Epoch: 8, loss = 151.73960113525388\n",
      "Epoch: 9, loss = 138.82074832916257\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 440.3460381825764\n",
      "Epoch: 1, loss = 368.21285883585614\n",
      "Epoch: 2, loss = 312.82383918762207\n",
      "Epoch: 3, loss = 269.459680557251\n",
      "Epoch: 4, loss = 235.0896736780802\n",
      "Epoch: 5, loss = 207.51166216532386\n",
      "Epoch: 6, loss = 185.0194708506266\n",
      "Epoch: 7, loss = 166.3802874883016\n",
      "Epoch: 8, loss = 150.7772388458252\n",
      "Epoch: 9, loss = 137.52429660161337\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 523.8169898986816\n",
      "Epoch: 1, loss = 432.7011693318685\n",
      "Epoch: 2, loss = 366.4281126658122\n",
      "Epoch: 3, loss = 315.84464073181147\n",
      "Epoch: 4, loss = 275.9653663635254\n",
      "Epoch: 5, loss = 243.7983061472575\n",
      "Epoch: 6, loss = 217.4280474980672\n",
      "Epoch: 7, loss = 195.53981177012128\n",
      "Epoch: 8, loss = 177.12681929270425\n",
      "Epoch: 9, loss = 161.4890864690145\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 513.8030611673992\n",
      "Epoch: 1, loss = 431.0577704111736\n",
      "Epoch: 2, loss = 367.999308904012\n",
      "Epoch: 3, loss = 318.3706878026326\n",
      "Epoch: 4, loss = 278.57527192433673\n",
      "Epoch: 5, loss = 246.17471917470297\n",
      "Epoch: 6, loss = 219.48719914754227\n",
      "Epoch: 7, loss = 197.231468518575\n",
      "Epoch: 8, loss = 178.47577937444055\n",
      "Epoch: 9, loss = 162.51149749755857\n",
      "(384, 5) (384, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(256, 5) (256, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 131.67157564163207\n",
      "Epoch: 1, loss = 102.95425567626955\n",
      "Epoch: 2, loss = 83.86308307647704\n",
      "Epoch: 3, loss = 70.21230211257935\n",
      "Epoch: 4, loss = 59.92647700309752\n",
      "Epoch: 5, loss = 51.9099497318268\n",
      "Epoch: 6, loss = 45.50178503990175\n",
      "Epoch: 7, loss = 40.2855727672577\n",
      "Epoch: 8, loss = 35.98487079143524\n",
      "Epoch: 9, loss = 32.40132229328155\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 115.99921321868898\n",
      "Epoch: 1, loss = 90.37334022521972\n",
      "Epoch: 2, loss = 73.37077293395996\n",
      "Epoch: 3, loss = 61.2792022228241\n",
      "Epoch: 4, loss = 52.22548971176147\n",
      "Epoch: 5, loss = 45.20535836219788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss = 39.62528133392333\n",
      "Epoch: 7, loss = 35.11491639614105\n",
      "Epoch: 8, loss = 31.421671891212455\n",
      "Epoch: 9, loss = 28.364833593368523\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 112.95289134979248\n",
      "Epoch: 1, loss = 89.010072517395\n",
      "Epoch: 2, loss = 72.71795010566711\n",
      "Epoch: 3, loss = 60.97576723098756\n",
      "Epoch: 4, loss = 52.07804622650147\n",
      "Epoch: 5, loss = 45.07319936752318\n",
      "Epoch: 6, loss = 39.45432169437408\n",
      "Epoch: 7, loss = 34.900456476211545\n",
      "Epoch: 8, loss = 31.17993927001953\n",
      "Epoch: 9, loss = 28.116901159286503\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 132.90819368362423\n",
      "Epoch: 1, loss = 104.30334339141848\n",
      "Epoch: 2, loss = 84.86042757034305\n",
      "Epoch: 3, loss = 70.82139596939088\n",
      "Epoch: 4, loss = 60.19446153640748\n",
      "Epoch: 5, loss = 51.89540438652038\n",
      "Epoch: 6, loss = 45.28352317810059\n",
      "Epoch: 7, loss = 39.93671293258666\n",
      "Epoch: 8, loss = 35.55444283485413\n",
      "Epoch: 9, loss = 31.92900936603546\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 135.65000419616703\n",
      "Epoch: 1, loss = 106.39943714141849\n",
      "Epoch: 2, loss = 86.67729673385621\n",
      "Epoch: 3, loss = 72.5311278820038\n",
      "Epoch: 4, loss = 61.85958218574523\n",
      "Epoch: 5, loss = 53.538844060897844\n",
      "Epoch: 6, loss = 46.8786250591278\n",
      "Epoch: 7, loss = 41.45022974014283\n",
      "Epoch: 8, loss = 36.976999497413644\n",
      "Epoch: 9, loss = 33.2588352918625\n",
      "(640, 5) (640, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n",
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(512, 5) (512, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 453.4712303161621\n",
      "Epoch: 1, loss = 336.57922554016113\n",
      "Epoch: 2, loss = 263.43390922546394\n",
      "Epoch: 3, loss = 213.56784038543702\n",
      "Epoch: 4, loss = 177.80225200653072\n",
      "Epoch: 5, loss = 151.02984275817872\n",
      "Epoch: 6, loss = 130.17660217285157\n",
      "Epoch: 7, loss = 113.51637268066403\n",
      "Epoch: 8, loss = 99.95231246948242\n",
      "Epoch: 9, loss = 88.75889730453493\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 404.80627136230476\n",
      "Epoch: 1, loss = 293.3362705230714\n",
      "Epoch: 2, loss = 228.1756946563721\n",
      "Epoch: 3, loss = 185.40815429687495\n",
      "Epoch: 4, loss = 155.1332471847534\n",
      "Epoch: 5, loss = 132.54947338104245\n",
      "Epoch: 6, loss = 115.05434379577636\n",
      "Epoch: 7, loss = 101.07757987976075\n",
      "Epoch: 8, loss = 89.65570449829103\n",
      "Epoch: 9, loss = 80.15576438903807\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 384.4314399719238\n",
      "Epoch: 1, loss = 288.4421237945557\n",
      "Epoch: 2, loss = 226.0274145126343\n",
      "Epoch: 3, loss = 183.18613719940188\n",
      "Epoch: 4, loss = 152.51142787933352\n",
      "Epoch: 5, loss = 129.72600498199466\n",
      "Epoch: 6, loss = 112.19899835586548\n",
      "Epoch: 7, loss = 98.34432830810545\n",
      "Epoch: 8, loss = 87.1207221031189\n",
      "Epoch: 9, loss = 77.85200233459474\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 460.4773834228514\n",
      "Epoch: 1, loss = 340.1261180877686\n",
      "Epoch: 2, loss = 266.3426250457764\n",
      "Epoch: 3, loss = 216.02450828552247\n",
      "Epoch: 4, loss = 179.7524492263794\n",
      "Epoch: 5, loss = 152.5880090713501\n",
      "Epoch: 6, loss = 131.58504695892336\n",
      "Epoch: 7, loss = 114.80192251205443\n",
      "Epoch: 8, loss = 100.95761346817018\n",
      "Epoch: 9, loss = 89.31606216430667\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 453.0462959289551\n",
      "Epoch: 1, loss = 342.3048168182372\n",
      "Epoch: 2, loss = 269.48496208190926\n",
      "Epoch: 3, loss = 218.76710414886477\n",
      "Epoch: 4, loss = 181.9747772216797\n",
      "Epoch: 5, loss = 154.33191776275635\n",
      "Epoch: 6, loss = 132.98847827911376\n",
      "Epoch: 7, loss = 116.06470756530761\n",
      "Epoch: 8, loss = 102.36234941482547\n",
      "Epoch: 9, loss = 91.00334568023679\n",
      "(640, 5) (640, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(512, 5) (512, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 71.68522339397006\n",
      "Epoch: 1, loss = 49.22967025968763\n",
      "Epoch: 2, loss = 36.97492044501834\n",
      "Epoch: 3, loss = 29.296214938163743\n",
      "Epoch: 4, loss = 24.164550463358562\n",
      "Epoch: 5, loss = 20.6033682955636\n",
      "Epoch: 6, loss = 18.065824468930558\n",
      "Epoch: 7, loss = 16.22343454096052\n",
      "Epoch: 8, loss = 14.858526607354486\n",
      "Epoch: 9, loss = 13.822327521112236\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 64.89352019627891\n",
      "Epoch: 1, loss = 44.297043906317825\n",
      "Epoch: 2, loss = 33.21629308329688\n",
      "Epoch: 3, loss = 26.381012452973255\n",
      "Epoch: 4, loss = 21.88020728694068\n",
      "Epoch: 5, loss = 18.803224298689095\n",
      "Epoch: 6, loss = 16.64103655020396\n",
      "Epoch: 7, loss = 15.084594051043192\n",
      "Epoch: 8, loss = 13.935689714219833\n",
      "Epoch: 9, loss = 13.062766326798336\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 63.67122668690151\n",
      "Epoch: 1, loss = 44.111935204929786\n",
      "Epoch: 2, loss = 33.2459538380305\n",
      "Epoch: 3, loss = 26.44089229901632\n",
      "Epoch: 4, loss = 21.937356988588977\n",
      "Epoch: 5, loss = 18.858885712093766\n",
      "Epoch: 6, loss = 16.710093047883767\n",
      "Epoch: 7, loss = 15.17726139227549\n",
      "Epoch: 8, loss = 14.054431855678558\n",
      "Epoch: 9, loss = 13.205574154853815\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 71.20826011233859\n",
      "Epoch: 1, loss = 49.00282351175944\n",
      "Epoch: 2, loss = 36.74786321322124\n",
      "Epoch: 3, loss = 29.111115548345772\n",
      "Epoch: 4, loss = 24.058692375818886\n",
      "Epoch: 5, loss = 20.593513978852165\n",
      "Epoch: 6, loss = 18.156389342414005\n",
      "Epoch: 7, loss = 16.40172898769379\n",
      "Epoch: 8, loss = 15.108596973949007\n",
      "Epoch: 9, loss = 14.126491400930615\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 74.08985733985902\n",
      "Epoch: 1, loss = 51.169562737147\n",
      "Epoch: 2, loss = 38.43742011653052\n",
      "Epoch: 3, loss = 30.455612036916943\n",
      "Epoch: 4, loss = 25.113207101821892\n",
      "Epoch: 5, loss = 21.40359263949923\n",
      "Epoch: 6, loss = 18.76815320385827\n",
      "Epoch: 7, loss = 16.85693939526876\n",
      "Epoch: 8, loss = 15.442433615525566\n",
      "Epoch: 9, loss = 14.372472723325096\n",
      "(1152, 5) (1152, 1)\n",
      "test set size is (512, 5)\n",
      "(128, 5) (128, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 897.7526092529297\n",
      "Epoch: 1, loss = 848.5229949951172\n",
      "Epoch: 2, loss = 804.1202239990234\n",
      "Epoch: 3, loss = 763.4480133056641\n",
      "Epoch: 4, loss = 725.9991760253906\n",
      "Epoch: 5, loss = 691.2446517944336\n",
      "Epoch: 6, loss = 658.7970314025879\n",
      "Epoch: 7, loss = 628.2924003601074\n",
      "Epoch: 8, loss = 599.5081977844238\n",
      "Epoch: 9, loss = 572.2824592590332\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 972.528881072998\n",
      "Epoch: 1, loss = 899.6927032470703\n",
      "Epoch: 2, loss = 835.6984024047852\n",
      "Epoch: 3, loss = 779.0978622436523\n",
      "Epoch: 4, loss = 728.9292640686035\n",
      "Epoch: 5, loss = 684.1504936218262\n",
      "Epoch: 6, loss = 643.9094848632812\n",
      "Epoch: 7, loss = 607.5042190551758\n",
      "Epoch: 8, loss = 574.3970108032227\n",
      "Epoch: 9, loss = 544.1415100097656\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 837.0923919677734\n",
      "Epoch: 1, loss = 792.8727951049805\n",
      "Epoch: 2, loss = 752.4189338684082\n",
      "Epoch: 3, loss = 714.944034576416\n",
      "Epoch: 4, loss = 679.9913101196289\n",
      "Epoch: 5, loss = 647.3750648498535\n",
      "Epoch: 6, loss = 616.7825965881348\n",
      "Epoch: 7, loss = 588.0034027099609\n",
      "Epoch: 8, loss = 560.8218231201172\n",
      "Epoch: 9, loss = 535.0878028869629\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 1028.6646270751953\n",
      "Epoch: 1, loss = 959.9606475830078\n",
      "Epoch: 2, loss = 899.2978210449219\n",
      "Epoch: 3, loss = 845.2395553588867\n",
      "Epoch: 4, loss = 797.0107650756836\n",
      "Epoch: 5, loss = 753.7688789367676\n",
      "Epoch: 6, loss = 714.6179809570312\n",
      "Epoch: 7, loss = 678.9241027832031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss = 646.1874465942383\n",
      "Epoch: 9, loss = 615.9990577697754\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 1040.334945678711\n",
      "Epoch: 1, loss = 977.7631530761719\n",
      "Epoch: 2, loss = 921.0476760864258\n",
      "Epoch: 3, loss = 869.0232009887695\n",
      "Epoch: 4, loss = 821.2963371276855\n",
      "Epoch: 5, loss = 777.464771270752\n",
      "Epoch: 6, loss = 737.0840835571289\n",
      "Epoch: 7, loss = 699.7607879638672\n",
      "Epoch: 8, loss = 665.0955924987793\n",
      "Epoch: 9, loss = 632.8350448608398\n",
      "\n",
      "T = 0\n",
      "\n",
      "(1024, 5) (1024, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 393.0636806488036\n",
      "Epoch: 1, loss = 244.1439666748047\n",
      "Epoch: 2, loss = 171.70213180118142\n",
      "Epoch: 3, loss = 129.48386679755316\n",
      "Epoch: 4, loss = 102.04987955093384\n",
      "Epoch: 5, loss = 82.65873283810083\n",
      "Epoch: 6, loss = 68.30274656083847\n",
      "Epoch: 7, loss = 57.4078000386556\n",
      "Epoch: 8, loss = 48.99597777260673\n",
      "Epoch: 9, loss = 42.414575709237\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 348.93428315056684\n",
      "Epoch: 1, loss = 212.60245503319638\n",
      "Epoch: 2, loss = 150.33471319410538\n",
      "Epoch: 3, loss = 114.33254861831665\n",
      "Epoch: 4, loss = 90.80841922760008\n",
      "Epoch: 5, loss = 74.24986505508426\n",
      "Epoch: 6, loss = 62.01877601941427\n",
      "Epoch: 7, loss = 52.69102578692968\n",
      "Epoch: 8, loss = 45.42267076174418\n",
      "Epoch: 9, loss = 39.67345277468363\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 336.69595570034454\n",
      "Epoch: 1, loss = 210.7929098341199\n",
      "Epoch: 2, loss = 147.67079385121662\n",
      "Epoch: 3, loss = 111.2848053508335\n",
      "Epoch: 4, loss = 87.9712382952372\n",
      "Epoch: 5, loss = 71.81639533572726\n",
      "Epoch: 6, loss = 60.00682968563504\n",
      "Epoch: 7, loss = 51.07179085413615\n",
      "Epoch: 8, loss = 44.128596756193375\n",
      "Epoch: 9, loss = 38.6392514705658\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 399.55219035678425\n",
      "Epoch: 1, loss = 247.81259865230987\n",
      "Epoch: 2, loss = 173.3502232233683\n",
      "Epoch: 3, loss = 129.9126738972134\n",
      "Epoch: 4, loss = 101.50430403815378\n",
      "Epoch: 5, loss = 81.33768584993149\n",
      "Epoch: 6, loss = 66.55216455459596\n",
      "Epoch: 7, loss = 55.50128605630664\n",
      "Epoch: 8, loss = 47.10566221343147\n",
      "Epoch: 9, loss = 40.63613367080688\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 389.2358966403537\n",
      "Epoch: 1, loss = 247.6083439721001\n",
      "Epoch: 2, loss = 174.29306432935928\n",
      "Epoch: 3, loss = 131.04637373818292\n",
      "Epoch: 4, loss = 103.07803424199425\n",
      "Epoch: 5, loss = 83.67187065548363\n",
      "Epoch: 6, loss = 69.43578468428716\n",
      "Epoch: 7, loss = 58.42963602807787\n",
      "Epoch: 8, loss = 49.62914172808328\n",
      "Epoch: 9, loss = 42.58218283123441\n",
      "(1152, 5) (1152, 1)\n",
      "\n",
      "T = 1\n",
      "\n",
      "(1024, 5) (1024, 1)\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 30.553547887241148\n",
      "Epoch: 1, loss = 18.4909357884351\n",
      "Epoch: 2, loss = 14.14851232486613\n",
      "Epoch: 3, loss = 12.10282617807389\n",
      "Epoch: 4, loss = 10.910282096442055\n",
      "Epoch: 5, loss = 10.084879412370569\n",
      "Epoch: 6, loss = 9.44768307138892\n",
      "Epoch: 7, loss = 8.925574355265674\n",
      "Epoch: 8, loss = 8.483554713866289\n",
      "Epoch: 9, loss = 8.102190568166622\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 28.889503310708427\n",
      "Epoch: 1, loss = 17.580794439596286\n",
      "Epoch: 2, loss = 13.653851183021775\n",
      "Epoch: 3, loss = 11.796020507812507\n",
      "Epoch: 4, loss = 10.67178211142035\n",
      "Epoch: 5, loss = 9.864271398852852\n",
      "Epoch: 6, loss = 9.228322597110969\n",
      "Epoch: 7, loss = 8.705095862641054\n",
      "Epoch: 8, loss = 8.264036003281088\n",
      "Epoch: 9, loss = 7.885715561754565\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 28.66771721839904\n",
      "Epoch: 1, loss = 17.796268568319423\n",
      "Epoch: 2, loss = 13.856053061345055\n",
      "Epoch: 3, loss = 11.988855407518493\n",
      "Epoch: 4, loss = 10.862894156399902\n",
      "Epoch: 5, loss = 10.051197781282315\n",
      "Epoch: 6, loss = 9.407605918014749\n",
      "Epoch: 7, loss = 8.874550051548901\n",
      "Epoch: 8, loss = 8.422578163006724\n",
      "Epoch: 9, loss = 8.033302745398355\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 29.70580095403335\n",
      "Epoch: 1, loss = 18.426221581066354\n",
      "Epoch: 2, loss = 14.36191262567745\n",
      "Epoch: 3, loss = 12.413230569923622\n",
      "Epoch: 4, loss = 11.222554666154524\n",
      "Epoch: 5, loss = 10.361232561223652\n",
      "Epoch: 6, loss = 9.680990731014928\n",
      "Epoch: 7, loss = 9.119028536712426\n",
      "Epoch: 8, loss = 8.643598121755263\n",
      "Epoch: 9, loss = 8.234518054653613\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 31.557604453142968\n",
      "Epoch: 1, loss = 19.118549017345213\n",
      "Epoch: 2, loss = 14.637255623060112\n",
      "Epoch: 3, loss = 12.52802039244596\n",
      "Epoch: 4, loss = 11.285374879837033\n",
      "Epoch: 5, loss = 10.41003700915505\n",
      "Epoch: 6, loss = 9.72522791343577\n",
      "Epoch: 7, loss = 9.158504019765287\n",
      "Epoch: 8, loss = 8.675902850487654\n",
      "Epoch: 9, loss = 8.258927240091213\n",
      "(2176, 5) (2176, 1)\n",
      "test set size is (512, 5)\n"
     ]
    }
   ],
   "source": [
    "errors_al = with_al(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b3a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9293802521732432,\n",
       " 0.9258422335970136,\n",
       " 0.9140231568534581,\n",
       " 0.8880773403590337,\n",
       " 0.8294082156666809,\n",
       " 0.7317469707959956,\n",
       " 0.6010039033083436,\n",
       " 0.557883292852054]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "749a86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_err_plot(frac_err_baseline,frac_err_AL_ens):\n",
    "    \n",
    "    K_train_list = [8,16, 32, 64, 128, 256,512,1024]  # make it global\n",
    "    #K_train_list = [10,20,40,80,160,320,640,1280]\n",
    "    ninit = 128   #128\n",
    "    T=2     \n",
    "    N_train_list = ninit + T * np.array(K_train_list)\n",
    "    plt.style.use(\"classic\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(N_train_list,frac_err_baseline, \".-\", label=\"Baseline\")\n",
    "    plt.plot(N_train_list,frac_err_AL_ens, \".-\", label=\"Active learning, ensemble\")\n",
    "    plt.ylabel('Fractional error on test set')\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ba49c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_err_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_867/277427597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_err_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors_baseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors_al\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compare_err_plot' is not defined"
     ]
    }
   ],
   "source": [
    "compare_err_plot(errors_baseline,errors_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee3a65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_results_table = pd.DataFrame({'Errors_baseline':errors_baseline,'Errors_al':errors_al})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e09491df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Errors_baseline</th>\n",
       "      <td>0.985704</td>\n",
       "      <td>0.981253</td>\n",
       "      <td>0.977226</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>0.947620</td>\n",
       "      <td>0.903082</td>\n",
       "      <td>0.804733</td>\n",
       "      <td>0.654533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errors_al</th>\n",
       "      <td>0.929380</td>\n",
       "      <td>0.925842</td>\n",
       "      <td>0.914023</td>\n",
       "      <td>0.888077</td>\n",
       "      <td>0.829408</td>\n",
       "      <td>0.731747</td>\n",
       "      <td>0.601004</td>\n",
       "      <td>0.557883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5  \\\n",
       "Errors_baseline  0.985704  0.981253  0.977226  0.968116  0.947620  0.903082   \n",
       "Errors_al        0.929380  0.925842  0.914023  0.888077  0.829408  0.731747   \n",
       "\n",
       "                        6         7  \n",
       "Errors_baseline  0.804733  0.654533  \n",
       "Errors_al        0.601004  0.557883  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL_results_table.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698137e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d4db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623569e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
