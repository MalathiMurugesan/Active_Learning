{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3f552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uq360\n",
      "  Using cached uq360-0.2-py3-none-any.whl (172 kB)\n",
      "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.4)\n",
      "Requirement already satisfied: gpytorch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.6.0)\n",
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (from uq360) (0.12.0)\n",
      "Requirement already satisfied: matplotlib>=3.2 in /usr/local/lib/python3.8/dist-packages (from uq360) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.8.0)\n",
      "Requirement already satisfied: numpy<1.21,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.19.5)\n",
      "Requirement already satisfied: botorch>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from uq360) (0.6.4)\n",
      "Requirement already satisfied: tqdm==4.42.0 in /usr/local/lib/python3.8/dist-packages (from uq360) (4.42.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from uq360) (2.6.0+nv)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.11.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from uq360) (2.27.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from uq360) (0.8.9)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from uq360) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn<1.0,>=0.22 in /usr/local/lib/python3.8/dist-packages (from uq360) (0.24.2)\n",
      "Requirement already satisfied: umap-learn==0.3.10 in /usr/local/lib/python3.8/dist-packages (from uq360) (0.3.10)\n",
      "Requirement already satisfied: gitpython==2.1.15 in /usr/local/lib/python3.8/dist-packages (from uq360) (2.1.15)\n",
      "Requirement already satisfied: gitdb2<3,>=2 in /usr/local/lib/python3.8/dist-packages (from gitpython==2.1.15->uq360) (2.0.6)\n",
      "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.8/dist-packages (from umap-learn==0.3.10->uq360) (0.55.1)\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from autograd>=1.3->uq360) (0.18.2)\n",
      "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.8/dist-packages (from botorch>=0.3.2->uq360) (0.6.0)\n",
      "Requirement already satisfied: pyro-ppl==1.8.0 in /usr/local/lib/python3.8/dist-packages (from botorch>=0.3.2->uq360) (1.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from pyro-ppl==1.8.0->botorch>=0.3.2->uq360) (3.3.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from pyro-ppl==1.8.0->botorch>=0.3.2->uq360) (0.1.2)\n",
      "Requirement already satisfied: smmap2>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gitdb2<3,>=2->gitpython==2.1.15->uq360) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (4.31.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (21.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2->uq360) (9.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.37->umap-learn==0.3.10->uq360) (58.2.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba>=0.37->umap-learn==0.3.10->uq360) (0.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->uq360) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2->uq360) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.0,>=0.22->uq360) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.0,>=0.22->uq360) (1.1.0)\n",
      "Requirement already satisfied: smmap>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from smmap2>=2.0.0->gitdb2<3,>=2->gitpython==2.1.15->uq360) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->uq360) (3.7.4.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->uq360) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->uq360) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->uq360) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->uq360) (2021.10.8)\n",
      "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (3.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.6.3)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (0.37.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.12)\n",
      "Requirement already satisfied: absl-py==0.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (0.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (1.39.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->uq360) (3.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow->uq360) (1.35.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->uq360) (4.2.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->uq360) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->uq360) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->uq360) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->uq360) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->uq360) (3.1.1)\n",
      "Installing collected packages: uq360\n",
      "Successfully installed uq360-0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install uq360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6743d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the libraries are found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from uq360.metrics import picp, mpiw, compute_regression_metrics\n",
    "    from uq360.metrics import UncertaintyCharacteristicsCurve as ucc\n",
    "\n",
    "    from uq360.algorithms import * \n",
    "    from uq360.algorithms.actively_learned_model import ActivelyLearnedModel\n",
    "    from uq360.algorithms.ensemble_heteroscedastic_regression import EnsembleHeteroscedasticRegression\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print('All the libraries are found')\n",
    "    \n",
    "except:\n",
    "    print(\"One or more libraries need to be installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed02bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name,sheet_name):\n",
    "    \n",
    "    xls_new = pd.ExcelFile(file_name)\n",
    "    df=pd.read_excel(xls_new,sheet_name,header=1).dropna(how='all', axis=1)\n",
    "    df.drop('#',axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = read_data(r'/data/MGP/TestPoints_100k_NEW.xlsx','ResFeasible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77daec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df,columns,input_columns,output_columns):\n",
    "    \n",
    "    df = df[columns]\n",
    "    df['Diff_Pressure'] = df['Pout [kPA]'] - df['Pin [kPa]']\n",
    "    df = pd.concat([df[input_columns],df[output_columns]],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b455886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2404/4194695666.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Diff_Pressure'] = df['Pout [kPA]'] - df['Pin [kPa]']\n"
     ]
    }
   ],
   "source": [
    "columns = ['Tin [K]','Pin [kPa]','N [rpm]','Total Consumed power','Pout [kPA]','GVFin','Qin [m3/s]']\n",
    "INPUT_C = ['Tin [K]','Pin [kPa]','N [rpm]','Total Consumed power','Pout [kPA]']\n",
    "OUTPUT_C =['Qin [m3/s]']\n",
    "data_1 = select_columns(data,columns,INPUT_C,OUTPUT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "069d67b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61225, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data and select the number of samples to be considered\n",
    "def scale_data(df,samples):\n",
    "    df_1 = df[0:samples]\n",
    "    df_x = df_1.iloc[:, :-1].values\n",
    "    y_labels = np.squeeze(df_1.iloc[:, -1:].values, axis=1)\n",
    "    y_labels = y_labels.reshape((-1,1))\n",
    "\n",
    "    # scale the values\n",
    "    scaler = StandardScaler()\n",
    "    scaling = scaler.fit(df_x)\n",
    "    x_data = scaling.transform(df_x)\n",
    "    \n",
    "    \n",
    "    return df, y_labels, x_data\n",
    "\n",
    "data,y_labels,x_data = scale_data(data_1,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e41d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Offline sample and query, two mandatory arguments (and the data):\n",
    "    - Position where to start sampling\n",
    "    - Number of points to sample\n",
    "'''\n",
    "def sample_(start_index, n_points, X_data=x_data):\n",
    "    return x_data[start_index:start_index+n_points,:]\n",
    "\n",
    "def querry_(start_index, n_points, y_labels=y_labels):\n",
    "    return y_labels[start_index:start_index+n_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed8f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configuration for both models, regression baseline and regression with Active Learning\n",
    "def config_():\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # define config for Heteroscedastic regression\n",
    "    config_HR = {\"num_features\": 5, \"num_hidden\": 32, \"num_outputs\": 1, \"batch_size\": 16, \"num_epochs\": 10,\n",
    "                      \"lr\": 0.001}\n",
    "    HR_kwargs = {\"model_type\":'mlp',\n",
    "                   \"config\": config_HR,\n",
    "                   \"device\": device}\n",
    "    # define config for ensemble\n",
    "    config_ensemble = {\"num_models\": 1, \n",
    "              \"batch_size\": 16,\n",
    "              \"model_kwargs\":HR_kwargs, }\n",
    "\n",
    "    ninit = 128\n",
    "    T = 4 # do not change this, since the model is CPU based  T 25 gives error need atleast one array\n",
    "    # define config for active learning object\n",
    "    # T = # no of iterations\n",
    "    # K = # no of uncertain points\n",
    "    config_AL = {\"num_init\": 512, \n",
    "     \"T\": 4, \n",
    "     \"K\": 64, \n",
    "     \"M\": 4, \n",
    "     \"sampling_function\": sample_, \n",
    "     \"querry_function\" : querry_,\n",
    "     \"model_function\": EnsembleHeteroscedasticRegression,\n",
    "     \"model_kwargs\": {\"model_type\":'ensembleheteroscedasticregression', \n",
    "                                                 \"config\":config_ensemble, \n",
    "                                                 \"device\":device}, }\n",
    "    \n",
    "    return config_HR,HR_kwargs,config_AL\n",
    "config_HR,HR_kwargs,config_AL = config_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e82f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the data set has the good dimension\n",
    "def verify_dimension(data_x,config_AL,config_HR):\n",
    "    \n",
    "    assert(data_x.shape[0] >= config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"])\n",
    "    assert(data_x.shape[1] == config_HR[\"num_features\"])\n",
    "    \n",
    "    return True\n",
    "\n",
    "verify_dimension(x_data,config_AL,config_HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f16289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(config_AL):\n",
    "    # Baseline without AL\n",
    "    K_train_list = [16, 32, 64, 128, 256, 512]\n",
    "    frac_err_baseline = []\n",
    "    ninit=128\n",
    "    N_test = 512\n",
    "    device = torch.device(\"cpu\")\n",
    "    T=4\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary to have no active learning and the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit + K_train_list[i] * T\n",
    "        print(config_AL[\"num_init\"])\n",
    "        config_AL[\"T\"] = 0  # no AL here\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit() # until here it is working # model loss -training\n",
    "\n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "        print(X_test.shape,y_test.shape)\n",
    "\n",
    "        res = uq_model.predict(X_test) \n",
    "        print(X_test.shape)\n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_baseline.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        print('iteration---------',i)\n",
    "        \n",
    "    return  frac_err_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8623052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.6796340694030125\n",
      "Epoch: 1, loss = 0.5946309665838877\n",
      "Epoch: 2, loss = 0.5205294887224833\n",
      "Epoch: 3, loss = 0.44867390890916187\n",
      "Epoch: 4, loss = 0.3744939242800077\n",
      "Epoch: 5, loss = 0.29527637362480164\n",
      "Epoch: 6, loss = 0.20841552565495172\n",
      "Epoch: 7, loss = 0.1126761371269822\n",
      "Epoch: 8, loss = 0.007132950394103926\n",
      "Epoch: 9, loss = -0.10853254670898121\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7060784995555878\n",
      "Epoch: 1, loss = 0.6407881478468578\n",
      "Epoch: 2, loss = 0.5770089874664942\n",
      "Epoch: 3, loss = 0.5110952133933704\n",
      "Epoch: 4, loss = 0.4401779994368553\n",
      "Epoch: 5, loss = 0.36200803766647977\n",
      "Epoch: 6, loss = 0.27497686569889385\n",
      "Epoch: 7, loss = 0.17763172214229903\n",
      "Epoch: 8, loss = 0.06857905102272828\n",
      "Epoch: 9, loss = -0.05339208866159121\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7263005077838899\n",
      "Epoch: 1, loss = 0.6316579778989156\n",
      "Epoch: 2, loss = 0.5539224793513615\n",
      "Epoch: 3, loss = 0.48027773946523655\n",
      "Epoch: 4, loss = 0.40363502502441406\n",
      "Epoch: 5, loss = 0.3225996022423108\n",
      "Epoch: 6, loss = 0.2352315622071425\n",
      "Epoch: 7, loss = 0.14018590562045574\n",
      "Epoch: 8, loss = 0.03650096586594979\n",
      "Epoch: 9, loss = -0.07683281507343052\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7256578852732977\n",
      "Epoch: 1, loss = 0.6691804826259614\n",
      "Epoch: 2, loss = 0.6150279144446055\n",
      "Epoch: 3, loss = 0.5605435023705164\n",
      "Epoch: 4, loss = 0.5027429312467575\n",
      "Epoch: 5, loss = 0.439220813413461\n",
      "Epoch: 6, loss = 0.3681787177920342\n",
      "Epoch: 7, loss = 0.2881108162303766\n",
      "Epoch: 8, loss = 0.1976523579408725\n",
      "Epoch: 9, loss = 0.09517187213835618\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7690875430901847\n",
      "Epoch: 1, loss = 0.7002131839593252\n",
      "Epoch: 2, loss = 0.638382817308108\n",
      "Epoch: 3, loss = 0.576862245798111\n",
      "Epoch: 4, loss = 0.5125294625759125\n",
      "Epoch: 5, loss = 0.4432409231861433\n",
      "Epoch: 6, loss = 0.367351601521174\n",
      "Epoch: 7, loss = 0.28353839615980786\n",
      "Epoch: 8, loss = 0.19042562569181123\n",
      "Epoch: 9, loss = 0.08668008306995034\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 0\n",
      "256\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8143937662243843\n",
      "Epoch: 1, loss = 0.7457415908575058\n",
      "Epoch: 2, loss = 0.6775983907282352\n",
      "Epoch: 3, loss = 0.6030754968523979\n",
      "Epoch: 4, loss = 0.516944756731391\n",
      "Epoch: 5, loss = 0.4156727008521557\n",
      "Epoch: 6, loss = 0.2959118876606226\n",
      "Epoch: 7, loss = 0.15458587452303618\n",
      "Epoch: 8, loss = -0.009671504143625498\n",
      "Epoch: 9, loss = -0.1919259624555707\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7468650192022324\n",
      "Epoch: 1, loss = 0.6433260217308998\n",
      "Epoch: 2, loss = 0.5464299414306879\n",
      "Epoch: 3, loss = 0.44270262867212296\n",
      "Epoch: 4, loss = 0.3286035805940628\n",
      "Epoch: 5, loss = 0.20008519478142262\n",
      "Epoch: 6, loss = 0.053986210259608924\n",
      "Epoch: 7, loss = -0.1121634051669389\n",
      "Epoch: 8, loss = -0.30011238949373364\n",
      "Epoch: 9, loss = -0.5092223584651947\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7934218198060989\n",
      "Epoch: 1, loss = 0.7290878966450691\n",
      "Epoch: 2, loss = 0.6602148003876209\n",
      "Epoch: 3, loss = 0.5824650824069977\n",
      "Epoch: 4, loss = 0.491922527551651\n",
      "Epoch: 5, loss = 0.3846374563872814\n",
      "Epoch: 6, loss = 0.25735072139650583\n",
      "Epoch: 7, loss = 0.10779609228484333\n",
      "Epoch: 8, loss = -0.06503426021663472\n",
      "Epoch: 9, loss = -0.2600989523343742\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.7104667760431767\n",
      "Epoch: 1, loss = 0.624744102358818\n",
      "Epoch: 2, loss = 0.5395172648131847\n",
      "Epoch: 3, loss = 0.44790269806981087\n",
      "Epoch: 4, loss = 0.34550124779343605\n",
      "Epoch: 5, loss = 0.22853634785860777\n",
      "Epoch: 6, loss = 0.0944197810604237\n",
      "Epoch: 7, loss = -0.05729791504563764\n",
      "Epoch: 8, loss = -0.2237531233113259\n",
      "Epoch: 9, loss = -0.39754688274115324\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7110259532928467\n",
      "Epoch: 1, loss = 0.641809094697237\n",
      "Epoch: 2, loss = 0.5696201361715794\n",
      "Epoch: 3, loss = 0.4913914203643799\n",
      "Epoch: 4, loss = 0.40438782796263695\n",
      "Epoch: 5, loss = 0.30621495097875595\n",
      "Epoch: 6, loss = 0.19451787183061242\n",
      "Epoch: 7, loss = 0.06693696300499141\n",
      "Epoch: 8, loss = -0.07837454089894891\n",
      "Epoch: 9, loss = -0.24257118627429008\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 1\n",
      "384\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8008486454685528\n",
      "Epoch: 1, loss = 0.7021746610601742\n",
      "Epoch: 2, loss = 0.5941924328605334\n",
      "Epoch: 3, loss = 0.4604257916410764\n",
      "Epoch: 4, loss = 0.2887496091425419\n",
      "Epoch: 5, loss = 0.06942133434737723\n",
      "Epoch: 6, loss = -0.1986658121459186\n",
      "Epoch: 7, loss = -0.49376814067363745\n",
      "Epoch: 8, loss = -0.7624886110424997\n",
      "Epoch: 9, loss = -0.9531706546743711\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7199024309714636\n",
      "Epoch: 1, loss = 0.5735201388597488\n",
      "Epoch: 2, loss = 0.4208752202490965\n",
      "Epoch: 3, loss = 0.24307090571771064\n",
      "Epoch: 4, loss = 0.028739494853653035\n",
      "Epoch: 5, loss = -0.2306271415824691\n",
      "Epoch: 6, loss = -0.5375185621281465\n",
      "Epoch: 7, loss = -0.8699043815334637\n",
      "Epoch: 8, loss = -1.1282388269901278\n",
      "Epoch: 9, loss = -1.3020466913779576\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7783618172009783\n",
      "Epoch: 1, loss = 0.6822906136512757\n",
      "Epoch: 2, loss = 0.5703615620732306\n",
      "Epoch: 3, loss = 0.4298551095028718\n",
      "Epoch: 4, loss = 0.24936274811625486\n",
      "Epoch: 5, loss = 0.021071722886214644\n",
      "Epoch: 6, loss = -0.2567423307336867\n",
      "Epoch: 7, loss = -0.5694839047888914\n",
      "Epoch: 8, loss = -0.8436180017888547\n",
      "Epoch: 9, loss = -0.9665770853559175\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.690897099673748\n",
      "Epoch: 1, loss = 0.56570053845644\n",
      "Epoch: 2, loss = 0.4314889001349608\n",
      "Epoch: 3, loss = 0.2728322700907786\n",
      "Epoch: 4, loss = 0.07830369868315758\n",
      "Epoch: 5, loss = -0.1532541101332754\n",
      "Epoch: 6, loss = -0.3962128038207689\n",
      "Epoch: 7, loss = -0.6252407083908716\n",
      "Epoch: 8, loss = -0.8355577600498996\n",
      "Epoch: 9, loss = -0.8983322456479071\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.6961687207221984\n",
      "Epoch: 1, loss = 0.5936207721630732\n",
      "Epoch: 2, loss = 0.4801578819751739\n",
      "Epoch: 3, loss = 0.3469625016053518\n",
      "Epoch: 4, loss = 0.186076195910573\n",
      "Epoch: 5, loss = -0.009692642682542402\n",
      "Epoch: 6, loss = -0.24542530439794064\n",
      "Epoch: 7, loss = -0.5194339863955975\n",
      "Epoch: 8, loss = -0.817069875697295\n",
      "Epoch: 9, loss = -1.1071435088912644\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 2\n",
      "640\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.7590695977211\n",
      "Epoch: 1, loss = 0.577646916359663\n",
      "Epoch: 2, loss = 0.32399913016706705\n",
      "Epoch: 3, loss = -0.033748793718405064\n",
      "Epoch: 4, loss = -0.3686451710760595\n",
      "Epoch: 5, loss = -0.6078841848298907\n",
      "Epoch: 6, loss = -0.8891694072633983\n",
      "Epoch: 7, loss = -1.135650360584259\n",
      "Epoch: 8, loss = -1.3491423189640044\n",
      "Epoch: 9, loss = -1.5965743005275725\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.6751525491476059\n",
      "Epoch: 1, loss = 0.42815046235918996\n",
      "Epoch: 2, loss = 0.12007029810920362\n",
      "Epoch: 3, loss = -0.29665543618611995\n",
      "Epoch: 4, loss = -0.8061484307050706\n",
      "Epoch: 5, loss = -1.2740332484245298\n",
      "Epoch: 6, loss = -1.5540366560220717\n",
      "Epoch: 7, loss = -1.691649064421654\n",
      "Epoch: 8, loss = -1.6466173157095911\n",
      "Epoch: 9, loss = -1.7746934831142427\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.7498362526297568\n",
      "Epoch: 1, loss = 0.5674924537539483\n",
      "Epoch: 2, loss = 0.3054682184010744\n",
      "Epoch: 3, loss = -0.07495567784644665\n",
      "Epoch: 4, loss = -0.5250161703675985\n",
      "Epoch: 5, loss = -0.90672892332077\n",
      "Epoch: 6, loss = -1.1702401429414744\n",
      "Epoch: 7, loss = -1.3856206417083743\n",
      "Epoch: 8, loss = -1.5155355989933017\n",
      "Epoch: 9, loss = -1.6520486563444134\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.6519603326916695\n",
      "Epoch: 1, loss = 0.43201748430728915\n",
      "Epoch: 2, loss = 0.149325885437429\n",
      "Epoch: 3, loss = -0.21855947780422866\n",
      "Epoch: 4, loss = -0.5930975332856179\n",
      "Epoch: 5, loss = -0.9236192777752875\n",
      "Epoch: 6, loss = -1.145404622144997\n",
      "Epoch: 7, loss = -1.3933377742767334\n",
      "Epoch: 8, loss = -1.4523135080933574\n",
      "Epoch: 9, loss = -1.6723965466022495\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.6635843873023987\n",
      "Epoch: 1, loss = 0.483189795166254\n",
      "Epoch: 2, loss = 0.2505636237561702\n",
      "Epoch: 3, loss = -0.06808300164993852\n",
      "Epoch: 4, loss = -0.4915359638631345\n",
      "Epoch: 5, loss = -0.9735125944018365\n",
      "Epoch: 6, loss = -1.3152398943901065\n",
      "Epoch: 7, loss = -1.5608886748552326\n",
      "Epoch: 8, loss = -1.700271201133728\n",
      "Epoch: 9, loss = -1.7721696615219114\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 3\n",
      "1152\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.6844429994622868\n",
      "Epoch: 1, loss = 0.24569939806436494\n",
      "Epoch: 2, loss = -0.3297215614002197\n",
      "Epoch: 3, loss = -0.6650604126561022\n",
      "Epoch: 4, loss = -1.096072706911299\n",
      "Epoch: 5, loss = -1.4066926642424522\n",
      "Epoch: 6, loss = -1.6882597315642562\n",
      "Epoch: 7, loss = -1.7959023656116593\n",
      "Epoch: 8, loss = -1.886801199780571\n",
      "Epoch: 9, loss = -1.9419230769077933\n",
      "\n",
      "Training model 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = 0.5815719999372962\n",
      "Epoch: 1, loss = 0.04876079453000179\n",
      "Epoch: 2, loss = -0.7841748251683185\n",
      "Epoch: 3, loss = -1.3669896870851517\n",
      "Epoch: 4, loss = -1.589398004942471\n",
      "Epoch: 5, loss = -1.7097006489833195\n",
      "Epoch: 6, loss = -1.8377373384104838\n",
      "Epoch: 7, loss = -1.868712196747462\n",
      "Epoch: 8, loss = -1.9592508706781602\n",
      "Epoch: 9, loss = -1.9930766042735844\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.6772785439259478\n",
      "Epoch: 1, loss = 0.2230586311003815\n",
      "Epoch: 2, loss = -0.5181641405862236\n",
      "Epoch: 3, loss = -1.0138409435749056\n",
      "Epoch: 4, loss = -1.409897049268087\n",
      "Epoch: 5, loss = -1.5279261594017346\n",
      "Epoch: 6, loss = -1.7107144378953505\n",
      "Epoch: 7, loss = -1.7110348037547538\n",
      "Epoch: 8, loss = -1.8581967237922883\n",
      "Epoch: 9, loss = -1.9273653974135716\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.5687730602092214\n",
      "Epoch: 1, loss = 0.08176980880347802\n",
      "Epoch: 2, loss = -0.4691851449509462\n",
      "Epoch: 3, loss = -1.0108777301179037\n",
      "Epoch: 4, loss = -1.369976685278946\n",
      "Epoch: 5, loss = -1.6273830516470806\n",
      "Epoch: 6, loss = -1.6953304269247587\n",
      "Epoch: 7, loss = -1.8430942131413364\n",
      "Epoch: 8, loss = -1.8409222670727305\n",
      "Epoch: 9, loss = -1.9351463110910525\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.5899321076770623\n",
      "Epoch: 1, loss = 0.1880397022857021\n",
      "Epoch: 2, loss = -0.48490214885936855\n",
      "Epoch: 3, loss = -1.2065636689464247\n",
      "Epoch: 4, loss = -1.4816691002084152\n",
      "Epoch: 5, loss = -1.7761817226807273\n",
      "Epoch: 6, loss = -1.7186362122495973\n",
      "Epoch: 7, loss = -1.9542837159501174\n",
      "Epoch: 8, loss = -2.022448809610473\n",
      "Epoch: 9, loss = -2.0885825024710774\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 4\n",
      "2176\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4934278160799294\n",
      "Epoch: 1, loss = -0.454342067351236\n",
      "Epoch: 2, loss = -1.086572420071153\n",
      "Epoch: 3, loss = -1.6329899235245058\n",
      "Epoch: 4, loss = -1.8785511640941397\n",
      "Epoch: 5, loss = -1.9640896267750685\n",
      "Epoch: 6, loss = -2.038028025451829\n",
      "Epoch: 7, loss = -2.099374018171255\n",
      "Epoch: 8, loss = -2.153067950816716\n",
      "Epoch: 9, loss = -2.2008245771422095\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.34655951571938426\n",
      "Epoch: 1, loss = -1.0254157314843997\n",
      "Epoch: 2, loss = -1.6632780399830902\n",
      "Epoch: 3, loss = -1.8501932108226955\n",
      "Epoch: 4, loss = -1.9890391572433361\n",
      "Epoch: 5, loss = -2.066482248113436\n",
      "Epoch: 6, loss = -2.0684404478353606\n",
      "Epoch: 7, loss = -2.1857132249895264\n",
      "Epoch: 8, loss = -2.2400170476997596\n",
      "Epoch: 9, loss = -2.2682498561985356\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48237058088895607\n",
      "Epoch: 1, loss = -0.6290413777426102\n",
      "Epoch: 2, loss = -1.3761351796634047\n",
      "Epoch: 3, loss = -1.6742018732954473\n",
      "Epoch: 4, loss = -1.7776053317767728\n",
      "Epoch: 5, loss = -1.903333342031521\n",
      "Epoch: 6, loss = -1.9865611208712357\n",
      "Epoch: 7, loss = -2.052783249932176\n",
      "Epoch: 8, loss = -2.1203470552230588\n",
      "Epoch: 9, loss = -2.1736099115189376\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.3473233593052584\n",
      "Epoch: 1, loss = -0.7633470885784308\n",
      "Epoch: 2, loss = -1.1464032198795502\n",
      "Epoch: 3, loss = -1.7377688420169495\n",
      "Epoch: 4, loss = -1.8572820543366324\n",
      "Epoch: 5, loss = -1.9442022350781114\n",
      "Epoch: 6, loss = -2.024208375636269\n",
      "Epoch: 7, loss = -2.0947522516636288\n",
      "Epoch: 8, loss = -2.158316169591512\n",
      "Epoch: 9, loss = -2.2148750564631285\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.42028493575258735\n",
      "Epoch: 1, loss = -0.7435316729140193\n",
      "Epoch: 2, loss = -1.6005328205578457\n",
      "Epoch: 3, loss = -1.8236200397505482\n",
      "Epoch: 4, loss = -1.9724196581279534\n",
      "Epoch: 5, loss = -2.0747359333669433\n",
      "Epoch: 6, loss = -2.154435500502587\n",
      "Epoch: 7, loss = -2.221202258678044\n",
      "Epoch: 8, loss = -2.2787789132665184\n",
      "Epoch: 9, loss = -2.3320095258600584\n",
      "(512, 5) (512,)\n",
      "(512, 5)\n",
      "iteration--------- 5\n"
     ]
    }
   ],
   "source": [
    "errors_baseline=baseline(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b36fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_al(config_AL):\n",
    "    # AL, ensemble of 5 NNs\n",
    "    frac_err_AL_ens = []\n",
    "    device = torch.device(\"cpu\")\n",
    "    K_train_list = [16, 32, 64, 128, 256, 512] # make it as a global variable\n",
    "    N_test = 512\n",
    "    ninit=128\n",
    "    T=4\n",
    "    for i in range(len(K_train_list)):\n",
    "\n",
    "        # Update dictiorary for the correct amount of points\n",
    "        config_AL[\"model_kwargs\"][\"config\"][\"num_models\"] = 5\n",
    "        config_AL[\"num_init\"] = ninit\n",
    "        config_AL[\"K\"] = K_train_list[i]\n",
    "        config_AL[\"M\"] = 4\n",
    "        config_AL[\"T\"] = T\n",
    "\n",
    "        # Instantiate the class object and train the model\n",
    "        uq_model = ActivelyLearnedModel(config=config_AL, device=device, online=False)\n",
    "        uq_model = uq_model.fit()\n",
    "\n",
    "        # Create a test dataset\n",
    "        X_test = sample_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = querry_(int(config_AL[\"num_init\"] + config_AL[\"T\"]*config_AL[\"M\"]*config_AL[\"K\"]), int(N_test))\n",
    "        y_test = np.reshape(y_test, (-1,))\n",
    "\n",
    "        res = uq_model.predict(X_test)\n",
    "        y_test_pred = np.squeeze(res.y_mean, axis=1)\n",
    "\n",
    "        frac_err_AL_ens.append(np.sqrt(np.sum(np.square(y_test - y_test_pred)))/np.sqrt(np.sum(np.square(y_test))))\n",
    "        \n",
    "    return frac_err_AL_ens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e285fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n",
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.4623216324382358\n",
      "Epoch: 1, loss = 0.41356725825203794\n",
      "Epoch: 2, loss = 0.36242745320002234\n",
      "Epoch: 3, loss = 0.30789896845817566\n",
      "Epoch: 4, loss = 0.24951102419031992\n",
      "Epoch: 5, loss = 0.18671411482824218\n",
      "Epoch: 6, loss = 0.11917455742756525\n",
      "Epoch: 7, loss = 0.04663026560511854\n",
      "Epoch: 8, loss = -0.03126243708862199\n",
      "Epoch: 9, loss = -0.11428019611371888\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.23909835351838007\n",
      "Epoch: 1, loss = 0.17316365324788624\n",
      "Epoch: 2, loss = 0.10429020826187399\n",
      "Epoch: 3, loss = 0.03182976630826791\n",
      "Epoch: 4, loss = -0.04513455658323235\n",
      "Epoch: 5, loss = -0.12654898522628677\n",
      "Epoch: 6, loss = -0.21325812240441644\n",
      "Epoch: 7, loss = -0.3050917171769672\n",
      "Epoch: 8, loss = -0.402198851108551\n",
      "Epoch: 9, loss = -0.504555023378796\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.43314579791492885\n",
      "Epoch: 1, loss = 0.3828010989560021\n",
      "Epoch: 2, loss = 0.33022196922037333\n",
      "Epoch: 3, loss = 0.2744401627116733\n",
      "Epoch: 4, loss = 0.2151168195737733\n",
      "Epoch: 5, loss = 0.1517037705828746\n",
      "Epoch: 6, loss = 0.08404576323098607\n",
      "Epoch: 7, loss = 0.011717727407813072\n",
      "Epoch: 8, loss = -0.06557787913415167\n",
      "Epoch: 9, loss = -0.1478914179735714\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.27155156433582306\n",
      "Epoch: 1, loss = 0.2136906103955375\n",
      "Epoch: 2, loss = 0.154305097543531\n",
      "Epoch: 3, loss = 0.09092032226423423\n",
      "Epoch: 4, loss = 0.024001594736344285\n",
      "Epoch: 5, loss = -0.04747295131285985\n",
      "Epoch: 6, loss = -0.12328130834632449\n",
      "Epoch: 7, loss = -0.20352682015962067\n",
      "Epoch: 8, loss = -0.2880798015329573\n",
      "Epoch: 9, loss = -0.37702559265825486\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3481917182604472\n",
      "Epoch: 1, loss = 0.3001544574896495\n",
      "Epoch: 2, loss = 0.250564639767011\n",
      "Epoch: 3, loss = 0.19854658593734104\n",
      "Epoch: 4, loss = 0.14359410148527887\n",
      "Epoch: 5, loss = 0.0851118854350514\n",
      "Epoch: 6, loss = 0.022671061257521313\n",
      "Epoch: 7, loss = -0.04418224768920077\n",
      "Epoch: 8, loss = -0.1157644068201383\n",
      "Epoch: 9, loss = -0.1924885655235913\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.17206814996898173\n",
      "Epoch: 1, loss = -0.25337001811712984\n",
      "Epoch: 2, loss = -0.3346090357750654\n",
      "Epoch: 3, loss = -0.42289060577750215\n",
      "Epoch: 4, loss = -0.5076154336333276\n",
      "Epoch: 5, loss = -0.5850148022174836\n",
      "Epoch: 6, loss = -0.6686676710844041\n",
      "Epoch: 7, loss = -0.7644721716642381\n",
      "Epoch: 8, loss = -0.8442012518644333\n",
      "Epoch: 9, loss = -0.9013795375823975\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.5696671694517136\n",
      "Epoch: 1, loss = -0.6700165390968322\n",
      "Epoch: 2, loss = -0.7708575040102006\n",
      "Epoch: 3, loss = -0.8745261788368225\n",
      "Epoch: 4, loss = -0.9795576393604277\n",
      "Epoch: 5, loss = -1.0840626060962677\n",
      "Epoch: 6, loss = -1.1896570146083834\n",
      "Epoch: 7, loss = -1.2958164811134338\n",
      "Epoch: 8, loss = -1.3996013402938843\n",
      "Epoch: 9, loss = -1.4960464596748353\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.2006736444309354\n",
      "Epoch: 1, loss = -0.2829779732972383\n",
      "Epoch: 2, loss = -0.3687562465667724\n",
      "Epoch: 3, loss = -0.45668904632329943\n",
      "Epoch: 4, loss = -0.5477585956454277\n",
      "Epoch: 5, loss = -0.6416654735803604\n",
      "Epoch: 6, loss = -0.7369345664978028\n",
      "Epoch: 7, loss = -0.830875751376152\n",
      "Epoch: 8, loss = -0.9186543107032775\n",
      "Epoch: 9, loss = -0.993503201007843\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.4281695544719696\n",
      "Epoch: 1, loss = -0.5147429138422013\n",
      "Epoch: 2, loss = -0.608666154742241\n",
      "Epoch: 3, loss = -0.6944519966840744\n",
      "Epoch: 4, loss = -0.7699777156114579\n",
      "Epoch: 5, loss = -0.8742024540901183\n",
      "Epoch: 6, loss = -0.968176966905594\n",
      "Epoch: 7, loss = -1.0476382732391358\n",
      "Epoch: 8, loss = -0.9746030032634736\n",
      "Epoch: 9, loss = -0.894768500328064\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.2425223681144416\n",
      "Epoch: 1, loss = -0.31926923170685767\n",
      "Epoch: 2, loss = -0.40091277807950965\n",
      "Epoch: 3, loss = -0.4848689794540405\n",
      "Epoch: 4, loss = -0.5733726054430008\n",
      "Epoch: 5, loss = -0.6665552854537965\n",
      "Epoch: 6, loss = -0.7625885128974914\n",
      "Epoch: 7, loss = -0.8600100040435792\n",
      "Epoch: 8, loss = -0.959740149974823\n",
      "Epoch: 9, loss = -1.0592112958431243\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.9249755848537792\n",
      "Epoch: 1, loss = -0.9790709181265397\n",
      "Epoch: 2, loss = -0.9673810817978599\n",
      "Epoch: 3, loss = -1.1170326525514775\n",
      "Epoch: 4, loss = -1.1443092552098362\n",
      "Epoch: 5, loss = -1.2418016574599526\n",
      "Epoch: 6, loss = -1.293439117344943\n",
      "Epoch: 7, loss = -1.2900397560813208\n",
      "Epoch: 8, loss = -1.2658660466020757\n",
      "Epoch: 9, loss = -1.343050566586581\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.4895117066123267\n",
      "Epoch: 1, loss = -1.537643486803228\n",
      "Epoch: 2, loss = -1.581431096250361\n",
      "Epoch: 3, loss = -1.624734217470342\n",
      "Epoch: 4, loss = -1.6921195116910066\n",
      "Epoch: 5, loss = -1.7427515875209463\n",
      "Epoch: 6, loss = -1.8115775151686235\n",
      "Epoch: 7, loss = -1.8900765830820259\n",
      "Epoch: 8, loss = -1.8705003369938245\n",
      "Epoch: 9, loss = -1.6266533244739876\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.0190697176889938\n",
      "Epoch: 1, loss = -1.0985257733951914\n",
      "Epoch: 2, loss = -1.1954153342680496\n",
      "Epoch: 3, loss = -1.283997969193892\n",
      "Epoch: 4, loss = -1.3404711322350935\n",
      "Epoch: 5, loss = -1.284256479956887\n",
      "Epoch: 6, loss = -1.4121429432522168\n",
      "Epoch: 7, loss = -1.5107137181542134\n",
      "Epoch: 8, loss = -1.5795650590549817\n",
      "Epoch: 9, loss = -1.5802013169635425\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.9126468842679804\n",
      "Epoch: 1, loss = -1.0514880147847263\n",
      "Epoch: 2, loss = -1.1738352938131853\n",
      "Epoch: 3, loss = -1.2493268251419067\n",
      "Epoch: 4, loss = -1.315441001545299\n",
      "Epoch: 5, loss = -1.396534410389987\n",
      "Epoch: 6, loss = -1.4049196460030295\n",
      "Epoch: 7, loss = -1.411643082445318\n",
      "Epoch: 8, loss = -1.5533250678669326\n",
      "Epoch: 9, loss = -1.5226719487797131\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.101347408511422\n",
      "Epoch: 1, loss = -1.1945237842473118\n",
      "Epoch: 2, loss = -1.277793125672774\n",
      "Epoch: 3, loss = -1.3596667918291958\n",
      "Epoch: 4, loss = -1.4478440284729004\n",
      "Epoch: 5, loss = -1.519643610174006\n",
      "Epoch: 6, loss = -1.588224942033941\n",
      "Epoch: 7, loss = -1.5779434659264304\n",
      "Epoch: 8, loss = -1.51375535401431\n",
      "Epoch: 9, loss = -1.6126302697441797\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.3510433981815975\n",
      "Epoch: 1, loss = -1.4879604925711951\n",
      "Epoch: 2, loss = -1.5055166482925417\n",
      "Epoch: 3, loss = -1.4481995900472007\n",
      "Epoch: 4, loss = -1.6030323505401611\n",
      "Epoch: 5, loss = -1.6267333030700686\n",
      "Epoch: 6, loss = -1.6323532263437905\n",
      "Epoch: 7, loss = -1.6212941110134123\n",
      "Epoch: 8, loss = -1.524382462104162\n",
      "Epoch: 9, loss = -1.364374913275242\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.2035013809800148\n",
      "Epoch: 1, loss = 0.67398268977801\n",
      "Epoch: 2, loss = 0.10633817811806999\n",
      "Epoch: 3, loss = -1.1555204292138417\n",
      "Epoch: 4, loss = -1.6997023324171703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss = -1.8031392296155293\n",
      "Epoch: 6, loss = -1.8099753359953563\n",
      "Epoch: 7, loss = -1.8386390805244446\n",
      "Epoch: 8, loss = -1.8604452709356947\n",
      "Epoch: 9, loss = -1.881903251012166\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5154457887013753\n",
      "Epoch: 1, loss = -1.5782305896282194\n",
      "Epoch: 2, loss = -1.6584618886311848\n",
      "Epoch: 3, loss = -1.7337785164515176\n",
      "Epoch: 4, loss = -1.7459768652915955\n",
      "Epoch: 5, loss = -1.636675367752711\n",
      "Epoch: 6, loss = -1.6208273073037465\n",
      "Epoch: 7, loss = -1.7240280508995056\n",
      "Epoch: 8, loss = -1.6011869907379153\n",
      "Epoch: 9, loss = -1.6194999814033508\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.423553521434466\n",
      "Epoch: 1, loss = -1.3618623291452727\n",
      "Epoch: 2, loss = -1.0621225436528523\n",
      "Epoch: 3, loss = -1.2411371419827144\n",
      "Epoch: 4, loss = -1.2938445806503298\n",
      "Epoch: 5, loss = -1.377952963113785\n",
      "Epoch: 6, loss = -1.4570773243904116\n",
      "Epoch: 7, loss = -1.5323930581410727\n",
      "Epoch: 8, loss = -1.5884803533554077\n",
      "Epoch: 9, loss = -1.6233981549739838\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.406755526860555\n",
      "Epoch: 1, loss = -1.4510178168614705\n",
      "Epoch: 2, loss = -1.4652578334013622\n",
      "Epoch: 3, loss = -1.6056587596734364\n",
      "Epoch: 4, loss = -1.673583726088206\n",
      "Epoch: 5, loss = -1.7373477518558502\n",
      "Epoch: 6, loss = -1.7738193472226462\n",
      "Epoch: 7, loss = -1.7927415966987608\n",
      "Epoch: 8, loss = -1.782920142014821\n",
      "Epoch: 9, loss = -1.793577432632446\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n",
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.46823874115943914\n",
      "Epoch: 1, loss = 0.41521532535552985\n",
      "Epoch: 2, loss = 0.35933686047792435\n",
      "Epoch: 3, loss = 0.29917928874492644\n",
      "Epoch: 4, loss = 0.23419552445411684\n",
      "Epoch: 5, loss = 0.16366269960999488\n",
      "Epoch: 6, loss = 0.08717640172690153\n",
      "Epoch: 7, loss = 0.00450780726969242\n",
      "Epoch: 8, loss = -0.08411250710487365\n",
      "Epoch: 9, loss = -0.17760934382677077\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.25120454132556913\n",
      "Epoch: 1, loss = 0.18039051145315171\n",
      "Epoch: 2, loss = 0.1057032562792301\n",
      "Epoch: 3, loss = 0.026947995275259016\n",
      "Epoch: 4, loss = -0.05777274230495095\n",
      "Epoch: 5, loss = -0.14771042703650894\n",
      "Epoch: 6, loss = -0.2442696616053581\n",
      "Epoch: 7, loss = -0.3471338450908661\n",
      "Epoch: 8, loss = -0.4563414305448532\n",
      "Epoch: 9, loss = -0.5714629441499711\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.44262882173061363\n",
      "Epoch: 1, loss = 0.3883305609226227\n",
      "Epoch: 2, loss = 0.33137915879487995\n",
      "Epoch: 3, loss = 0.2704874023795128\n",
      "Epoch: 4, loss = 0.20519858859479428\n",
      "Epoch: 5, loss = 0.13486883230507374\n",
      "Epoch: 6, loss = 0.059249983914196495\n",
      "Epoch: 7, loss = -0.022180788032710556\n",
      "Epoch: 8, loss = -0.109542500320822\n",
      "Epoch: 9, loss = -0.20290488749742508\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.2848311737179756\n",
      "Epoch: 1, loss = 0.22245898842811584\n",
      "Epoch: 2, loss = 0.1577496126294136\n",
      "Epoch: 3, loss = 0.08853304106742144\n",
      "Epoch: 4, loss = 0.014748781919479374\n",
      "Epoch: 5, loss = -0.06445528715848924\n",
      "Epoch: 6, loss = -0.1485549253411591\n",
      "Epoch: 7, loss = -0.2379176672548056\n",
      "Epoch: 8, loss = -0.3320666268467903\n",
      "Epoch: 9, loss = -0.4302121117711067\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.35830900371074675\n",
      "Epoch: 1, loss = 0.3071371048688889\n",
      "Epoch: 2, loss = 0.2541207775473595\n",
      "Epoch: 3, loss = 0.1981174893677235\n",
      "Epoch: 4, loss = 0.13840986043214798\n",
      "Epoch: 5, loss = 0.07430336019024253\n",
      "Epoch: 6, loss = 0.005213743261992931\n",
      "Epoch: 7, loss = -0.06931910030543804\n",
      "Epoch: 8, loss = -0.14979416131973267\n",
      "Epoch: 9, loss = -0.23663613349199294\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.20966100133955473\n",
      "Epoch: 1, loss = -0.29931069662173587\n",
      "Epoch: 2, loss = -0.39868698921054607\n",
      "Epoch: 3, loss = -0.4951253977293769\n",
      "Epoch: 4, loss = -0.587947458649675\n",
      "Epoch: 5, loss = -0.6454536008338133\n",
      "Epoch: 6, loss = -0.7461044440666835\n",
      "Epoch: 7, loss = -0.8374051426847775\n",
      "Epoch: 8, loss = -0.927889347076416\n",
      "Epoch: 9, loss = -0.9078160698215166\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.6273515199621518\n",
      "Epoch: 1, loss = -0.7418528348207473\n",
      "Epoch: 2, loss = -0.8593516647815703\n",
      "Epoch: 3, loss = -0.9712564845879873\n",
      "Epoch: 4, loss = -1.081124986211459\n",
      "Epoch: 5, loss = -1.1935923546552658\n",
      "Epoch: 6, loss = -1.3075549950202308\n",
      "Epoch: 7, loss = -1.410721778869629\n",
      "Epoch: 8, loss = -1.4758029381434123\n",
      "Epoch: 9, loss = -1.434942662715912\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.22873262781649828\n",
      "Epoch: 1, loss = -0.3236473786334197\n",
      "Epoch: 2, loss = -0.4222656482209762\n",
      "Epoch: 3, loss = -0.5235352284895877\n",
      "Epoch: 4, loss = -0.6259877358873684\n",
      "Epoch: 5, loss = -0.7245010485251745\n",
      "Epoch: 6, loss = -0.8164508193731308\n",
      "Epoch: 7, loss = -0.9131177092591921\n",
      "Epoch: 8, loss = -1.0122924819588663\n",
      "Epoch: 9, loss = -1.092688408990701\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.46926498040556913\n",
      "Epoch: 1, loss = -0.5695454149196545\n",
      "Epoch: 2, loss = -0.6798042866090934\n",
      "Epoch: 3, loss = -0.7766171817978222\n",
      "Epoch: 4, loss = -0.8247865960001947\n",
      "Epoch: 5, loss = -0.8767868702610335\n",
      "Epoch: 6, loss = -0.9452556396524111\n",
      "Epoch: 7, loss = -1.050428698460261\n",
      "Epoch: 8, loss = -1.0061762978633246\n",
      "Epoch: 9, loss = -1.201141471664111\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.2773582125858714\n",
      "Epoch: 1, loss = -0.3660016929109891\n",
      "Epoch: 2, loss = -0.4632412269711495\n",
      "Epoch: 3, loss = -0.562969463566939\n",
      "Epoch: 4, loss = -0.6641332730650901\n",
      "Epoch: 5, loss = -0.77235030879577\n",
      "Epoch: 6, loss = -0.8849172989527384\n",
      "Epoch: 7, loss = -0.9857953935861589\n",
      "Epoch: 8, loss = -1.0639157642920813\n",
      "Epoch: 9, loss = -1.1689953903357189\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.0123641576085773\n",
      "Epoch: 1, loss = -0.9338062235287258\n",
      "Epoch: 2, loss = -1.0519661349909646\n",
      "Epoch: 3, loss = -1.1419057633195604\n",
      "Epoch: 4, loss = -1.1035306836877552\n",
      "Epoch: 5, loss = -1.2123180202075414\n",
      "Epoch: 6, loss = -1.077055654355458\n",
      "Epoch: 7, loss = -1.0976740366646223\n",
      "Epoch: 8, loss = -0.6247062172208514\n",
      "Epoch: 9, loss = -0.12189530687672753\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.1364741548895834\n",
      "Epoch: 1, loss = -0.922542691230774\n",
      "Epoch: 2, loss = -0.48087695453848156\n",
      "Epoch: 3, loss = -0.6646920549018043\n",
      "Epoch: 4, loss = -1.095488318375179\n",
      "Epoch: 5, loss = -1.3654052657740454\n",
      "Epoch: 6, loss = -1.4839296170643397\n",
      "Epoch: 7, loss = -1.5359441467693875\n",
      "Epoch: 8, loss = -1.5834689140319826\n",
      "Epoch: 9, loss = -1.6317207217216492\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.0968557000160215\n",
      "Epoch: 1, loss = -1.1636454675878798\n",
      "Epoch: 2, loss = -1.2769245590482439\n",
      "Epoch: 3, loss = -1.3543812930583954\n",
      "Epoch: 4, loss = -1.4438394180365972\n",
      "Epoch: 5, loss = -1.4076226864542283\n",
      "Epoch: 6, loss = -1.1586276143789291\n",
      "Epoch: 7, loss = -1.2926304851259502\n",
      "Epoch: 8, loss = -1.2554906053202493\n",
      "Epoch: 9, loss = -1.208458776984896\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.151442608663014\n",
      "Epoch: 1, loss = -1.1386148929595945\n",
      "Epoch: 2, loss = -0.94794000685215\n",
      "Epoch: 3, loss = -1.0230933938707625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss = -0.9674055193151747\n",
      "Epoch: 5, loss = -0.9543821407215936\n",
      "Epoch: 6, loss = -1.029688251870019\n",
      "Epoch: 7, loss = -1.1653030599866594\n",
      "Epoch: 8, loss = -1.2975437172821587\n",
      "Epoch: 9, loss = -1.3669502351965224\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.2340544845376695\n",
      "Epoch: 1, loss = -1.3056970153536116\n",
      "Epoch: 2, loss = -1.4050396851130895\n",
      "Epoch: 3, loss = -1.4627298925604137\n",
      "Epoch: 4, loss = -1.5476155706814356\n",
      "Epoch: 5, loss = -1.4692728604589194\n",
      "Epoch: 6, loss = -1.449520570891244\n",
      "Epoch: 7, loss = -1.5902362976755415\n",
      "Epoch: 8, loss = -1.6607024329049245\n",
      "Epoch: 9, loss = -1.6882088439805165\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.1220029555261135\n",
      "Epoch: 1, loss = -1.2814105711877346\n",
      "Epoch: 2, loss = -1.2514662258327007\n",
      "Epoch: 3, loss = -1.0592047944664955\n",
      "Epoch: 4, loss = -0.8088926719501615\n",
      "Epoch: 5, loss = -0.9264704347588122\n",
      "Epoch: 6, loss = -1.2220314480364323\n",
      "Epoch: 7, loss = -1.069987677037716\n",
      "Epoch: 8, loss = -1.001883178949356\n",
      "Epoch: 9, loss = -1.1784124821424484\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.572501502931118\n",
      "Epoch: 1, loss = -1.4465084187686443\n",
      "Epoch: 2, loss = -1.6623921021819115\n",
      "Epoch: 3, loss = -1.6815389096736908\n",
      "Epoch: 4, loss = -1.7263155430555344\n",
      "Epoch: 5, loss = -1.8223520293831825\n",
      "Epoch: 6, loss = -1.8744127750396729\n",
      "Epoch: 7, loss = -1.8519390299916267\n",
      "Epoch: 8, loss = -1.8488368690013885\n",
      "Epoch: 9, loss = -1.5114680044353008\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.3804537281394005\n",
      "Epoch: 1, loss = -1.3049296028912067\n",
      "Epoch: 2, loss = -1.2387112863361835\n",
      "Epoch: 3, loss = -1.1688319072127342\n",
      "Epoch: 4, loss = -0.9457073099911213\n",
      "Epoch: 5, loss = -0.7895677154883742\n",
      "Epoch: 6, loss = -0.9132595732808113\n",
      "Epoch: 7, loss = -1.1209917031228542\n",
      "Epoch: 8, loss = -1.3337943479418755\n",
      "Epoch: 9, loss = -1.4398481994867325\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.3670425079762936\n",
      "Epoch: 1, loss = -1.405815064907074\n",
      "Epoch: 2, loss = -1.3598719201982021\n",
      "Epoch: 3, loss = -1.206645518541336\n",
      "Epoch: 4, loss = -1.077537415549159\n",
      "Epoch: 5, loss = -0.9889168422669172\n",
      "Epoch: 6, loss = -1.13099623657763\n",
      "Epoch: 7, loss = -1.3120062351226807\n",
      "Epoch: 8, loss = -1.3721274733543396\n",
      "Epoch: 9, loss = -1.3142944276332855\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.6052413880825043\n",
      "Epoch: 1, loss = -1.0138055123388767\n",
      "Epoch: 2, loss = -0.6694871820509434\n",
      "Epoch: 3, loss = -0.7229675799608231\n",
      "Epoch: 4, loss = -1.3065183013677597\n",
      "Epoch: 5, loss = -1.6339589804410934\n",
      "Epoch: 6, loss = -1.6823544055223465\n",
      "Epoch: 7, loss = -1.7309939116239548\n",
      "Epoch: 8, loss = -1.7349504306912422\n",
      "Epoch: 9, loss = -1.76035837829113\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n",
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.49052197734514874\n",
      "Epoch: 1, loss = 0.4318644925951957\n",
      "Epoch: 2, loss = 0.3695255480706692\n",
      "Epoch: 3, loss = 0.30135844709972537\n",
      "Epoch: 4, loss = 0.2265056795440614\n",
      "Epoch: 5, loss = 0.14422643836587667\n",
      "Epoch: 6, loss = 0.05389721877872944\n",
      "Epoch: 7, loss = -0.04463427327573301\n",
      "Epoch: 8, loss = -0.14971077411125103\n",
      "Epoch: 9, loss = -0.2543807631979386\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2631751957039038\n",
      "Epoch: 1, loss = 0.18240171608825523\n",
      "Epoch: 2, loss = 0.09535575533906619\n",
      "Epoch: 3, loss = 0.0033563991698125992\n",
      "Epoch: 4, loss = -0.09790703499068816\n",
      "Epoch: 5, loss = -0.20670769829303026\n",
      "Epoch: 6, loss = -0.32401963385442895\n",
      "Epoch: 7, loss = -0.4497891987363497\n",
      "Epoch: 8, loss = -0.5830031087001164\n",
      "Epoch: 9, loss = -0.7209861526886621\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.464611458281676\n",
      "Epoch: 1, loss = 0.4052155166864395\n",
      "Epoch: 2, loss = 0.34261406833926833\n",
      "Epoch: 3, loss = 0.27485574347277486\n",
      "Epoch: 4, loss = 0.20105273781033856\n",
      "Epoch: 5, loss = 0.12061007243270676\n",
      "Epoch: 6, loss = 0.0328211912419647\n",
      "Epoch: 7, loss = -0.06269016582518816\n",
      "Epoch: 8, loss = -0.1661301615725582\n",
      "Epoch: 9, loss = -0.2770354443540176\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.2982101154824098\n",
      "Epoch: 1, loss = 0.22603395332892734\n",
      "Epoch: 2, loss = 0.15027243985484043\n",
      "Epoch: 3, loss = 0.0681581183647116\n",
      "Epoch: 4, loss = -0.020785264670848843\n",
      "Epoch: 5, loss = -0.11702777848889431\n",
      "Epoch: 6, loss = -0.2203371993576487\n",
      "Epoch: 7, loss = -0.3299012252440055\n",
      "Epoch: 8, loss = -0.4439754711153607\n",
      "Epoch: 9, loss = -0.5577019328872361\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.37430058668057126\n",
      "Epoch: 1, loss = 0.316589326908191\n",
      "Epoch: 2, loss = 0.2563565423091253\n",
      "Epoch: 3, loss = 0.19175931873420873\n",
      "Epoch: 4, loss = 0.12152861951229472\n",
      "Epoch: 5, loss = 0.04478990713444849\n",
      "Epoch: 6, loss = -0.03922530775889754\n",
      "Epoch: 7, loss = -0.1312125859161218\n",
      "Epoch: 8, loss = -0.2316443636858215\n",
      "Epoch: 9, loss = -0.340454447393616\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.3015694839414209\n",
      "Epoch: 1, loss = -0.4109247839078307\n",
      "Epoch: 2, loss = -0.5416420996189117\n",
      "Epoch: 3, loss = -0.6515255440026522\n",
      "Epoch: 4, loss = -0.7478500828146935\n",
      "Epoch: 5, loss = -0.6995507590472698\n",
      "Epoch: 6, loss = -0.7724818550050259\n",
      "Epoch: 7, loss = -0.8787692934274673\n",
      "Epoch: 8, loss = -0.8670857883989811\n",
      "Epoch: 9, loss = -0.9058144353330135\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.7832292336970568\n",
      "Epoch: 1, loss = -0.9181753695011139\n",
      "Epoch: 2, loss = -1.055822428315878\n",
      "Epoch: 3, loss = -1.1822617538273335\n",
      "Epoch: 4, loss = -1.1578134633600712\n",
      "Epoch: 5, loss = -0.6961387991905212\n",
      "Epoch: 6, loss = -0.5566718587651849\n",
      "Epoch: 7, loss = 0.23126564174890518\n",
      "Epoch: 8, loss = -0.04199415957555175\n",
      "Epoch: 9, loss = -0.8866596296429634\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.3164527161279693\n",
      "Epoch: 1, loss = -0.4369336711242795\n",
      "Epoch: 2, loss = -0.5666090743616223\n",
      "Epoch: 3, loss = -0.693859163671732\n",
      "Epoch: 4, loss = -0.8052951246500015\n",
      "Epoch: 5, loss = -0.8743255566805601\n",
      "Epoch: 6, loss = -1.0516092330217361\n",
      "Epoch: 7, loss = -1.1644237376749516\n",
      "Epoch: 8, loss = -1.2691564373672009\n",
      "Epoch: 9, loss = -1.2215527221560478\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.5996139729395509\n",
      "Epoch: 1, loss = -0.7347374130040407\n",
      "Epoch: 2, loss = -0.8645048197358847\n",
      "Epoch: 3, loss = -0.8625331725925207\n",
      "Epoch: 4, loss = -0.9292230922728777\n",
      "Epoch: 5, loss = -0.636432446539402\n",
      "Epoch: 6, loss = -0.959953922778368\n",
      "Epoch: 7, loss = -1.0658697038888931\n",
      "Epoch: 8, loss = -1.124317780137062\n",
      "Epoch: 9, loss = -1.1852212846279144\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.4068382512778044\n",
      "Epoch: 1, loss = -0.5092020854353905\n",
      "Epoch: 2, loss = -0.647159531712532\n",
      "Epoch: 3, loss = -0.774896290153265\n",
      "Epoch: 4, loss = -0.8760585952550173\n",
      "Epoch: 5, loss = -1.0137523375451565\n",
      "Epoch: 6, loss = -1.1334944851696491\n",
      "Epoch: 7, loss = -1.1856476739048958\n",
      "Epoch: 8, loss = -1.1399310231208801\n",
      "Epoch: 9, loss = -1.3300422467291355\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = -0.8947036772966385\n",
      "Epoch: 1, loss = -0.9701023519039152\n",
      "Epoch: 2, loss = -0.8677435137331485\n",
      "Epoch: 3, loss = -0.8380152061581612\n",
      "Epoch: 4, loss = -0.9222400948405264\n",
      "Epoch: 5, loss = -1.1385740369558333\n",
      "Epoch: 6, loss = -1.3057905882596967\n",
      "Epoch: 7, loss = -1.3906421780586242\n",
      "Epoch: 8, loss = -1.4887386977672576\n",
      "Epoch: 9, loss = -1.54427342414856\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.1319556057453155\n",
      "Epoch: 1, loss = -1.2984931737184522\n",
      "Epoch: 2, loss = -1.4177573919296265\n",
      "Epoch: 3, loss = -1.3887398272752762\n",
      "Epoch: 4, loss = -1.3003158420324326\n",
      "Epoch: 5, loss = -1.566631007194519\n",
      "Epoch: 6, loss = -1.4570242732763292\n",
      "Epoch: 7, loss = -1.554442945122719\n",
      "Epoch: 8, loss = -1.7640731930732727\n",
      "Epoch: 9, loss = -1.8560036063194276\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.0089821740984917\n",
      "Epoch: 1, loss = -1.1911167204380033\n",
      "Epoch: 2, loss = -1.1706212669610976\n",
      "Epoch: 3, loss = -1.0791080258786676\n",
      "Epoch: 4, loss = -1.0446329742670057\n",
      "Epoch: 5, loss = -1.0799082919955254\n",
      "Epoch: 6, loss = -1.181170970201492\n",
      "Epoch: 7, loss = -1.3616190612316132\n",
      "Epoch: 8, loss = -1.4575925916433334\n",
      "Epoch: 9, loss = -1.5125661849975587\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.2539011359214784\n",
      "Epoch: 1, loss = -1.2384200423955916\n",
      "Epoch: 2, loss = -0.9294734969735148\n",
      "Epoch: 3, loss = -0.3919524744153024\n",
      "Epoch: 4, loss = -0.32169256284832964\n",
      "Epoch: 5, loss = -0.6319074213504792\n",
      "Epoch: 6, loss = -1.0165605962276458\n",
      "Epoch: 7, loss = -1.1859741538763044\n",
      "Epoch: 8, loss = -1.2723996311426164\n",
      "Epoch: 9, loss = -1.3397449582815169\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.2661731332540513\n",
      "Epoch: 1, loss = -1.3611046969890594\n",
      "Epoch: 2, loss = -1.3007366269826888\n",
      "Epoch: 3, loss = -1.267546832561493\n",
      "Epoch: 4, loss = -1.1781971514225005\n",
      "Epoch: 5, loss = -1.026197624206543\n",
      "Epoch: 6, loss = -0.835305482149124\n",
      "Epoch: 7, loss = -0.95540639385581\n",
      "Epoch: 8, loss = -1.238219851255417\n",
      "Epoch: 9, loss = -1.429458558559418\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.4586858078837395\n",
      "Epoch: 1, loss = -1.6175666352113085\n",
      "Epoch: 2, loss = -1.7071516116460166\n",
      "Epoch: 3, loss = -1.6429346352815624\n",
      "Epoch: 4, loss = -1.6708871175845466\n",
      "Epoch: 5, loss = -1.5866872866948447\n",
      "Epoch: 6, loss = -1.3293528718252976\n",
      "Epoch: 7, loss = -1.5036555950840316\n",
      "Epoch: 8, loss = -1.6222149481376014\n",
      "Epoch: 9, loss = -1.2034122732778392\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.8603877673546474\n",
      "Epoch: 1, loss = -1.8035142521063485\n",
      "Epoch: 2, loss = -1.8080167497197788\n",
      "Epoch: 3, loss = -1.4881812793513138\n",
      "Epoch: 4, loss = -1.442714663843314\n",
      "Epoch: 5, loss = -1.7446925987799962\n",
      "Epoch: 6, loss = -1.5774043872952463\n",
      "Epoch: 7, loss = -1.6301038789873323\n",
      "Epoch: 8, loss = -1.577620000268022\n",
      "Epoch: 9, loss = -1.4491188774506252\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.4772399465243025\n",
      "Epoch: 1, loss = -1.5605784108241396\n",
      "Epoch: 2, loss = -1.4640062004327776\n",
      "Epoch: 3, loss = -1.1133396830409763\n",
      "Epoch: 4, loss = -1.0776957534253595\n",
      "Epoch: 5, loss = -0.8135051081577936\n",
      "Epoch: 6, loss = -0.7593284292767444\n",
      "Epoch: 7, loss = -1.000102149322629\n",
      "Epoch: 8, loss = -1.0922205249468488\n",
      "Epoch: 9, loss = -0.9317017408708731\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.3698904688159623\n",
      "Epoch: 1, loss = -1.3538550958037376\n",
      "Epoch: 2, loss = -1.3710571279128394\n",
      "Epoch: 3, loss = -1.2345646396279335\n",
      "Epoch: 4, loss = -1.133737172931433\n",
      "Epoch: 5, loss = -0.8626176963249843\n",
      "Epoch: 6, loss = -0.7944986447691919\n",
      "Epoch: 7, loss = -1.031943435470263\n",
      "Epoch: 8, loss = -1.3286588316162429\n",
      "Epoch: 9, loss = -1.470139463742574\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.4850573490063348\n",
      "Epoch: 1, loss = -1.5768759151299792\n",
      "Epoch: 2, loss = -1.4759738941987357\n",
      "Epoch: 3, loss = -1.4850377353529134\n",
      "Epoch: 4, loss = -1.6853395452102027\n",
      "Epoch: 5, loss = -1.802965670824051\n",
      "Epoch: 6, loss = -1.8529805789391196\n",
      "Epoch: 7, loss = -1.761351391673088\n",
      "Epoch: 8, loss = -1.834503591060638\n",
      "Epoch: 9, loss = -1.4666143183906872\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n",
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5103982351720333\n",
      "Epoch: 1, loss = 0.4371834546327591\n",
      "Epoch: 2, loss = 0.3561863945797086\n",
      "Epoch: 3, loss = 0.2643822970567271\n",
      "Epoch: 4, loss = 0.15947459475137293\n",
      "Epoch: 5, loss = 0.03972358023747802\n",
      "Epoch: 6, loss = -0.09577037114650011\n",
      "Epoch: 7, loss = -0.24726921296678483\n",
      "Epoch: 8, loss = -0.40885693626478314\n",
      "Epoch: 9, loss = -0.5803261650726199\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2719305790960789\n",
      "Epoch: 1, loss = 0.16860951436683536\n",
      "Epoch: 2, loss = 0.05195153335807845\n",
      "Epoch: 3, loss = -0.07552617706824094\n",
      "Epoch: 4, loss = -0.21767667611129582\n",
      "Epoch: 5, loss = -0.3738510673865676\n",
      "Epoch: 6, loss = -0.5404384918510914\n",
      "Epoch: 7, loss = -0.7122709024697542\n",
      "Epoch: 8, loss = -0.8830852098762989\n",
      "Epoch: 9, loss = -1.0395896099507809\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.48299642838537693\n",
      "Epoch: 1, loss = 0.4107547476887703\n",
      "Epoch: 2, loss = 0.3313036635518074\n",
      "Epoch: 3, loss = 0.24324627686291933\n",
      "Epoch: 4, loss = 0.14311043923953548\n",
      "Epoch: 5, loss = 0.030795700382441282\n",
      "Epoch: 6, loss = -0.09542169084306806\n",
      "Epoch: 7, loss = -0.23506023501977324\n",
      "Epoch: 8, loss = -0.38341486162971705\n",
      "Epoch: 9, loss = -0.5280982339754701\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.3102379599586129\n",
      "Epoch: 1, loss = 0.21766242268495262\n",
      "Epoch: 2, loss = 0.11478925606934354\n",
      "Epoch: 3, loss = 0.001520508958492428\n",
      "Epoch: 4, loss = -0.12511244614142925\n",
      "Epoch: 5, loss = -0.2645944969262928\n",
      "Epoch: 6, loss = -0.4179787961766124\n",
      "Epoch: 7, loss = -0.5638474281877279\n",
      "Epoch: 8, loss = -0.6472138483077288\n",
      "Epoch: 9, loss = -0.7116694264113903\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.38867295160889626\n",
      "Epoch: 1, loss = 0.31613722536712885\n",
      "Epoch: 2, loss = 0.23797424603253603\n",
      "Epoch: 3, loss = 0.15058740973472595\n",
      "Epoch: 4, loss = 0.05181764782173559\n",
      "Epoch: 5, loss = -0.05966903327498585\n",
      "Epoch: 6, loss = -0.18492198025342077\n",
      "Epoch: 7, loss = -0.3238509907387197\n",
      "Epoch: 8, loss = -0.4722947273403406\n",
      "Epoch: 9, loss = -0.6211070865392685\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -0.6625782810151578\n",
      "Epoch: 1, loss = -0.853493706633647\n",
      "Epoch: 2, loss = -0.9411105314890545\n",
      "Epoch: 3, loss = -0.8436247011025748\n",
      "Epoch: 4, loss = -0.6689824064572653\n",
      "Epoch: 5, loss = -0.6518923516074817\n",
      "Epoch: 6, loss = -0.8715614099055529\n",
      "Epoch: 7, loss = -0.7568993537376325\n",
      "Epoch: 8, loss = -0.9291432338456314\n",
      "Epoch: 9, loss = -1.0850482856233914\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.093463438252608\n",
      "Epoch: 1, loss = -1.195120304822922\n",
      "Epoch: 2, loss = -1.1995279838641484\n",
      "Epoch: 3, loss = -1.2559182867407797\n",
      "Epoch: 4, loss = -1.2178509682416916\n",
      "Epoch: 5, loss = -1.4215642288327217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss = -1.4785919984181723\n",
      "Epoch: 7, loss = -1.44726311104993\n",
      "Epoch: 8, loss = -1.5406005109349885\n",
      "Epoch: 9, loss = -1.6816727568705878\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.6208221515019734\n",
      "Epoch: 1, loss = -0.7942324094474316\n",
      "Epoch: 2, loss = -0.9880636818706989\n",
      "Epoch: 3, loss = -1.0831663658221562\n",
      "Epoch: 4, loss = -1.129499112566312\n",
      "Epoch: 5, loss = -1.1879441017905872\n",
      "Epoch: 6, loss = -1.3429997141162555\n",
      "Epoch: 7, loss = -1.2264292525748413\n",
      "Epoch: 8, loss = -1.0064681048194568\n",
      "Epoch: 9, loss = -0.4566996482511362\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.5778606701642276\n",
      "Epoch: 1, loss = -0.7706807379921277\n",
      "Epoch: 2, loss = -0.8371757181982199\n",
      "Epoch: 3, loss = -0.9508186976114908\n",
      "Epoch: 4, loss = -0.9949091523885725\n",
      "Epoch: 5, loss = -1.0754260395963988\n",
      "Epoch: 6, loss = -1.2423589949806533\n",
      "Epoch: 7, loss = -1.3751146718859673\n",
      "Epoch: 8, loss = -1.1763719307879605\n",
      "Epoch: 9, loss = -1.2537110770742097\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.6896711836258571\n",
      "Epoch: 1, loss = -0.8397456556558609\n",
      "Epoch: 2, loss = -1.03771044810613\n",
      "Epoch: 3, loss = -1.1851635326941807\n",
      "Epoch: 4, loss = -1.165605867902438\n",
      "Epoch: 5, loss = -0.847467176616192\n",
      "Epoch: 6, loss = -1.1934831328690052\n",
      "Epoch: 7, loss = -1.1979416621228063\n",
      "Epoch: 8, loss = -1.046677942077319\n",
      "Epoch: 9, loss = -0.8056521024554968\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.2824915293604136\n",
      "Epoch: 1, loss = -1.0711653772741556\n",
      "Epoch: 2, loss = -1.2696629986166954\n",
      "Epoch: 3, loss = -1.4234974011778831\n",
      "Epoch: 4, loss = -1.507982900366187\n",
      "Epoch: 5, loss = -1.5165954669937491\n",
      "Epoch: 6, loss = -1.3270450760610402\n",
      "Epoch: 7, loss = -0.8429493056610227\n",
      "Epoch: 8, loss = -1.1224902290850878\n",
      "Epoch: 9, loss = -1.492294479161501\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.7358202524483204\n",
      "Epoch: 1, loss = -1.6980976816266775\n",
      "Epoch: 2, loss = -1.9208093285560608\n",
      "Epoch: 3, loss = -1.7445876160636544\n",
      "Epoch: 4, loss = -1.8581522889435291\n",
      "Epoch: 5, loss = -1.9042783975601196\n",
      "Epoch: 6, loss = -1.988382987678051\n",
      "Epoch: 7, loss = -1.7068343171849847\n",
      "Epoch: 8, loss = -1.7535985745489597\n",
      "Epoch: 9, loss = -1.3862313516438007\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -0.9380277735181153\n",
      "Epoch: 1, loss = -1.2942250669002533\n",
      "Epoch: 2, loss = -1.4145498592406511\n",
      "Epoch: 3, loss = -1.4544500410556793\n",
      "Epoch: 4, loss = -1.3587515037506819\n",
      "Epoch: 5, loss = -1.456503914669156\n",
      "Epoch: 6, loss = -1.3022088035941124\n",
      "Epoch: 7, loss = -1.5688589736819267\n",
      "Epoch: 8, loss = -1.5917969718575478\n",
      "Epoch: 9, loss = -1.5301959654316306\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.9747812757268548\n",
      "Epoch: 1, loss = -1.1023355973884463\n",
      "Epoch: 2, loss = -1.3704723324626684\n",
      "Epoch: 3, loss = -1.5051357373595238\n",
      "Epoch: 4, loss = -1.467863729223609\n",
      "Epoch: 5, loss = -1.3928588693961501\n",
      "Epoch: 6, loss = -1.2075863347854465\n",
      "Epoch: 7, loss = -1.2653342233970761\n",
      "Epoch: 8, loss = -1.5405373349785805\n",
      "Epoch: 9, loss = -1.6881551966071129\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -0.6773256864398718\n",
      "Epoch: 1, loss = -1.1557443030178547\n",
      "Epoch: 2, loss = -1.3355997446924448\n",
      "Epoch: 3, loss = -1.4149604048579931\n",
      "Epoch: 4, loss = -1.423865806311369\n",
      "Epoch: 5, loss = -1.224172015907243\n",
      "Epoch: 6, loss = -1.0473026409745216\n",
      "Epoch: 7, loss = -1.4730064235627651\n",
      "Epoch: 8, loss = -1.6193842515349388\n",
      "Epoch: 9, loss = -1.6553384028375149\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.6189096808433534\n",
      "Epoch: 1, loss = -1.6952235609292983\n",
      "Epoch: 2, loss = -1.2606319636106487\n",
      "Epoch: 3, loss = -1.7574899613857267\n",
      "Epoch: 4, loss = -1.7781296193599707\n",
      "Epoch: 5, loss = -1.8371263235807422\n",
      "Epoch: 6, loss = -1.7997911214828488\n",
      "Epoch: 7, loss = -1.8302061527967455\n",
      "Epoch: 8, loss = -1.7671683609485624\n",
      "Epoch: 9, loss = -1.6561074085533627\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.5959916338324551\n",
      "Epoch: 1, loss = -1.25927169919014\n",
      "Epoch: 2, loss = -1.3569888323545458\n",
      "Epoch: 3, loss = -1.7376549094915392\n",
      "Epoch: 4, loss = -1.6585029020905493\n",
      "Epoch: 5, loss = -1.7385561227798463\n",
      "Epoch: 6, loss = -1.5830079138278959\n",
      "Epoch: 7, loss = -1.1413952454924585\n",
      "Epoch: 8, loss = -1.573371335864067\n",
      "Epoch: 9, loss = -1.832483121752739\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.5986767232418064\n",
      "Epoch: 1, loss = -1.22812769934535\n",
      "Epoch: 2, loss = -1.5968100458383565\n",
      "Epoch: 3, loss = -1.7126111537218092\n",
      "Epoch: 4, loss = -1.6206437699496745\n",
      "Epoch: 5, loss = -1.4053651265799998\n",
      "Epoch: 6, loss = -1.3818332381546494\n",
      "Epoch: 7, loss = -1.7286971837282183\n",
      "Epoch: 8, loss = -1.684753686189651\n",
      "Epoch: 9, loss = -1.6725794743746518\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.6711672246456144\n",
      "Epoch: 1, loss = -1.5182662077248097\n",
      "Epoch: 2, loss = -1.6246369630098336\n",
      "Epoch: 3, loss = -1.6497657239437105\n",
      "Epoch: 4, loss = -1.8114194929599763\n",
      "Epoch: 5, loss = -1.8569679856300356\n",
      "Epoch: 6, loss = -1.7840144485235216\n",
      "Epoch: 7, loss = -1.6564755037426953\n",
      "Epoch: 8, loss = -1.5099329743534324\n",
      "Epoch: 9, loss = -1.7741732001304624\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.7440596520900726\n",
      "Epoch: 1, loss = -1.5813066482543947\n",
      "Epoch: 2, loss = -1.8969188332557676\n",
      "Epoch: 3, loss = -1.7473113119602202\n",
      "Epoch: 4, loss = -1.727500342577696\n",
      "Epoch: 5, loss = -1.003859531879425\n",
      "Epoch: 6, loss = -1.2405986135825513\n",
      "Epoch: 7, loss = -1.720466876029968\n",
      "Epoch: 8, loss = -1.8362380683422084\n",
      "Epoch: 9, loss = -1.9097061365842818\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n",
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5278336902459463\n",
      "Epoch: 1, loss = 0.4248689965655406\n",
      "Epoch: 2, loss = 0.3008134663105011\n",
      "Epoch: 3, loss = 0.14811509381979704\n",
      "Epoch: 4, loss = -0.03993417287711056\n",
      "Epoch: 5, loss = -0.2681874245560417\n",
      "Epoch: 6, loss = -0.5251190091172856\n",
      "Epoch: 7, loss = -0.7601768150925634\n",
      "Epoch: 8, loss = -0.8730339532097181\n",
      "Epoch: 9, loss = -1.2159728432695067\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.2700213299443325\n",
      "Epoch: 1, loss = 0.11442957484784226\n",
      "Epoch: 2, loss = -0.06900290601576367\n",
      "Epoch: 3, loss = -0.2854989959547917\n",
      "Epoch: 4, loss = -0.5339546091854571\n",
      "Epoch: 5, loss = -0.7835557957490284\n",
      "Epoch: 6, loss = -1.0215112020572028\n",
      "Epoch: 7, loss = -1.2145861834287646\n",
      "Epoch: 8, loss = -1.0608238553007443\n",
      "Epoch: 9, loss = -0.5626121088862419\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.4961108701924483\n",
      "Epoch: 1, loss = 0.3991619056711595\n",
      "Epoch: 2, loss = 0.2792746820487082\n",
      "Epoch: 3, loss = 0.1386553829846283\n",
      "Epoch: 4, loss = -0.0331463462401492\n",
      "Epoch: 5, loss = -0.23996523562042665\n",
      "Epoch: 6, loss = -0.4777988453085223\n",
      "Epoch: 7, loss = -0.7391507749756178\n",
      "Epoch: 8, loss = -0.9532238120834033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss = -1.060022821029027\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.32269122637808323\n",
      "Epoch: 1, loss = 0.19865700866406164\n",
      "Epoch: 2, loss = 0.035044522141106434\n",
      "Epoch: 3, loss = -0.14352840852613247\n",
      "Epoch: 4, loss = -0.33970120409503574\n",
      "Epoch: 5, loss = -0.5478320444623629\n",
      "Epoch: 6, loss = -0.7024617443482081\n",
      "Epoch: 7, loss = -0.8512587199608486\n",
      "Epoch: 8, loss = -0.9157418943941594\n",
      "Epoch: 9, loss = -1.0248202979564667\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3921672378977139\n",
      "Epoch: 1, loss = 0.28806850872933865\n",
      "Epoch: 2, loss = 0.16660853444288176\n",
      "Epoch: 3, loss = 0.02035951804524909\n",
      "Epoch: 4, loss = -0.15451651454592746\n",
      "Epoch: 5, loss = -0.35428974839548266\n",
      "Epoch: 6, loss = -0.5589576512575148\n",
      "Epoch: 7, loss = -0.723328864822785\n",
      "Epoch: 8, loss = -0.8134300727397202\n",
      "Epoch: 9, loss = -0.9493827509383358\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.2578194156289098\n",
      "Epoch: 1, loss = -1.2866894230246544\n",
      "Epoch: 2, loss = -0.8948308702558277\n",
      "Epoch: 3, loss = -0.616480367258191\n",
      "Epoch: 4, loss = -0.7206785656511783\n",
      "Epoch: 5, loss = -0.8779198125004768\n",
      "Epoch: 6, loss = -1.190531615912914\n",
      "Epoch: 7, loss = -1.3574900314211846\n",
      "Epoch: 8, loss = -1.4779432475566863\n",
      "Epoch: 9, loss = -1.560755839943886\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -0.928852131962776\n",
      "Epoch: 1, loss = -1.1581525169312956\n",
      "Epoch: 2, loss = -1.3747264891862871\n",
      "Epoch: 3, loss = -1.5471180886030194\n",
      "Epoch: 4, loss = -1.6431944593787193\n",
      "Epoch: 5, loss = -1.6841125592589374\n",
      "Epoch: 6, loss = -1.4910545557737347\n",
      "Epoch: 7, loss = -1.5512143976986406\n",
      "Epoch: 8, loss = -1.6933341860771176\n",
      "Epoch: 9, loss = -1.946639978885651\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.2222203537821767\n",
      "Epoch: 1, loss = -1.249770273268223\n",
      "Epoch: 2, loss = -1.3941122204065322\n",
      "Epoch: 3, loss = -1.3302684143185615\n",
      "Epoch: 4, loss = -1.3261810332536694\n",
      "Epoch: 5, loss = -1.155018094927072\n",
      "Epoch: 6, loss = -1.5180901199579242\n",
      "Epoch: 7, loss = -1.577180010080338\n",
      "Epoch: 8, loss = -1.7276700288057323\n",
      "Epoch: 9, loss = -1.7537872821092608\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.04793194681406\n",
      "Epoch: 1, loss = -0.9119649983942509\n",
      "Epoch: 2, loss = -0.8073531083762646\n",
      "Epoch: 3, loss = -1.1534365594387055\n",
      "Epoch: 4, loss = -1.1027132309973238\n",
      "Epoch: 5, loss = -1.2198625177145004\n",
      "Epoch: 6, loss = -1.253552412986755\n",
      "Epoch: 7, loss = -1.3406634822487833\n",
      "Epoch: 8, loss = -1.4696131974458697\n",
      "Epoch: 9, loss = -1.601838561892509\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.0891506373882291\n",
      "Epoch: 1, loss = -1.0289295256137847\n",
      "Epoch: 2, loss = -1.3374446466565135\n",
      "Epoch: 3, loss = -1.4690298706293106\n",
      "Epoch: 4, loss = -1.5017005860805512\n",
      "Epoch: 5, loss = -1.591861155629158\n",
      "Epoch: 6, loss = -1.64054939635098\n",
      "Epoch: 7, loss = -1.7323630928993226\n",
      "Epoch: 8, loss = -1.7479229032993315\n",
      "Epoch: 9, loss = -1.7560297727584837\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.397690250538289\n",
      "Epoch: 1, loss = -1.16490658359336\n",
      "Epoch: 2, loss = -1.414802435785532\n",
      "Epoch: 3, loss = -1.5987113416194916\n",
      "Epoch: 4, loss = -1.5598159565457272\n",
      "Epoch: 5, loss = -1.6797365312065398\n",
      "Epoch: 6, loss = -1.4707006007166845\n",
      "Epoch: 7, loss = -1.6802612223795486\n",
      "Epoch: 8, loss = -1.693233069564615\n",
      "Epoch: 9, loss = -1.7933829277753832\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.8800587153860502\n",
      "Epoch: 1, loss = -1.98400242626667\n",
      "Epoch: 2, loss = -2.061918137328966\n",
      "Epoch: 3, loss = -2.137916230729648\n",
      "Epoch: 4, loss = -2.0989718990666524\n",
      "Epoch: 5, loss = -2.184367362942015\n",
      "Epoch: 6, loss = -2.114446902913707\n",
      "Epoch: 7, loss = -2.1219898590019772\n",
      "Epoch: 8, loss = -2.258803080235209\n",
      "Epoch: 9, loss = -2.23388721048832\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.72616156722818\n",
      "Epoch: 1, loss = -1.4537386942122659\n",
      "Epoch: 2, loss = -1.519718000798353\n",
      "Epoch: 3, loss = -1.3675577802849668\n",
      "Epoch: 4, loss = -1.062528877386025\n",
      "Epoch: 5, loss = -1.4813147122040389\n",
      "Epoch: 6, loss = -1.6844710218054908\n",
      "Epoch: 7, loss = -1.7789501334939681\n",
      "Epoch: 8, loss = -1.895424610802105\n",
      "Epoch: 9, loss = -1.9036855378321236\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.5042061530319706\n",
      "Epoch: 1, loss = -1.3394362213356157\n",
      "Epoch: 2, loss = -1.379021227359772\n",
      "Epoch: 3, loss = -1.6760636568069462\n",
      "Epoch: 4, loss = -1.7439388377325875\n",
      "Epoch: 5, loss = -1.5651424851800708\n",
      "Epoch: 6, loss = -1.509462754907352\n",
      "Epoch: 7, loss = -1.646402289159596\n",
      "Epoch: 8, loss = -1.6064107601663893\n",
      "Epoch: 9, loss = -1.8072112745472362\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.812898948788643\n",
      "Epoch: 1, loss = -1.6952430536704401\n",
      "Epoch: 2, loss = -1.3664538344102246\n",
      "Epoch: 3, loss = -1.7420900112816267\n",
      "Epoch: 4, loss = -1.831609246986253\n",
      "Epoch: 5, loss = -1.9358587690762112\n",
      "Epoch: 6, loss = -1.889313612665449\n",
      "Epoch: 7, loss = -1.592985530516931\n",
      "Epoch: 8, loss = -1.6456307814057383\n",
      "Epoch: 9, loss = -1.9443480627877372\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.6224142971138156\n",
      "Epoch: 1, loss = -1.5909718275070188\n",
      "Epoch: 2, loss = -1.8062401149008007\n",
      "Epoch: 3, loss = -1.8634563850031944\n",
      "Epoch: 4, loss = -1.895983502268791\n",
      "Epoch: 5, loss = -1.9590866963068647\n",
      "Epoch: 6, loss = -2.010395447413127\n",
      "Epoch: 7, loss = -2.0665159324804936\n",
      "Epoch: 8, loss = -2.0896338936355376\n",
      "Epoch: 9, loss = -2.1079351123836303\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.7642653588619501\n",
      "Epoch: 1, loss = -1.9326099993454087\n",
      "Epoch: 2, loss = -2.140793963438935\n",
      "Epoch: 3, loss = -2.12248821121951\n",
      "Epoch: 4, loss = -2.1977024045255447\n",
      "Epoch: 5, loss = -2.2266332457462945\n",
      "Epoch: 6, loss = -2.2837744818793406\n",
      "Epoch: 7, loss = -2.3096704350577464\n",
      "Epoch: 8, loss = -2.35213407377402\n",
      "Epoch: 9, loss = -2.354059022333887\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.6619420581393776\n",
      "Epoch: 1, loss = -1.7024726890441442\n",
      "Epoch: 2, loss = -1.6700815649496181\n",
      "Epoch: 3, loss = -1.761875328504377\n",
      "Epoch: 4, loss = -1.8737433966663155\n",
      "Epoch: 5, loss = -1.9325899365875456\n",
      "Epoch: 6, loss = -2.006238136026594\n",
      "Epoch: 7, loss = -2.004607990384102\n",
      "Epoch: 8, loss = -1.955958651171791\n",
      "Epoch: 9, loss = -2.0463666419188185\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.7546676480107837\n",
      "Epoch: 1, loss = -1.69918698279394\n",
      "Epoch: 2, loss = -1.7997876877586043\n",
      "Epoch: 3, loss = -1.848763348327743\n",
      "Epoch: 4, loss = -1.8369352701637485\n",
      "Epoch: 5, loss = -1.8439713269472122\n",
      "Epoch: 6, loss = -1.8900595787498689\n",
      "Epoch: 7, loss = -1.92679019106759\n",
      "Epoch: 8, loss = -1.9514353854788673\n",
      "Epoch: 9, loss = -1.9827563282516267\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.0009900345984435\n",
      "Epoch: 1, loss = -1.90595104586747\n",
      "Epoch: 2, loss = -2.041257686085171\n",
      "Epoch: 3, loss = -2.135303157899115\n",
      "Epoch: 4, loss = -2.196529171533055\n",
      "Epoch: 5, loss = -2.2463868326610994\n",
      "Epoch: 6, loss = -2.2837305714686713\n",
      "Epoch: 7, loss = -2.308994965420829\n",
      "Epoch: 8, loss = -2.3496247579654055\n",
      "Epoch: 9, loss = -2.3208838933044\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.8343117833137512\n",
      "Epoch: 1, loss = 0.7972749918699265\n",
      "Epoch: 2, loss = 0.7639063000679016\n",
      "Epoch: 3, loss = 0.7307401970028877\n",
      "Epoch: 4, loss = 0.6967381536960602\n",
      "Epoch: 5, loss = 0.6615797951817513\n",
      "Epoch: 6, loss = 0.624359242618084\n",
      "Epoch: 7, loss = 0.5844887346029282\n",
      "Epoch: 8, loss = 0.5414410643279552\n",
      "Epoch: 9, loss = 0.49476340040564537\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.7739237174391747\n",
      "Epoch: 1, loss = 0.7152590304613113\n",
      "Epoch: 2, loss = 0.6652219742536545\n",
      "Epoch: 3, loss = 0.6177457123994827\n",
      "Epoch: 4, loss = 0.5690100565552711\n",
      "Epoch: 5, loss = 0.5187578201293945\n",
      "Epoch: 6, loss = 0.4668896980583668\n",
      "Epoch: 7, loss = 0.4124934710562229\n",
      "Epoch: 8, loss = 0.3551187813282013\n",
      "Epoch: 9, loss = 0.29415640234947205\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.8077187612652779\n",
      "Epoch: 1, loss = 0.776576891541481\n",
      "Epoch: 2, loss = 0.7452234998345375\n",
      "Epoch: 3, loss = 0.7128882631659508\n",
      "Epoch: 4, loss = 0.6790819689631462\n",
      "Epoch: 5, loss = 0.6433211416006088\n",
      "Epoch: 6, loss = 0.6051415279507637\n",
      "Epoch: 7, loss = 0.5640516802668571\n",
      "Epoch: 8, loss = 0.5195331387221813\n",
      "Epoch: 9, loss = 0.47104930505156517\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.729969933629036\n",
      "Epoch: 1, loss = 0.6834419742226601\n",
      "Epoch: 2, loss = 0.6410914584994316\n",
      "Epoch: 3, loss = 0.5994448438286781\n",
      "Epoch: 4, loss = 0.5568822696805\n",
      "Epoch: 5, loss = 0.5131351090967655\n",
      "Epoch: 6, loss = 0.4676937386393547\n",
      "Epoch: 7, loss = 0.41985850036144257\n",
      "Epoch: 8, loss = 0.3689381368458271\n",
      "Epoch: 9, loss = 0.31456316262483597\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.7333459183573723\n",
      "Epoch: 1, loss = 0.6986559182405472\n",
      "Epoch: 2, loss = 0.6641641482710838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss = 0.6290376335382462\n",
      "Epoch: 4, loss = 0.5928840339183807\n",
      "Epoch: 5, loss = 0.5553633347153664\n",
      "Epoch: 6, loss = 0.5161524079740047\n",
      "Epoch: 7, loss = 0.4749310128390789\n",
      "Epoch: 8, loss = 0.4314114935696125\n",
      "Epoch: 9, loss = 0.3852224051952362\n",
      "\n",
      "T = 0\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = 0.5211547158658504\n",
      "Epoch: 1, loss = 0.33868848700076337\n",
      "Epoch: 2, loss = 0.07510341762099415\n",
      "Epoch: 3, loss = -0.3039833523333073\n",
      "Epoch: 4, loss = -0.7867119967937471\n",
      "Epoch: 5, loss = -1.2172438785433768\n",
      "Epoch: 6, loss = -1.3956934809684753\n",
      "Epoch: 7, loss = -1.5668059319257739\n",
      "Epoch: 8, loss = -1.1255787648260593\n",
      "Epoch: 9, loss = -0.78642489425838\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = 0.23103481531143188\n",
      "Epoch: 1, loss = -0.05990755269303918\n",
      "Epoch: 2, loss = -0.4484477452933789\n",
      "Epoch: 3, loss = -0.8179497018456461\n",
      "Epoch: 4, loss = -0.445475029014051\n",
      "Epoch: 5, loss = -0.795846926048398\n",
      "Epoch: 6, loss = -1.0476002976298333\n",
      "Epoch: 7, loss = -1.171707487106323\n",
      "Epoch: 8, loss = -1.3891720220446582\n",
      "Epoch: 9, loss = -1.5120402187108992\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = 0.4866897895932199\n",
      "Epoch: 1, loss = 0.3193076971918345\n",
      "Epoch: 2, loss = 0.0778032979927957\n",
      "Epoch: 3, loss = -0.2526807059533895\n",
      "Epoch: 4, loss = -0.6803371667861938\n",
      "Epoch: 5, loss = -1.1165497526526453\n",
      "Epoch: 6, loss = -1.3871997416019441\n",
      "Epoch: 7, loss = -1.2501182720065118\n",
      "Epoch: 8, loss = -1.2773470975458623\n",
      "Epoch: 9, loss = -1.5242655441164976\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = 0.29329740256071096\n",
      "Epoch: 1, loss = 0.07696035045664758\n",
      "Epoch: 2, loss = -0.21220310712233187\n",
      "Epoch: 3, loss = -0.4860351376235486\n",
      "Epoch: 4, loss = -0.7555714614689351\n",
      "Epoch: 5, loss = -1.0177027985453604\n",
      "Epoch: 6, loss = -1.1940940052270888\n",
      "Epoch: 7, loss = -1.2624611034989357\n",
      "Epoch: 8, loss = -1.3633461728692058\n",
      "Epoch: 9, loss = -1.4357325948774813\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = 0.3756956487894058\n",
      "Epoch: 1, loss = 0.1903068317100406\n",
      "Epoch: 2, loss = -0.06846506181173026\n",
      "Epoch: 3, loss = -0.4134983763098718\n",
      "Epoch: 4, loss = -0.7278574198484422\n",
      "Epoch: 5, loss = -1.0093542009592056\n",
      "Epoch: 6, loss = -0.9916895668953657\n",
      "Epoch: 7, loss = -1.2108211174607277\n",
      "Epoch: 8, loss = -1.2190386578440666\n",
      "Epoch: 9, loss = -1.1930826246738435\n",
      "\n",
      "T = 1\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.0541160222556858\n",
      "Epoch: 1, loss = -1.501987955636448\n",
      "Epoch: 2, loss = -1.6010749803649054\n",
      "Epoch: 3, loss = -1.6747696747382481\n",
      "Epoch: 4, loss = -1.759754281904963\n",
      "Epoch: 5, loss = -1.785756886833244\n",
      "Epoch: 6, loss = -1.77321131941345\n",
      "Epoch: 7, loss = -1.8821265482240255\n",
      "Epoch: 8, loss = -1.888848641680347\n",
      "Epoch: 9, loss = -1.9025222924020553\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -1.4126368282983703\n",
      "Epoch: 1, loss = -1.5782240902384124\n",
      "Epoch: 2, loss = -1.7783602285716262\n",
      "Epoch: 3, loss = -1.8593363993697698\n",
      "Epoch: 4, loss = -1.873851653602387\n",
      "Epoch: 5, loss = -2.0051017122136225\n",
      "Epoch: 6, loss = -1.8841614485200906\n",
      "Epoch: 7, loss = -2.04838788178232\n",
      "Epoch: 8, loss = -2.050700013836225\n",
      "Epoch: 9, loss = -1.8329307453499901\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.3385753010710084\n",
      "Epoch: 1, loss = -1.5958464600973652\n",
      "Epoch: 2, loss = -1.6446987688541406\n",
      "Epoch: 3, loss = -1.7011042071713338\n",
      "Epoch: 4, loss = -1.7513076166311903\n",
      "Epoch: 5, loss = -1.7961000386211614\n",
      "Epoch: 6, loss = -1.8581064889828365\n",
      "Epoch: 7, loss = -1.9099358303679355\n",
      "Epoch: 8, loss = -1.9322111432751021\n",
      "Epoch: 9, loss = -1.969909394780795\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -0.9437898105631272\n",
      "Epoch: 1, loss = -1.2369398023519247\n",
      "Epoch: 2, loss = -1.450197383140524\n",
      "Epoch: 3, loss = -1.4968198405371773\n",
      "Epoch: 4, loss = -1.562170891712109\n",
      "Epoch: 5, loss = -1.626922438955969\n",
      "Epoch: 6, loss = -1.6921905146704779\n",
      "Epoch: 7, loss = -1.759482777780957\n",
      "Epoch: 8, loss = -1.7780541492005186\n",
      "Epoch: 9, loss = -1.7681550300783582\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.0715784520531693\n",
      "Epoch: 1, loss = -1.4726088320215547\n",
      "Epoch: 2, loss = -1.5801380127668383\n",
      "Epoch: 3, loss = -1.628461562510994\n",
      "Epoch: 4, loss = -1.6994584600130722\n",
      "Epoch: 5, loss = -1.7899740644627151\n",
      "Epoch: 6, loss = -1.8621358391311433\n",
      "Epoch: 7, loss = -1.9004167707429986\n",
      "Epoch: 8, loss = -1.963414553966787\n",
      "Epoch: 9, loss = -2.019799611634679\n",
      "\n",
      "T = 2\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -1.836367554962636\n",
      "Epoch: 1, loss = -1.9065450882682435\n",
      "Epoch: 2, loss = -1.9687552245763629\n",
      "Epoch: 3, loss = -2.0108696841276603\n",
      "Epoch: 4, loss = -2.0491886729231243\n",
      "Epoch: 5, loss = -2.0819817947653614\n",
      "Epoch: 6, loss = -2.11983223259449\n",
      "Epoch: 7, loss = -2.154236368261851\n",
      "Epoch: 8, loss = -2.1892744623697724\n",
      "Epoch: 9, loss = -2.223437626774494\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -2.0466585096258383\n",
      "Epoch: 1, loss = -1.9683833784208846\n",
      "Epoch: 2, loss = -2.1839538190800405\n",
      "Epoch: 3, loss = -2.206801450166564\n",
      "Epoch: 4, loss = -2.2746910206400432\n",
      "Epoch: 5, loss = -2.2394943724458027\n",
      "Epoch: 6, loss = -2.3157054564127555\n",
      "Epoch: 7, loss = -2.3634186942990003\n",
      "Epoch: 8, loss = -2.4081888233239837\n",
      "Epoch: 9, loss = -2.453969231018654\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -1.9937181031474704\n",
      "Epoch: 1, loss = -2.098518175574449\n",
      "Epoch: 2, loss = -2.0594325231818043\n",
      "Epoch: 3, loss = -2.162077565605825\n",
      "Epoch: 4, loss = -2.1438741387369546\n",
      "Epoch: 5, loss = -2.2661076807058773\n",
      "Epoch: 6, loss = -2.2113055724364057\n",
      "Epoch: 7, loss = -2.3172566581230893\n",
      "Epoch: 8, loss = -2.324898998897809\n",
      "Epoch: 9, loss = -2.36127642599436\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -1.8043835592957644\n",
      "Epoch: 1, loss = -1.8182200735005047\n",
      "Epoch: 2, loss = -1.8780408286704464\n",
      "Epoch: 3, loss = -1.9577966521565744\n",
      "Epoch: 4, loss = -1.9786180709130488\n",
      "Epoch: 5, loss = -2.069613848741239\n",
      "Epoch: 6, loss = -2.0863907658136807\n",
      "Epoch: 7, loss = -2.1804488805624156\n",
      "Epoch: 8, loss = -2.294290474974192\n",
      "Epoch: 9, loss = -2.2814714822631608\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -1.9946313691683688\n",
      "Epoch: 1, loss = -2.0724220665601583\n",
      "Epoch: 2, loss = -2.0649921596050267\n",
      "Epoch: 3, loss = -2.1310217546728927\n",
      "Epoch: 4, loss = -2.1528102509104277\n",
      "Epoch: 5, loss = -2.2026561624728718\n",
      "Epoch: 6, loss = -2.2248595288166633\n",
      "Epoch: 7, loss = -2.2731968703178262\n",
      "Epoch: 8, loss = -2.3056969413390522\n",
      "Epoch: 9, loss = -2.346416906668589\n",
      "\n",
      "T = 3\n",
      "\n",
      "\n",
      "Training model 0\n",
      "\n",
      "Epoch: 0, loss = -2.230249234858681\n",
      "Epoch: 1, loss = -2.177024927647676\n",
      "Epoch: 2, loss = -2.290365737150697\n",
      "Epoch: 3, loss = -2.289828257744803\n",
      "Epoch: 4, loss = -2.3565931477967443\n",
      "Epoch: 5, loss = -2.3819237666971547\n",
      "Epoch: 6, loss = -2.423620034666622\n",
      "Epoch: 7, loss = -2.4552259401363505\n",
      "Epoch: 8, loss = -2.4896828795180608\n",
      "Epoch: 9, loss = -2.5258179263157015\n",
      "\n",
      "Training model 1\n",
      "\n",
      "Epoch: 0, loss = -2.4644666506963606\n",
      "Epoch: 1, loss = -2.452946678680532\n",
      "Epoch: 2, loss = -2.589593254468022\n",
      "Epoch: 3, loss = -2.583742381895289\n",
      "Epoch: 4, loss = -2.6808444454389435\n",
      "Epoch: 5, loss = -2.6914939836544143\n",
      "Epoch: 6, loss = -2.744312523042454\n",
      "Epoch: 7, loss = -2.7622125955188968\n",
      "Epoch: 8, loss = -2.8058008691843823\n",
      "Epoch: 9, loss = -2.837016047800289\n",
      "\n",
      "Training model 2\n",
      "\n",
      "Epoch: 0, loss = -2.3747792901361695\n",
      "Epoch: 1, loss = -2.45233255712425\n",
      "Epoch: 2, loss = -2.4981022862827067\n",
      "Epoch: 3, loss = -2.5491337276556902\n",
      "Epoch: 4, loss = -2.596217123024603\n",
      "Epoch: 5, loss = -2.637749163543476\n",
      "Epoch: 6, loss = -2.6773836200728147\n",
      "Epoch: 7, loss = -2.7352674182723553\n",
      "Epoch: 8, loss = -2.8116225372342507\n",
      "Epoch: 9, loss = -2.8515267985708586\n",
      "\n",
      "Training model 3\n",
      "\n",
      "Epoch: 0, loss = -2.2758310296956235\n",
      "Epoch: 1, loss = -2.352652769426213\n",
      "Epoch: 2, loss = -2.4250875382738966\n",
      "Epoch: 3, loss = -2.484924563590218\n",
      "Epoch: 4, loss = -2.521758495008245\n",
      "Epoch: 5, loss = -2.574986408738529\n",
      "Epoch: 6, loss = -2.6029978885370144\n",
      "Epoch: 7, loss = -2.656284745125209\n",
      "Epoch: 8, loss = -2.689598459531279\n",
      "Epoch: 9, loss = -2.737371798823861\n",
      "\n",
      "Training model 4\n",
      "\n",
      "Epoch: 0, loss = -2.3285737826543693\n",
      "Epoch: 1, loss = -2.401308785466588\n",
      "Epoch: 2, loss = -2.488856947597334\n",
      "Epoch: 3, loss = -2.5373587582041233\n",
      "Epoch: 4, loss = -2.5999438771430197\n",
      "Epoch: 5, loss = -2.648151658913669\n",
      "Epoch: 6, loss = -2.690130170653848\n",
      "Epoch: 7, loss = -2.7340395941453814\n",
      "Epoch: 8, loss = -2.7768651054185964\n",
      "Epoch: 9, loss = -2.8282812079962576\n"
     ]
    }
   ],
   "source": [
    "errors_al = with_al(config_AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "749a86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_err_plot(frac_err_baseline,frac_err_AL_ens):\n",
    "    \n",
    "    K_train_list = [16, 32, 64, 128, 256, 512]  # make it global\n",
    "    ninit =128\n",
    "    T=4\n",
    "    N_train_list = ninit + T * np.array(K_train_list)\n",
    "    plt.style.use(\"classic\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(N_train_list,frac_err_baseline, \".-\", label=\"Baseline\")\n",
    "    plt.plot(N_train_list,frac_err_AL_ens, \".-\", label=\"Active learning, ensemble\")\n",
    "    plt.ylabel('Fractional error on test set')\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf8aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_err_plot(errors_baseline,errors_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba49c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
